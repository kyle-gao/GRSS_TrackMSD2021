{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SiameseFCN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMt5X0m9rA4e2fKAzbnziii",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyle-gao/GRSS_TrackMSD2021/blob/main/SiameseFCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akMeZV4ExN0i"
      },
      "source": [
        "Code from https://arxiv.org/abs/1906.11479"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8VNPgl67Sbp",
        "outputId": "bb146efb-f340-4a6b-c1ae-c7efce305859"
      },
      "source": [
        "!wget https://dfc2021.blob.core.windows.net/competition-data/nlcd-2013/2792_nlcd-2013.tif\r\n",
        "!wget https://dfc2021.blob.core.windows.net/competition-data/nlcd-2016/2792_nlcd-2016.tif\r\n",
        "!wget https://dfc2021.blob.core.windows.net/competition-data/naip-2013/2792_naip-2013.tif\r\n",
        "!wget https://dfc2021.blob.core.windows.net/competition-data/naip-2017/2792_naip-2017.tif"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-21 16:22:30--  https://dfc2021.blob.core.windows.net/competition-data/nlcd-2013/2792_nlcd-2013.tif\n",
            "Resolving dfc2021.blob.core.windows.net (dfc2021.blob.core.windows.net)... 52.239.169.100\n",
            "Connecting to dfc2021.blob.core.windows.net (dfc2021.blob.core.windows.net)|52.239.169.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 524021 (512K) [application/octet-stream]\n",
            "Saving to: ‘2792_nlcd-2013.tif.2’\n",
            "\n",
            "\r2792_nlcd-2013.tif.   0%[                    ]       0  --.-KB/s               \r2792_nlcd-2013.tif. 100%[===================>] 511.74K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-12-21 16:22:30 (30.3 MB/s) - ‘2792_nlcd-2013.tif.2’ saved [524021/524021]\n",
            "\n",
            "--2020-12-21 16:22:30--  https://dfc2021.blob.core.windows.net/competition-data/nlcd-2016/2792_nlcd-2016.tif\n",
            "Resolving dfc2021.blob.core.windows.net (dfc2021.blob.core.windows.net)... 52.239.169.100\n",
            "Connecting to dfc2021.blob.core.windows.net (dfc2021.blob.core.windows.net)|52.239.169.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 525158 (513K) [application/octet-stream]\n",
            "Saving to: ‘2792_nlcd-2016.tif.2’\n",
            "\n",
            "2792_nlcd-2016.tif. 100%[===================>] 512.85K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-12-21 16:22:30 (42.3 MB/s) - ‘2792_nlcd-2016.tif.2’ saved [525158/525158]\n",
            "\n",
            "--2020-12-21 16:22:30--  https://dfc2021.blob.core.windows.net/competition-data/naip-2013/2792_naip-2013.tif\n",
            "Resolving dfc2021.blob.core.windows.net (dfc2021.blob.core.windows.net)... 52.239.169.100\n",
            "Connecting to dfc2021.blob.core.windows.net (dfc2021.blob.core.windows.net)|52.239.169.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 57758915 (55M) [application/octet-stream]\n",
            "Saving to: ‘2792_naip-2013.tif.2’\n",
            "\n",
            "2792_naip-2013.tif. 100%[===================>]  55.08M   145MB/s    in 0.4s    \n",
            "\n",
            "2020-12-21 16:22:31 (145 MB/s) - ‘2792_naip-2013.tif.2’ saved [57758915/57758915]\n",
            "\n",
            "--2020-12-21 16:22:31--  https://dfc2021.blob.core.windows.net/competition-data/naip-2017/2792_naip-2017.tif\n",
            "Resolving dfc2021.blob.core.windows.net (dfc2021.blob.core.windows.net)... 52.239.169.100\n",
            "Connecting to dfc2021.blob.core.windows.net (dfc2021.blob.core.windows.net)|52.239.169.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60474233 (58M) [application/octet-stream]\n",
            "Saving to: ‘2792_naip-2017.tif.2’\n",
            "\n",
            "2792_naip-2017.tif. 100%[===================>]  57.67M   171MB/s    in 0.3s    \n",
            "\n",
            "2020-12-21 16:22:31 (171 MB/s) - ‘2792_naip-2017.tif.2’ saved [60474233/60474233]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgq7GECt-LMq"
      },
      "source": [
        "import numpy as np\r\n",
        "import gdal\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import keras.backend as K\r\n",
        "import tensorflow as tf\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D, Concatenate, Lambda, Subtract, Conv2DTranspose, \\\r\n",
        "    Multiply, GlobalAveragePooling2D\r\n",
        "from keras.models import Input, Model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsCxdeX68w5Q"
      },
      "source": [
        "naip2013 = np.transpose(np.expand_dims(gdal.Open(\"/content/2792_naip-2013.tif\").ReadAsArray(),axis=0),axes=[0,2,3,1])\r\n",
        "nlcd2013 = np.expand_dims(gdal.Open(\"/content/2792_nlcd-2013.tif\").ReadAsArray(),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1REqoqJnjDf_"
      },
      "source": [
        "#Our data are 3880x3880, we pad to nearest multiple of 16 3888"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiKS8jbY-jvU",
        "outputId": "233e0799-16b3-478d-9381-43899b415687"
      },
      "source": [
        "naip20133888=y = tf.keras.layers.ZeroPadding2D(padding=4)(naip2013)\r\n",
        "nlcd20133888 = tf.keras.layers.ZeroPadding2D(padding=8)(naip2013)\r\n",
        "tf.shape(naip20133888)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([   1, 3888, 3888,    4], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH-jNuyCoiYG"
      },
      "source": [
        "def get_naip (path, padding = 4):\r\n",
        "  naip = np.transpose(np.expand_dims(gdal.Open(path).ReadAsArray(),axis=0),axes=[0,2,3,1])\r\n",
        "  return tf.keras.layers.ZeroPadding2D(padding=padding)(naip)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY54qDRTo40l"
      },
      "source": [
        "naip20173888 = get_naip(\"/content/2792_naip-2017.tif\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beoCPKpEQcbW"
      },
      "source": [
        "class SiameseInception(object):\r\n",
        "\r\n",
        "    def get_model(self, input_size):\r\n",
        "        inputs_tensor = Input(shape=input_size)\r\n",
        "        Feature_Extract_Model = Model(inputs=[inputs_tensor], outputs=self._feature_extract_layer(inputs_tensor),\r\n",
        "                                      name='FEM')\r\n",
        "        Inputs_1 = Input(shape=input_size)\r\n",
        "        Inputs_2 = Input(shape=input_size)\r\n",
        "        net_X, feature_1_X, feature_2_X, feature_3_X, feature_4_X = Feature_Extract_Model(inputs=Inputs_1)\r\n",
        "        net_Y, feature_1_Y, feature_2_Y, feature_3_Y, feature_4_Y = Feature_Extract_Model(inputs=Inputs_2)\r\n",
        "\r\n",
        "        # both_net = Concatenate()([net_X, net_Y])\r\n",
        "        diff_fea_1 = self.Abs_layer(Subtract()([feature_1_X, feature_1_Y]))  # (B, H, W, 16)\r\n",
        "        diff_fea_2 = self.Abs_layer(Subtract()([feature_2_X, feature_2_Y]))  # (B, H/2, W/2, 32)\r\n",
        "        diff_fea_3 = self.Abs_layer(Subtract()([feature_3_X, feature_3_Y]))  # (B, H/4, W/4, 64)\r\n",
        "        diff_fea_4 = self.Abs_layer(Subtract()([feature_4_X, feature_4_Y]))  # (B, H/8, W/8. 128)\r\n",
        "\r\n",
        "        pred = self._change_judge_layer(inputs=net_Y, diff_fea_1=diff_fea_1, diff_fea_2=diff_fea_2,\r\n",
        "                                        diff_fea_3=diff_fea_3, diff_fea_4=diff_fea_4)\r\n",
        "        FCI_model = Model(inputs=[Inputs_1, Inputs_2], outputs=pred)\r\n",
        "        return FCI_model\r\n",
        "\r\n",
        "    def _feature_extract_layer(self, inputs):\r\n",
        "        \"\"\"\r\n",
        "        feature extraction layer\r\n",
        "        :param inputs: (B, H, W, C)\r\n",
        "        :return:\r\n",
        "            net: (B, H/16, W/16, 256)\r\n",
        "            feature_1: (B, H, W, 16)\r\n",
        "            feature_2: (B, H/2, W/16, 32)\r\n",
        "            feature_3: (B, H/4, W/16, 64)\r\n",
        "            feature_4: (B, H/8, W/16, 128)\r\n",
        "        \"\"\"\r\n",
        "        # (B, H, W, C) --> (B, H/2, W/2, 16)\r\n",
        "        layer_1 = Conv2D(16, kernel_size=3, strides=[1, 1], activation='relu', padding='same',\r\n",
        "                         kernel_initializer='he_normal', name='Conv_1')(inputs)\r\n",
        "        layer_1 = Conv2D(16, kernel_size=3, strides=[1, 1], activation='relu', padding='same',\r\n",
        "                         kernel_initializer='he_normal', name='Conv_2')(layer_1)\r\n",
        "        # layer_1 = BatchNormalization()(layer_1)\r\n",
        "        feature_1 = layer_1\r\n",
        "        layer_1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='Max_Pool_1')(layer_1)\r\n",
        "        # drop_layer_1 = Dropout(0.2)(layer_1)\r\n",
        "\r\n",
        "        # (B, H/2, W/2, 16) --> (B, H/4, W/4, 32)\r\n",
        "        layer_2 = Conv2D(32, kernel_size=3, strides=[1, 1], activation='relu', padding='same',\r\n",
        "                         kernel_initializer='he_normal', name='Conv_3')(layer_1)\r\n",
        "        layer_2 = Conv2D(32, kernel_size=3, strides=[1, 1], activation='relu', padding='same',\r\n",
        "                         kernel_initializer='he_normal', name='Conv_4')(layer_2)\r\n",
        "        #  layer_2 = BatchNormalization()(layer_2)\r\n",
        "        feature_2 = layer_2\r\n",
        "        layer_2 = Dropout(0.2)(layer_2)\r\n",
        "        layer_2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='Max_Pool_2')(layer_2)\r\n",
        "\r\n",
        "        # (B, H/4, W/4, 32) --> (B, H/8, W/8, 64)\r\n",
        "        layer_3 = self._Inception_model_2(inputs=layer_2, strides=[1, 1], data_format='NHWC')\r\n",
        "        layer_3 = self._Inception_model_1(inputs=layer_3, strides=[1, 1], data_format='NHWC')\r\n",
        "        # layer_3 = self._Inception_model_1(inputs=layer_3, strides=[1, 1], data_format='NHWC')\r\n",
        "        # layer_3 = Conv2D(64, kernel_size=1, strides=[1, 1], padding='same',\r\n",
        "                         # kernel_initializer='he_normal', name='Conv_111')(layer_3)\r\n",
        "        # layer_3 = BatchNormalization()(layer_3)\r\n",
        "        feature_3 = layer_3\r\n",
        "        layer_3 = Dropout(0.4)(layer_3)\r\n",
        "        layer_3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='Max_Pool_3')(layer_3)\r\n",
        "\r\n",
        "        # (B, H/8, W/8, 64) --> (B, H/16, W/16, 128)\r\n",
        "        layer_4 = self._Inception_model_2(inputs=layer_3, strides=[1, 1], data_format='NHWC')\r\n",
        "        layer_4 = self._Inception_model_1(inputs=layer_4, strides=[1, 1], data_format='NHWC')\r\n",
        "        # layer_4 = self._Inception_model_1(inputs=layer_4, strides=[1, 1], data_format='NHWC')\r\n",
        "        # layer_4 = Conv2D(128, kernel_size=1, strides=[1, 1], padding='same',\r\n",
        "                        #  kernel_initializer='he_normal', name='Conv_112')(layer_4)\r\n",
        "        # layer_4 = BatchNormalization()(layer_4)\r\n",
        "        feature_4 = layer_4\r\n",
        "        layer_4 = Dropout(0.5)(layer_4)\r\n",
        "        net = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='Max_Pool_4')(layer_4)\r\n",
        "\r\n",
        "        return net, feature_1, feature_2, feature_3, feature_4\r\n",
        "\r\n",
        "    def _change_judge_layer(self, inputs, diff_fea_1, diff_fea_2, diff_fea_3, diff_fea_4):\r\n",
        "        # (B, H/16, W/16, 128) --> (B, H/8, W/8, 64)\r\n",
        "        layer_1 = Conv2DTranspose(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\r\n",
        "            UpSampling2D(size=(2, 2))(inputs))\r\n",
        "\r\n",
        "        # attention_1 = self.Attention_layer(layer_1)\r\n",
        "        #  diff_fea_4 = Multiply()([attention_1, diff_fea_4])\r\n",
        "        concat_layer_1 = Concatenate()([layer_1, diff_fea_4])\r\n",
        "\r\n",
        "        # layer_1 = Conv2D(128, 3, strides=[1, 1], activation='relu', padding='same', kernel_initializer='he_normal')(\r\n",
        "        #     concat_layer_1)\r\n",
        "\r\n",
        "        layer_1 = Conv2D(128, 3, strides=[1, 1], activation='relu', padding='same', kernel_initializer='he_normal')(\r\n",
        "            concat_layer_1)\r\n",
        "        # layer_1 = BatchNormalization()(layer_1)\r\n",
        "        layer_1 = Dropout(0.5)(layer_1)\r\n",
        "        layer_1 = Conv2D(64, 3, strides=[1, 1], activation='relu', padding='same', kernel_initializer='he_normal')(\r\n",
        "            layer_1)\r\n",
        "\r\n",
        "        # (B, H/8, W/8, 64) --> (B, H/4, W/4, 32)\r\n",
        "        layer_2 = Conv2DTranspose(64, 2, strides=[1, 1], activation='relu', padding='same',\r\n",
        "                                  kernel_initializer='he_normal')(\r\n",
        "            UpSampling2D(size=(2, 2))(layer_1))\r\n",
        "\r\n",
        "        # attention_2 = self.Attention_layer(layer_2)\r\n",
        "        # diff_fea_3 = Multiply()([attention_2, diff_fea_3])\r\n",
        "        concat_layer_2 = Concatenate()([layer_2, diff_fea_3])\r\n",
        "\r\n",
        "        # layer_2 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(\r\n",
        "        #     concat_layer_2)\r\n",
        "        layer_2 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(concat_layer_2)\r\n",
        "        # layer_2 = BatchNormalization()(layer_2)\r\n",
        "        layer_2 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(layer_2)\r\n",
        "        drop_layer_2 = Dropout(0.4)(layer_2)\r\n",
        "        # (B, H/4, W/4, 32) --> (B, H/2, W/2, 16)\r\n",
        "        layer_3 = Conv2DTranspose(32, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\r\n",
        "            UpSampling2D(size=(2, 2))(drop_layer_2))\r\n",
        "\r\n",
        "        # attention_3 = self.Attention_layer(layer_3)\r\n",
        "        # diff_fea_2 = Multiply()([attention_3, diff_fea_2])\r\n",
        "        concat_layer_3 = Concatenate()([layer_3, diff_fea_2])\r\n",
        "\r\n",
        "        layer_3 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(concat_layer_3)\r\n",
        "        # layer_3 = BatchNormalization()(layer_3)\r\n",
        "        layer_3 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(layer_3)\r\n",
        "        drop_layer_3 = Dropout(0.3)(layer_3)\r\n",
        "        # (B, H/2, W/2, 16) --> (B, H, W, 1)\r\n",
        "        layer_4 = Conv2DTranspose(16, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\r\n",
        "            UpSampling2D(size=(2, 2))(drop_layer_3))\r\n",
        "\r\n",
        "        # attention_4 = self.Attention_layer(layer_4)\r\n",
        "        # diff_fea_1 = Multiply()([attention_4, diff_fea_1])\r\n",
        "        concat_layer_4 = Concatenate()([layer_4, diff_fea_1])\r\n",
        "        # drop_layer_4 = Dropout(0.2)(concat_layer_4)\r\n",
        "        # layer_4 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(\r\n",
        "        #     concat_layer_4)\r\n",
        "        # layer_3 = BatchNormalization()(layer_3)\r\n",
        "        layer_4 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(concat_layer_4)\r\n",
        "        logits = Conv2D(1, 3, activation='sigmoid', padding='same', kernel_initializer='he_normal')(layer_4)\r\n",
        "        logits = Lambda(self.squeeze)(logits)\r\n",
        "        return logits\r\n",
        "\r\n",
        "    def squeeze(self, tensor):\r\n",
        "        return K.squeeze(tensor, axis=-1)\r\n",
        "\r\n",
        "    def sum_func(self, tensor):\r\n",
        "        return K.sum(tensor, axis=-1, keepdims=True)\r\n",
        "\r\n",
        "    def Abs_layer(self, tensor):\r\n",
        "        return Lambda(K.abs)(tensor)\r\n",
        "\r\n",
        "\r\n",
        "    def Negative_layer(self, tensor):\r\n",
        "        return Lambda(self.negative)(tensor)\r\n",
        "\r\n",
        "    def negative(self, tensor):\r\n",
        "        return -tensor\r\n",
        "\r\n",
        "    def _Inception_model_1(self, inputs, strides, data_format='NHWC'):\r\n",
        "        \"\"\"\r\n",
        "        Inception model v1, which keep the channel of outputs is same with inputs\r\n",
        "        :param inputs: (B, H, W, C)\r\n",
        "        :param data_format: str\r\n",
        "        :return: net, (B, H, W, C)\r\n",
        "        \"\"\"\r\n",
        "        # attention = tf.Variable(initial_value=[1, 1, 1, 1], dtype=tf.float32)\r\n",
        "        if data_format == 'NHWC':\r\n",
        "            inputs_channel = inputs.get_shape().as_list()[-1]\r\n",
        "\r\n",
        "        else:\r\n",
        "            inputs_channel = inputs.get_shape().as_list()[1]\r\n",
        "\r\n",
        "        # 1x1 Conv\r\n",
        "        branch_11conv = Conv2D(inputs_channel // 4, kernel_size=1, strides=strides, activation='relu',\r\n",
        "                               padding='same',\r\n",
        "                               kernel_initializer='he_normal')(inputs)\r\n",
        "        # 3x3 Conv\r\n",
        "        # branch_33conv = Conv2D(inputs_channel // 4, kernel_size=1, strides=[1, 1], activation='relu', padding='same',\r\n",
        "        #                        kernel_initializer='he_normal')(inputs)\r\n",
        "        branch_33conv = Conv2D(inputs_channel // 2, kernel_size=3, strides=strides, activation='relu',\r\n",
        "                               padding='same',\r\n",
        "                               kernel_initializer='he_normal')(inputs)\r\n",
        "        # use two 3x3 conv layer to replace 5x5 conv layer, which can reduce parameter size and improve nonlinear\r\n",
        "        branch_55conv = Conv2D(inputs_channel // 4, kernel_size=1, strides=strides, activation='relu',\r\n",
        "                               padding='same',\r\n",
        "                               kernel_initializer='he_normal')(inputs)\r\n",
        "        branch_55conv = Conv2D(inputs_channel // 8, kernel_size=3, strides=strides, activation='relu',\r\n",
        "                               padding='same',\r\n",
        "                               kernel_initializer='he_normal')(branch_55conv)\r\n",
        "        branch_55conv = Conv2D(inputs_channel // 8, kernel_size=3, strides=strides, activation='relu',\r\n",
        "                               padding='same',\r\n",
        "                               kernel_initializer='he_normal')(branch_55conv)\r\n",
        "        # branch_55conv = Multiply()([attention[2], branch_55conv])\r\n",
        "        # Max Pool\r\n",
        "        branch_pool = MaxPooling2D(pool_size=[3, 3], strides=strides, padding='same')(inputs)\r\n",
        "        branch_pool = Conv2D(inputs_channel // 8, kernel_size=[1, 1], strides=strides, activation='relu',\r\n",
        "                             padding='same', kernel_initializer='he_normal')(branch_pool)\r\n",
        "        # branch_pool = Multiply()([attention[3], branch_pool])\r\n",
        "\r\n",
        "        net = Concatenate()([branch_11conv, branch_33conv, branch_55conv, branch_pool])\r\n",
        "\r\n",
        "        return net\r\n",
        "\r\n",
        "    def _Inception_model_2(self, inputs, strides, data_format='NHWC'):\r\n",
        "        \"\"\"\r\n",
        "        Inception model v2, which keep the channel of outputs is twice than inputs\r\n",
        "        :param inputs: (B, H, W, C)\r\n",
        "        :param data_format: str\r\n",
        "        :return: net, (B, H, W, 2 * C)\r\n",
        "        \"\"\"\r\n",
        "        # attention = tf.Variable(initial_value=[1, 1, 1, 1], dtype=tf.float32)\r\n",
        "        if data_format == 'NHWC':\r\n",
        "            inputs_channel = inputs.get_shape().as_list()[-1]\r\n",
        "            concat_dim = 3\r\n",
        "        else:\r\n",
        "            inputs_channel = inputs.get_shape().as_list()[1]\r\n",
        "            concat_dim = 1\r\n",
        "        # 1x1 Conv\r\n",
        "        branch_11conv = Conv2D(inputs_channel // 2, 1, strides=strides, activation='relu', padding='same',\r\n",
        "                               kernel_initializer='he_normal')(inputs)\r\n",
        "        # branch_11conv = Multiply()([attention[0], branch_11conv])\r\n",
        "        # 3x3 Conv\r\n",
        "        # branch_33conv = Conv2D(inputs_channel // 2, 1, strides=strides, activation='relu', padding='same',\r\n",
        "        #                        kernel_initializer='he_normal')(inputs)\r\n",
        "        branch_33conv = Conv2D(inputs_channel, 3, strides=strides, activation='relu', padding='same',\r\n",
        "                               kernel_initializer='he_normal')(inputs)\r\n",
        "        # use two 3x3 conv layer to replace 5x5 conv layer, which can reduce parameter size and improve nonlinear\r\n",
        "\r\n",
        "        branch_55conv = Conv2D(inputs_channel // 2, 1, strides=strides, activation='relu', padding='same',\r\n",
        "                               kernel_initializer='he_normal')(inputs)\r\n",
        "\r\n",
        "        branch_55conv = Conv2D(inputs_channel // 4, 3, strides=strides, activation='relu', padding='same',\r\n",
        "                               kernel_initializer='he_normal')(branch_55conv)\r\n",
        "        branch_55conv = Conv2D(inputs_channel // 4, 3, strides=strides, activation='relu', padding='same',\r\n",
        "                               kernel_initializer='he_normal')(branch_55conv)\r\n",
        "        # Max Pool\r\n",
        "        branch_pool = MaxPooling2D(pool_size=[3, 3], strides=strides, padding='same')(inputs)\r\n",
        "        branch_pool = Conv2D(inputs_channel // 4, 1, strides=strides, activation='relu', padding='same',\r\n",
        "                             kernel_initializer='he_normal')(branch_pool)\r\n",
        "        # branch_pool = Multiply()([attention[3], branch_pool])\r\n",
        "        net = Concatenate(axis=concat_dim)([branch_11conv, branch_33conv, branch_55conv, branch_pool])\r\n",
        "\r\n",
        "        return net\r\n",
        "\r\n",
        "\r\n",
        "    def Expand_Dim_Layer(self, tensor):\r\n",
        "        def expand_dim(tensor):\r\n",
        "            return K.expand_dims(tensor, axis=1)\r\n",
        "\r\n",
        "        return Lambda(expand_dim)(tensor)\r\n",
        "\r\n",
        "    def get_loss(self, label, logits, pos_weight):\r\n",
        "        loss = tf.reduce_mean(\r\n",
        "            tf.nn.weighted_cross_entropy_with_logits(targets=label, logits=logits, pos_weight=pos_weight,\r\n",
        "                                                     name='weight_loss'))\r\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjXfbLUOB5ye"
      },
      "source": [
        "#I believe their model need an input size divisible by 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfdvae9ewyr-"
      },
      "source": [
        "siameseInception = SiameseInception()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCfRNIfHROLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb7d07c-3a57-4ef1-97dc-2db3cdff4eaa"
      },
      "source": [
        "model2 = siameseInception.get_model((3888,3888,4))\r\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 3888, 3888,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 3888, 3888,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "FEM (Functional)                ((None, 243, 243, 12 192048      input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 486, 486, 128 0           FEM[1][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "subtract_3 (Subtract)           (None, 486, 486, 128 0           FEM[0][4]                        \n",
            "                                                                 FEM[1][4]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 486, 486, 128 65664       up_sampling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 486, 486, 128 0           subtract_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 486, 486, 256 0           conv2d_transpose[0][0]           \n",
            "                                                                 lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 486, 486, 128 295040      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 486, 486, 128 0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 486, 486, 64) 73792       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 972, 972, 64) 0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "subtract_2 (Subtract)           (None, 972, 972, 64) 0           FEM[0][3]                        \n",
            "                                                                 FEM[1][3]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 972, 972, 64) 16448       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 972, 972, 64) 0           subtract_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 972, 972, 128 0           conv2d_transpose_1[0][0]         \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 972, 972, 64) 73792       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 972, 972, 32) 18464       conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 972, 972, 32) 0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 1944, 1944, 3 0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "subtract_1 (Subtract)           (None, 1944, 1944, 3 0           FEM[0][2]                        \n",
            "                                                                 FEM[1][2]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 1944, 1944, 3 4128        up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1944, 1944, 3 0           subtract_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 1944, 1944, 6 0           conv2d_transpose_2[0][0]         \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 1944, 1944, 3 18464       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 1944, 1944, 1 4624        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 1944, 1944, 1 0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 3888, 3888, 1 0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "subtract (Subtract)             (None, 3888, 3888, 1 0           FEM[0][1]                        \n",
            "                                                                 FEM[1][1]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 3888, 3888, 1 1040        up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 3888, 3888, 1 0           subtract[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 3888, 3888, 3 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 3888, 3888, 1 4624        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 3888, 3888, 1 145         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 3888, 3888)   0           conv2d_31[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 768,273\n",
            "Trainable params: 768,273\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW7hlrAWs4A0"
      },
      "source": [
        "input = (naip20133888,naip20173888)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9RCbzD8Gyk8"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFZX76r4lvfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343e7e88-5355-483b-e515-e88ab6b18e4d"
      },
      "source": [
        "t1 = time.time()\r\n",
        "out = model2.predict(input)\r\n",
        "print(time.time()-t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.057432651519775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8HHLQL5w_w8"
      },
      "source": [
        "Long training/inference time ~ 10 sec per 2 3880 3880 image on collab gpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTMnoL0Vs7mf",
        "outputId": "cc15b586-c8e4-424c-e1d1-4b373a5a08c3"
      },
      "source": [
        "np.shape(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3888, 3888)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}