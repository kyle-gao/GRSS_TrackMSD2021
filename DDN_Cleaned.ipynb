{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDN_Cleaned.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEzMsniFCTACClPL2U0B6j",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyle-gao/GRSS_TrackMSD2021/blob/main/DDN_Cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcdRBC3lFZvV"
      },
      "source": [
        "#https://github.com/GeoZcx/A-deeply-supervised-image-fusion-network-for-change-detection-in-remote-sensing-images"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4sAKIleU-pl"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import shutil\r\n",
        "import os\r\n",
        "from PIL import Image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYunA1z8FUVb"
      },
      "source": [
        "def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same',droprate=0.3):\r\n",
        "    x = tf.keras.layers.Conv2D(nb_filter, kernel_size, padding=padding, strides=strides,activation = 'relu')(x)\r\n",
        "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\r\n",
        "    x = tf.keras.layers.Dropout(rate = droprate)(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "def attach_attention_module(net, attention_module):\r\n",
        "    if attention_module == 'se_block':  # SE_block\r\n",
        "        net = se_block(net)\r\n",
        "    elif attention_module == 'cbam_block':  # CBAM_block\r\n",
        "        net = cbam_block(net)\r\n",
        "    else:\r\n",
        "        raise Exception(\"'{}' is not supported attention module!\".format(attention_module))\r\n",
        "\r\n",
        "    return net\r\n",
        "\r\n",
        "\r\n",
        "def se_block(input_feature, ratio=8):\r\n",
        "    \"\"\"Contains the implementation of Squeeze-and-Excitation(SE) block.\r\n",
        "    As described in https://arxiv.org/abs/1709.01507.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    channel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\r\n",
        "    channel = input_feature.shape[channel_axis]\r\n",
        "\r\n",
        "    se_feature = tf.keras.layers.GlobalAveragePooling2D()(input_feature)\r\n",
        "    se_feature = tf.keras.layers.Reshape((1, 1, channel))(se_feature)\r\n",
        "    assert se_feature.shape[1:] == (1, 1, channel)\r\n",
        "    se_feature = tf.keras.layers.Dense(channel // ratio,\r\n",
        "                       activation='relu',\r\n",
        "                       kernel_initializer='he_normal',\r\n",
        "                       use_bias=True,\r\n",
        "                       bias_initializer='zeros')(se_feature)\r\n",
        "    assert se_feature.shape[1:] == (1, 1, channel // ratio)\r\n",
        "    se_feature = tf.keras.layers.Dense(channel,\r\n",
        "                       activation='sigmoid',\r\n",
        "                       kernel_initializer='he_normal',\r\n",
        "                       use_bias=True,\r\n",
        "                       bias_initializer='zeros')(se_feature)\r\n",
        "    assert se_feature.shape[1:] == (1, 1, channel)\r\n",
        "    if tf.keras.backend.image_data_format() == 'channels_first':\r\n",
        "        se_feature = tf.keras.layers.Permute((3, 1, 2))(se_feature)\r\n",
        "\r\n",
        "    se_feature = input_feature*se_feature\r\n",
        "    return se_feature\r\n",
        "\r\n",
        "\r\n",
        "def cbam_block(cbam_feature, ratio=8):\r\n",
        "    \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block\r\n",
        "    As described in https://arxiv.org/abs/1807.06521.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    cbam_feature = channel_attention(cbam_feature, ratio)\r\n",
        "    cbam_feature = spatial_attention(cbam_feature)\r\n",
        "    return cbam_feature\r\n",
        "\r\n",
        "\r\n",
        "def channel_attention(input_feature, ratio=8):\r\n",
        "    channel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\r\n",
        "    channel = input_feature.shape[channel_axis]\r\n",
        "\r\n",
        "    shared_layer_one = tf.keras.layers.Dense(channel // ratio,\r\n",
        "                             activation='relu',\r\n",
        "                             kernel_initializer='he_normal',\r\n",
        "                             use_bias=True,\r\n",
        "                             bias_initializer='zeros')\r\n",
        "    shared_layer_two = tf.keras.layers.Dense(channel,\r\n",
        "                             kernel_initializer='he_normal',\r\n",
        "                             use_bias=True,\r\n",
        "                             bias_initializer='zeros')\r\n",
        "\r\n",
        "    avg_pool = tf.keras.layers.GlobalAveragePooling2D()(input_feature)\r\n",
        "    avg_pool = tf.keras.layers.Reshape((1, 1, channel))(avg_pool)\r\n",
        "    assert avg_pool.shape[1:] == (1, 1, channel)\r\n",
        "    avg_pool = shared_layer_one(avg_pool)\r\n",
        "    assert avg_pool.shape[1:] == (1, 1, channel // ratio)\r\n",
        "    avg_pool = shared_layer_two(avg_pool)\r\n",
        "    assert avg_pool.shape[1:] == (1, 1, channel)\r\n",
        "\r\n",
        "    max_pool = tf.keras.layers.GlobalMaxPooling2D()(input_feature)\r\n",
        "    max_pool = tf.keras.layers.Reshape((1, 1, channel))(max_pool)\r\n",
        "    assert max_pool.shape[1:] == (1, 1, channel)\r\n",
        "    max_pool = shared_layer_one(max_pool)\r\n",
        "    assert max_pool.shape[1:] == (1, 1, channel // ratio)\r\n",
        "    max_pool = shared_layer_two(max_pool)\r\n",
        "    assert max_pool.shape[1:] == (1, 1, channel)\r\n",
        "\r\n",
        "    cbam_feature = avg_pool + max_pool\r\n",
        "    cbam_feature = tf.keras.layers.Activation('sigmoid')(cbam_feature)\r\n",
        "\r\n",
        "    if tf.keras.backend.image_data_format() == \"channels_first\":\r\n",
        "        cbam_feature = tf.keras.layers.Permute((3, 1, 2))(cbam_feature)\r\n",
        "\r\n",
        "    return input_feature * cbam_feature\r\n",
        "\r\n",
        "\r\n",
        "def spatial_attention(input_feature):\r\n",
        "    kernel_size = 7\r\n",
        "\r\n",
        "    if tf.keras.backend.image_data_format() == \"channels_first\":\r\n",
        "        channel = input_feature.shape[1]\r\n",
        "        cbam_feature = tf.keras.layers.Permute((2, 3, 1))(input_feature)\r\n",
        "    else:\r\n",
        "        channel = input_feature.shape[-1]\r\n",
        "        cbam_feature = input_feature\r\n",
        "\r\n",
        "    avg_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert avg_pool.shape[-1] == 1\r\n",
        "    max_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.max(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert max_pool.shape[-1] == 1\r\n",
        "    concat = tf.keras.layers.Concatenate(axis=3)([avg_pool, max_pool])\r\n",
        "    assert concat.shape[-1] == 2\r\n",
        "    cbam_feature = tf.keras.layers.Conv2D(filters=1,\r\n",
        "                          kernel_size=kernel_size,\r\n",
        "                          strides=1,\r\n",
        "                          padding='same',\r\n",
        "                          activation='sigmoid',\r\n",
        "                          kernel_initializer='he_normal',\r\n",
        "                          use_bias=False)(concat)\r\n",
        "    assert cbam_feature.shape[-1] == 1\r\n",
        "\r\n",
        "    if tf.keras.backend.image_data_format() == \"channels_first\":\r\n",
        "        cbam_feature = tf.keras.layers.Permute((3, 1, 2))(cbam_feature)\r\n",
        "\r\n",
        "    return input_feature * cbam_feature\r\n",
        "\r\n",
        "\r\n",
        "def get_spatial_attention_map(input_feature):\r\n",
        "    kernel_size = 7\r\n",
        "    cbam_feature = input_feature\r\n",
        "\r\n",
        "    avg_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert avg_pool.shape[-1] == 1\r\n",
        "    max_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.max(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert max_pool.shape[-1] == 1\r\n",
        "    concat = tf.keras.layers.Concatenate(axis=3)([avg_pool, max_pool])\r\n",
        "    assert concat.shape[-1] == 2\r\n",
        "    cbam_feature = tf.keras.layers.Conv2D(filters=1,\r\n",
        "                          kernel_size=kernel_size,\r\n",
        "                          strides=1,\r\n",
        "                          padding='same',\r\n",
        "                          activation='sigmoid',\r\n",
        "                          kernel_initializer='he_normal',\r\n",
        "                          use_bias=False)(concat)\r\n",
        "    assert cbam_feature.shape[-1] == 1\r\n",
        "\r\n",
        "    if tf.keras.backend.image_data_format() == \"channels_first\":\r\n",
        "        cbam_feature = tf.keras.layers.Permute((3, 1, 2))(cbam_feature)\r\n",
        "\r\n",
        "    return cbam_feature"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbdAfEOxU5o4"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNSoIhZsWRpq",
        "outputId": "03ac742b-3d0c-44fb-8195-7f0b696e0053"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAVHeP8jW6yM"
      },
      "source": [
        "if not(os.path.isdir(\"/content/Kaggle_CoverChange\")):\r\n",
        "  shutil.unpack_archive(\"/content/drive/MyDrive/Kaggle_CoverChange.zip\",\"/content/\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtVych-nS5n5"
      },
      "source": [
        "data_dir = \"/content/Kaggle_CoverChange\"\r\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir+\"/im1/*\"),shuffle=False)\r\n",
        "#dataset is made up of strings\r\n",
        "oh_label = True\r\n",
        "out_list = True\r\n",
        "out_layers = 5\r\n",
        "concat_and_mask = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASeQSd7UwjPO"
      },
      "source": [
        "\r\n",
        "#classes = array([ 29.,  38.,  75.,  76., 128., 150., 255.])\r\n",
        "class_dict = {(29):1, (38):2, (75):3,(76):3,128:4,150:5,(255):0} #mapping 75 and 76 to same class, i'm assuming this is an encoding issue.\r\n",
        "\r\n",
        "def to_categorical(tensor,class_dict):\r\n",
        "  #maps pixel values to categories 1,2...num_classes\r\n",
        "  for k,v in class_dict.items():\r\n",
        "    tensor[tensor==k]=v\r\n",
        "  return tensor"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiwDCfO1j-3g"
      },
      "source": [
        "label1_fn = \"/content/Kaggle_CoverChange/label1/00003.png\"\r\n",
        "label1 = tf.keras.preprocessing.image.load_img(label1_fn,color_mode=\"grayscale\")\r\n",
        "label1 = tf.keras.preprocessing.image.img_to_array(label1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMQDMpk9p9FM"
      },
      "source": [
        "##Testing label change conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyb7mGzSxDXK"
      },
      "source": [
        "num_classes = 6"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sd3fkTBxlLh"
      },
      "source": [
        "##Need to convert 2 labels into 1 change label\r\n",
        "\r\n",
        "Trick: Let n be number of classes\r\n",
        "Step 1. Use an outer product between one_hot encoded labels\r\n",
        "(h,w,n),(h,w,n)->(h,w,n,n), this is gives a one hot encoded change matrix M.\r\n",
        "\r\n",
        "Eg. M = 0 except for Mij = 1 -> class i changed to class j.\r\n",
        "\r\n",
        "Step 2. Convert to categorical change -> (h,w,n,n)->(h,w,n^2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnWIcy96GeId",
        "outputId": "61f1cc5f-c0d8-4c2a-82a9-df3788d68b95"
      },
      "source": [
        "\"\"\"#converting (label1,label2)->(label changemap)\r\n",
        "#where change map has num_classes^2 (not all unique) change classes \r\n",
        "def make_label_change_dict(num_classes):\r\n",
        "  label_change_dict = {}\r\n",
        "  i = 0\r\n",
        "  for x in range(num_classes):\r\n",
        "    for y in range(num_classes):\r\n",
        "      label_change_dict[(x,y)] = i *(x!=y)\r\n",
        "      i += 1\r\n",
        "  return label_change_dict\r\n",
        "\r\n",
        "label_change_dict = make_label_change_dict(6)\r\n",
        "print(label_change_dict)\"\"\"\r\n",
        "\r\n",
        "#converting (label1,label2)->(label changemap)\r\n",
        "#where change map has num_classes^2 (not all unique) change classes \r\n",
        "def make_label_change_array(num_classes):\r\n",
        "  \"\"\"Arg:\r\n",
        "  num_classes:int, number of classes\r\n",
        "  returns:\r\n",
        "  num_classes^2 matrix of categorical change labels.\r\n",
        "  \"\"\"\r\n",
        "  label_change_arr = np.zeros((num_classes,num_classes),dtype=np.uint8)\r\n",
        "  i = 0\r\n",
        "  for x in range(num_classes):\r\n",
        "    for y in range(num_classes):\r\n",
        "      label_change_arr[x,y] = i *(x!=y)\r\n",
        "      i += 1\r\n",
        "  return label_change_arr\r\n",
        "\r\n",
        "label_change_arr = make_label_change_array(6)\r\n",
        "\r\n",
        "print(label_change_arr)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  0  8  9 10 11]\n",
            " [12 13  0 15 16 17]\n",
            " [18 19 20  0 22 23]\n",
            " [24 25 26 27  0 29]\n",
            " [30 31 32 33 34  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSTX_fohoYku"
      },
      "source": [
        "def get_class_change_label(before,after,label_change_arr):\r\n",
        "  \"\"\"\r\n",
        "  Input:\r\n",
        "  two np.array or tf.tensor of shape (batch,Width,Height, num_classes) corresponding to class labeled data in one hot encoding\r\n",
        "  the arrays represent the before and after class labels for change detection\r\n",
        "  Output:\r\n",
        "  a np.array of shape (batch,Width,Height) corresponding to change labels (see figure 2)\r\n",
        "  \"\"\"\r\n",
        "  labels_combined = np.einsum(\"abd,abe->abde\",before,after)\r\n",
        "  labels_combined = labels_combined*label_change_arr\r\n",
        "  labels_combined = np.sum(labels_combined, axis=(-1,-2))\r\n",
        "  return labels_combined"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP6H0-H8FkJQ"
      },
      "source": [
        "label1_fn = \"/content/Kaggle_CoverChange/label1/00018.png\"\r\n",
        "label2_fn = \"/content/Kaggle_CoverChange/label2/00018.png\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaPsT5RHIlCo"
      },
      "source": [
        "##Testing change label generation trick"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipkjfudFFiUW"
      },
      "source": [
        " \"\"\"   label1 = tf.keras.preprocessing.image.load_img(label1_fn, color_mode=\"grayscale\")\r\n",
        "    label1 = tf.keras.preprocessing.image.img_to_array(label1)\r\n",
        "    label1old = label1\r\n",
        "    label1 = to_categorical(label1,class_dict)\r\n",
        "    label1 = tf.expand_dims(label1,axis=0)\r\n",
        "    label1 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth = num_classes)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    label2 = tf.keras.preprocessing.image.load_img(label2_fn, color_mode =\"grayscale\")\r\n",
        "    label2 = tf.keras.preprocessing.image.img_to_array(label2)\r\n",
        "    label1old = label1\r\n",
        "    label2 = to_categorical(label2,class_dict)\r\n",
        "    label2 = tf.expand_dims(label2,axis=0)\r\n",
        "    label2old = label2\r\n",
        "    label2 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth=num_classes)\r\n",
        "\r\n",
        "    print(label1.shape)\r\n",
        "    print(label2.shape)\r\n",
        "    print(label1[0,300,300,:])\r\n",
        "    print(label2[0,300,300,:])\r\n",
        "    lc = np.einsum(\"abcd,abce->abcde\",label1,label2)\r\n",
        "\r\n",
        "    print(lc[0,300,300,:,:])\r\n",
        "    lc = lc * label_change_arr\r\n",
        "    print(lc[0,300,300,:,:])\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPl1JfAgIo3b"
      },
      "source": [
        "##Testing over"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J74OxNbF7kb"
      },
      "source": [
        "##Data processing\r\n",
        "\r\n",
        "*   Load as string dataset of filenames\r\n",
        "*   map get_item() to create dataset of (image1,image2, change labels)\r\n",
        "*   apply other pipeline steps (batching, shuffling, transformations)\r\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6pCJ-DdGc_n"
      },
      "source": [
        "Tricks:\r\n",
        "\r\n",
        "Creating 1 change map from 2 labels:\r\n",
        "\r\n",
        "\r\n",
        "*   one hot encode the labels\r\n",
        "*   use an outer produce to produce a one-hot change matrix\r\n",
        "*   flatten for one hot change matrix, or use broadcast a change_array see make_label_change_array\r\n",
        "*   convert to categorical as needed\r\n",
        "\r\n",
        "Creating 2 change maps from 2 change labels:\r\n",
        "\r\n",
        "\r\n",
        "*   one hot encode labels\r\n",
        "*   substract label 2 from label 1, l3 = l1-l2\r\n",
        "*   l3 == 1 correspond to elements removed from label 1\r\n",
        "*   l3 == -1 correspond to elements added by label 2\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooE716J8bpnx"
      },
      "source": [
        "def get_item(path):\r\n",
        "  \"\"\"\r\n",
        "  returns 3 tensors when called in a dataset.map\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  #wrap function in tf.numpy_function() or tf.data.dataset.map bugs out\r\n",
        "\r\n",
        "  def _get_item(path):\r\n",
        "    \"\"\"\r\n",
        "    args:\r\n",
        "    path: Dataset.list_file dataset element\r\n",
        "\r\n",
        "    returns: \r\n",
        "    (h,w,3),(h,w,1),(h,w,3),(h,w,1) image-label 4-tuple in tf.float32 tf.Tensor\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    fn = tf.strings.split(path,\"/\")\r\n",
        "    base_dir = tf.strings.join(fn[:-2],separator=\"/\")\r\n",
        "\r\n",
        "    image1_fn = (base_dir+\"/im1/\"+fn[-1]).numpy()\r\n",
        "    image2_fn = (base_dir+\"/im2/\"+fn[-1]).numpy()\r\n",
        "\r\n",
        "    label1_fn = (base_dir+\"/label1/\"+fn[-1]).numpy()\r\n",
        "    label2_fn = (base_dir+\"/label2/\"+fn[-1]).numpy()\r\n",
        "\r\n",
        "    #label1_fn = \"/content/Kaggle_CoverChange/label1/00018.png\"\r\n",
        "    #label2_fn = \"/content/Kaggle_CoverChange/label2/00018.png\"\r\n",
        "\r\n",
        "\r\n",
        "    image1 = tf.keras.preprocessing.image.load_img(image1_fn)\r\n",
        "    image1 = tf.keras.preprocessing.image.img_to_array(image1)\r\n",
        "\r\n",
        "    image2 = tf.keras.preprocessing.image.load_img(image2_fn)\r\n",
        "    image2 = tf.keras.preprocessing.image.img_to_array(image2)\r\n",
        "\r\n",
        "    label1 = tf.keras.preprocessing.image.load_img(label1_fn, color_mode=\"grayscale\")\r\n",
        "    label1 = tf.keras.preprocessing.image.img_to_array(label1)\r\n",
        "    label1 = to_categorical(label1,class_dict)\r\n",
        "    #label1 = tf.expand_dims(label1,axis=0)\r\n",
        "\r\n",
        "    label1 = tf.one_hot(tf.cast(label1[:,:,0],dtype = tf.uint8),depth = num_classes)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    label2 = tf.keras.preprocessing.image.load_img(label2_fn, color_mode =\"grayscale\")\r\n",
        "    label2 = tf.keras.preprocessing.image.img_to_array(label2)\r\n",
        "    label2 = to_categorical(label2,class_dict)\r\n",
        "    #label2 = tf.expand_dims(label2,axis=0)\r\n",
        "\r\n",
        "    label2 = tf.one_hot(tf.cast(label2[:,:,0],dtype = tf.uint8),depth=num_classes)\r\n",
        "\r\n",
        "    change_label = get_class_change_label(label1,label2,label_change_arr=label_change_arr)\r\n",
        "    \r\n",
        "    if oh_label:\r\n",
        "      change_label = tf.one_hot(tf.cast(change_label[:,:],dtype = tf.uint8),depth=num_classes**2-1)\r\n",
        "    else:\r\n",
        "      change_label = tf.expand_dims(change_label, axis=-1)\r\n",
        "    \"\"\"\r\n",
        "    #doesn't work, errors on backend when passing datasets from list of tensors of different size\r\n",
        "    if out_list:\r\n",
        "      y_list = [change_label]\r\n",
        "      change_label = tf.expand_dims(change_label,axis=0)\r\n",
        "      for i in range(out_layers):\r\n",
        "        \r\n",
        "        change_label = tf.keras.layers.MaxPool2D()(change_label)\r\n",
        "        y_list.append(change_label.numpy()[0,:,:,:])\r\n",
        "      change_label = tf.ragged.constant(y_list)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    #classes = array([ 29.,  38.,  75.,  76., 128., 150., 255.])\r\n",
        "    #(h,w,1) tensor of int from 1-6\r\n",
        "    \r\n",
        "\r\n",
        "    return image1,image2,change_label\r\n",
        "\r\n",
        "  output = tf.numpy_function(_get_item,[path],[tf.float32,tf.float32,tf.float32])\r\n",
        "\r\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOMt8H9bN19L"
      },
      "source": [
        "def two_labels_to_twochanges(l1,l2):\r\n",
        "  \"\"\"\r\n",
        "  args:\r\n",
        "  l1,l2 one_hot encoded labels\r\n",
        "  returns: l3, l4, mask: one_hot encoded labels of changes and change mask\r\n",
        "  eg (categorical version) : if at a pixel p :\r\n",
        "   l1 == 1, l2 == 1 => l3 = 0, l4 = 0\r\n",
        "   but instead\r\n",
        "   l1 == 1, l2 == 2 => l3 = 1, l4 = 2\r\n",
        "  \"\"\"\r\n",
        "  lmixed = l1 - l2\r\n",
        "  l3 = lmixed == 1 \r\n",
        "  l4 = lmixed == -1\r\n",
        "  mask = lmixed != 0\r\n",
        "  return l3, l4\r\n",
        "\r\n",
        "def get_item2(path):\r\n",
        "  \"\"\"\r\n",
        "  returns 4 tensors: image1,image2, (label1,label2), change mask\r\n",
        "  when called inside a dataset.map\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  #wrap function in tf.numpy_function() or tf.data.dataset.map bugs out\r\n",
        "\r\n",
        "  def _get_item2(path):\r\n",
        "    \"\"\"\r\n",
        "    args:\r\n",
        "    path: Dataset.list_file dataset element\r\n",
        "\r\n",
        "    returns: \r\n",
        "    (h,w,3),(h,w,1),(h,w,3),(h,w,1) image-label 4-tuple in tf.float32 tf.Tensor\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    fn = tf.strings.split(path,\"/\")\r\n",
        "    base_dir = tf.strings.join(fn[:-2],separator=\"/\")\r\n",
        "\r\n",
        "    image1_fn = (base_dir+\"/im1/\"+fn[-1]).numpy()\r\n",
        "    image2_fn = (base_dir+\"/im2/\"+fn[-1]).numpy()\r\n",
        "\r\n",
        "    label1_fn = (base_dir+\"/label1/\"+fn[-1]).numpy()\r\n",
        "    label2_fn = (base_dir+\"/label2/\"+fn[-1]).numpy()\r\n",
        "\r\n",
        "    #label1_fn = \"/content/Kaggle_CoverChange/label1/00018.png\"\r\n",
        "    #label2_fn = \"/content/Kaggle_CoverChange/label2/00018.png\"\r\n",
        "\r\n",
        "\r\n",
        "    image1 = tf.keras.preprocessing.image.load_img(image1_fn)\r\n",
        "    image1 = tf.keras.preprocessing.image.img_to_array(image1)\r\n",
        "\r\n",
        "    image2 = tf.keras.preprocessing.image.load_img(image2_fn)\r\n",
        "    image2 = tf.keras.preprocessing.image.img_to_array(image2)\r\n",
        "\r\n",
        "    label1 = tf.keras.preprocessing.image.load_img(label1_fn, color_mode=\"grayscale\")\r\n",
        "    label1 = tf.keras.preprocessing.image.img_to_array(label1)\r\n",
        "    label1 = to_categorical(label1,class_dict)\r\n",
        "    #label1 = tf.expand_dims(label1,axis=0)\r\n",
        "    label1 = tf.one_hot(tf.cast(label1[:,:,0],dtype = tf.uint8),depth = num_classes)\r\n",
        "\r\n",
        "\r\n",
        "    label2 = tf.keras.preprocessing.image.load_img(label2_fn, color_mode =\"grayscale\")\r\n",
        "    label2 = tf.keras.preprocessing.image.img_to_array(label2)\r\n",
        "    label2 = to_categorical(label2,class_dict)\r\n",
        "    #label2 = tf.expand_dims(label2,axis=0)\r\n",
        "    label2 = tf.one_hot(tf.cast(label2[:,:,0],dtype = tf.uint8),depth=num_classes)\r\n",
        "\r\n",
        "    label1,label2 = two_labels_to_twochanges(label1,label2) #(1,H,W,num_classes)\r\n",
        "    \r\n",
        "\r\n",
        "    if not(oh_label):\r\n",
        "      label1 = tf.argmax(label1, axis=-1,output_type=tf.int32)\r\n",
        "      label1 = tf.expand_dims(label1,axis=-1)\r\n",
        "      label2 = tf.argmax(label2, axis=-1,output_type=tf.int32)\r\n",
        "      label2 = tf.expand_dims(label2,axis=-1)\r\n",
        "\r\n",
        "    change_label = tf.concat([label1,label2],axis=-1) #(1,512,512, 2*num_class) if one_hot, (1,512,512,2) otherwise\r\n",
        "    change_mask = change_label != 0\r\n",
        "    change_mask = tf.cast(change_mask,tf.int32)\r\n",
        "      \r\n",
        "    \"\"\"\r\n",
        "    #doesn't work, errors on backend when passing datasets from list of tensors of different size\r\n",
        "    if out_list:\r\n",
        "      y_list = [change_label]\r\n",
        "      change_label = tf.expand_dims(change_label,axis=0)\r\n",
        "      for i in range(out_layers):\r\n",
        "        \r\n",
        "        change_label = tf.keras.layers.MaxPool2D()(change_label)\r\n",
        "        y_list.append(change_label.numpy()[0,:,:,:])\r\n",
        "      change_label = tf.ragged.constant(y_list)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    #classes = array([ 29.,  38.,  75.,  76., 128., 150., 255.])\r\n",
        "    #(h,w,1) tensor of int from 1-6\r\n",
        "    \r\n",
        "\r\n",
        "    return image1,image2,change_label,change_mask\r\n",
        "\r\n",
        "  output = tf.numpy_function(_get_item2,[path],[tf.float32,tf.float32,tf.int32,tf.int32])\r\n",
        "\r\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT3E2boXh6fa"
      },
      "source": [
        "def transform(x1,x2,y):\r\n",
        "  \"\"\"\r\n",
        "  Write your data transformations here\r\n",
        "  \"\"\"\r\n",
        "  x1=tf.keras.layers.experimental.preprocessing.Rescaling(1./255.0)(x1)\r\n",
        "  x2=tf.keras.layers.experimental.preprocessing.Rescaling(1./255.0)(x2)\r\n",
        "  #y=tf.one_hot(tf.cast(y[:,:,0],dtype = tf.int32),depth = 7)\r\n",
        "  \"\"\"\r\n",
        "  if out_list:\r\n",
        "    y_list = [y]\r\n",
        "    for i in range(out_layers):\r\n",
        "      y = tf.keras.layers.MaxPool2D()(y)\r\n",
        "      y_list.append(y)\r\n",
        "    y = tf.ragged.constant(y_list)\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "\r\n",
        "  return x1,x2,y\r\n",
        "\r\n",
        "def transform2(x1,x2,y1,y2):\r\n",
        "  \"\"\"\r\n",
        "  Write your data transformations here\r\n",
        "  \"\"\"\r\n",
        "  x1=tf.keras.layers.experimental.preprocessing.Rescaling(1./255.0)(x1)\r\n",
        "  x2=tf.keras.layers.experimental.preprocessing.Rescaling(1./255.0)(x2)\r\n",
        "  #y=tf.one_hot(tf.cast(y[:,:,0],dtype = tf.int32),depth = 7)\r\n",
        "  \"\"\"\r\n",
        "  if out_list:\r\n",
        "    y_list = [y]\r\n",
        "    for i in range(out_layers):\r\n",
        "      y = tf.keras.layers.MaxPool2D()(y)\r\n",
        "      y_list.append(y)\r\n",
        "    y = tf.ragged.constant(y_list)\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "\r\n",
        "  return x1,x2,y1,y2\r\n",
        "\r\n",
        "def preprocessing(list_ds,batch_size=8,augmentation=transform):\r\n",
        "  \"\"\"\r\n",
        "  applies some preprocessing\r\n",
        "  args:\r\n",
        "  list_ds-Dataset.list_files dataset object\r\n",
        "  batch_size-int \r\n",
        "  augmentation-a function (x,y)->(x,y)\r\n",
        "  returns-batched dataset\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  #ds = list_ds.cache() \r\n",
        "  if concat_and_mask:\r\n",
        "    ds = list_ds.map(get_item2,num_parallel_calls=tf.data.AUTOTUNE) \r\n",
        "    ds = ds.batch(batch_size,drop_remainder=True)\r\n",
        "    ds = ds.shuffle(100)\r\n",
        "\r\n",
        "    if augmentation:\r\n",
        "      ds = ds.map((lambda x1,x2,y1,y2 : augmentation(x1,x2,y1,y2)),num_parallel_calls=tf.data.AUTOTUNE)\r\n",
        "      \r\n",
        "  else:\r\n",
        "    ds = list_ds.map(get_item,num_parallel_calls=tf.data.AUTOTUNE) \r\n",
        "    ds = ds.batch(batch_size,drop_remainder=True)\r\n",
        "    ds = ds.shuffle(100)\r\n",
        "    if augmentation:\r\n",
        "      ds = ds.map((lambda x,y,z : augmentation(x,y,z)),num_parallel_calls=tf.data.AUTOTUNE)\r\n",
        "      \r\n",
        "\r\n",
        "\r\n",
        "  \r\n",
        "  ds = ds.prefetch(tf.data.AUTOTUNE)\r\n",
        "  return ds\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu4qpWMq6guQ"
      },
      "source": [
        "#load pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1jzSEkZ4YZW"
      },
      "source": [
        "if not(os.path.isdir(\"/content/Drive/Saved_Model/\")):\r\n",
        "  shutil.unpack_archive(\"/content/drive/MyDrive/vgg_512_seg_model.zip\",\"/content/Drive/Saved_Model/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtrhDcrsZM3u"
      },
      "source": [
        "##Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm7aDD4m6pIK"
      },
      "source": [
        "\"\"\"\r\n",
        "vgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\r\n",
        "vgg16_512.summary()\r\n",
        "\r\n",
        "feature_layers = [vgg16_512.get_layer(\"features_c1\"),vgg16_512.get_layer(\"features_c2\"),vgg16_512.get_layer('features_c3'),vgg16_512.get_layer('features_c4'),vgg16_512.get_layer('features_c5')]\r\n",
        "feature_extractor = tf.keras.models.Model(inputs = vgg16_512.input, outputs = [layer.output for layer in feature_layers])\r\n",
        "\r\n",
        "test_tensor = tf.random.normal((1,512,512,3))\r\n",
        "test_out = feature_extractor(test_tensor)\r\n",
        "for t in test_out:\r\n",
        "  print(t.shape)\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2mdKpIkXsl4"
      },
      "source": [
        "#DDN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBfmi39zGBYO"
      },
      "source": [
        "#vgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\r\n",
        "#vgg16_512.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eiduk23cFPBz"
      },
      "source": [
        "def DDN (imsize, num_classes = 6):\r\n",
        "    #if input image 512*512\r\n",
        "\r\n",
        "    vgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\r\n",
        "\r\n",
        "    image1 = tf.keras.layers.Input((imsize,imsize,3),name = \"image1\")\r\n",
        "    image2 = tf.keras.layers.Input((imsize,imsize,3),name = \"image2\")\r\n",
        "\r\n",
        "    feature_layers = [vgg16_512.get_layer(\"features_c1\"),vgg16_512.get_layer(\"features_c2\"),vgg16_512.get_layer('features_c3'),vgg16_512.get_layer('features_c4'),vgg16_512.get_layer('features_c5')]\r\n",
        "    feature_extractor = tf.keras.models.Model(inputs = vgg16_512.input, outputs = [layer.output for layer in feature_layers],trainable=False)\r\n",
        "\r\n",
        "    features_1 = feature_extractor(image1)\r\n",
        "    features_2 = feature_extractor(image2)\r\n",
        "\r\n",
        "    t1_b5c3 = features_1[4] #(None, 32, 32, 512)\r\n",
        "    t2_b5c3 = features_2[4] \r\n",
        "\r\n",
        "    t1_b4c3 = features_1[3] #(None, 64, 64, 512)\r\n",
        "    t2_b4c3 = features_2[3] \r\n",
        "    \r\n",
        "    t1_b3c3 = features_1[2] #(None, 128, 128, 256)  \r\n",
        "    t2_b3c3 = features_2[2]\r\n",
        "\r\n",
        "    t1_b2c2 = features_1[1]\r\n",
        "    t2_b2c2 = features_2[1] #(None, 256, 256, 128) \r\n",
        "\r\n",
        "    t1_b1c2 = features_1[0]\r\n",
        "    t2_b1c2 = features_2[0] #(None, 512, 512, 64)\r\n",
        "\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    pair5 = tf.keras.layers.Input((imsize,imsize,64*2), name='pair5') #rbg images concatenated channel-wise\r\n",
        "    pair4 = tf.keras.layers.Input((imsize//2,imsize//2,128*2), name='pair4')\r\n",
        "    pair3 = tf.keras.layers.Input((imsize//4,imsize//4,256*2), name='pair3')\r\n",
        "    pair2 = tf.keras.layers.Input((imsize//8,imsize//8,512*2), name='pair2')\r\n",
        "    pair1 = tf.keras.layers.Input((imsize//16,imsize//16,512*2), name='pair1')\r\n",
        "\r\n",
        "\r\n",
        "    t1_b5c3 = pair1[:,:,:,:3] #(None, 32, 32, 512)\r\n",
        "    t2_b5c3 = pair1[:,:,:,3:] \r\n",
        "\r\n",
        "    t1_b4c3 = pair2[:,:,:,:3] #(None, 64, 64, 512)\r\n",
        "    t2_b4c3 = pair2[:,:,:,3:] \r\n",
        "    \r\n",
        "    t1_b3c3 = pair3[:,:,:,:3] #(None, 128, 128, 256)  \r\n",
        "    t2_b3c3 = pair3[:,:,:,3:]\r\n",
        "\r\n",
        "    t1_b2c2 = pair4[:,:,:,:3]\r\n",
        "    t2_b2c2 = pair4[:,:,:,3:] #(None, 256, 256, 128) \r\n",
        "\r\n",
        "    t1_b1c2 = pair5[:,:,:,:3]\r\n",
        "    t2_b1c2 = pair5[:,:,:,3:] #(None, 512, 512, 64)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    concat_b5c3 = tf.keras.layers.concatenate([t1_b5c3, t2_b5c3], axis=3) #channel 1024\r\n",
        "    x = Conv2d_BN(concat_b5c3,256, 3)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    attention_map_1 = get_spatial_attention_map(x)\r\n",
        "    x = x * attention_map_1\r\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche1\r\n",
        "    branch_1 =tf.keras.layers.Conv2D(num_classes**2-1, kernel_size=3, padding='same',name='output_32')(x)\r\n",
        "\r\n",
        "    x = tf.keras.layers.Conv2DTranspose(imsize, kernel_size=5, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = tf.keras.layers.concatenate([x,t1_b4c3,t2_b4c3],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,256,3)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x,64,3)\r\n",
        "    attention_map_2 = get_spatial_attention_map(x)\r\n",
        "    x = x *attention_map_2\r\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche2\r\n",
        "    branch_2 =tf.keras.layers.Conv2D(num_classes**2-1, kernel_size=3, padding='same',name='output_64')(x)\r\n",
        "\r\n",
        "    x = tf.keras.layers.Conv2DTranspose(256, kernel_size=5, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = tf.keras.layers.concatenate([x,t1_b3c3,t2_b3c3],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,256,3)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x, 64, 3)\r\n",
        "    attention_map_3 = get_spatial_attention_map(x)\r\n",
        "    x = x * attention_map_3\r\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche3\r\n",
        "    branch_3 =tf.keras.layers.Conv2D(num_classes**2-1, kernel_size=3, padding='same',name='output_128')(x)\r\n",
        "\r\n",
        "    x = tf.keras.layers.Conv2DTranspose(128, kernel_size=5, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = tf.keras.layers.concatenate([x,t1_b2c2,t2_b2c2],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x,64,3)\r\n",
        "    x = Conv2d_BN(x, 64, 3)\r\n",
        "    attention_map_4 = get_spatial_attention_map(x)\r\n",
        "    x = x * attention_map_4\r\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche4\r\n",
        "    branch_4 =tf.keras.layers.Conv2D(num_classes**2-1, kernel_size=3, padding='same',name='output_256')(x)\r\n",
        "\r\n",
        "    x = tf.keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = tf.keras.layers.concatenate([x,t1_b1c2,t2_b1c2],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,64,3)\r\n",
        "    x = Conv2d_BN(x,64,3)\r\n",
        "    x = Conv2d_BN(x, 64, 3)\r\n",
        "    attention_map_5 = get_spatial_attention_map(x)\r\n",
        "    x = x * attention_map_5\r\n",
        "\r\n",
        "    # branche5\r\n",
        "    branch_5 =tf.keras.layers.Conv2D(num_classes**2-1, kernel_size=3, padding='same',name='output_imsize')(x)\r\n",
        "\r\n",
        "    DDN = tf.keras.models.Model(inputs=[image1,image2], outputs=[branch_5,branch_4,branch_3,branch_2,branch_1])\r\n",
        "\r\n",
        "    return DDN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NykWcUcQzdFh"
      },
      "source": [
        "#TEST\r\n",
        "\"\"\"\r\n",
        "imsize = 512\r\n",
        "image1 = tf.random.normal((1,512,512,3))\r\n",
        "image2 = tf.random.normal((1,512,512,3))\r\n",
        "ddn = DDN(512,6)\r\n",
        "forward = ddn([image1,image2])\r\n",
        "for f in forward:\r\n",
        "  print (f.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-ihDr4C1Siz"
      },
      "source": [
        "ddn = DDN(512,6)\r\n",
        "ddn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq-Zv5CyrHv8"
      },
      "source": [
        "#Defining loss and metrics\r\n",
        "Using Pooling layers to reduce target image size for deep supervision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yyXEEYvvHLP"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n",
        "  def __init__(self, warmup_steps=20, base_lr=0.01):\r\n",
        "    super(CustomSchedule, self).__init__()\r\n",
        "\r\n",
        "    self.base_lr = base_lr\r\n",
        "    self.warmup_steps = tf.cast(warmup_steps,tf.float32)\r\n",
        "\r\n",
        "  def __call__(self, step):\r\n",
        "    step = tf.cast(step,tf.float32)\r\n",
        "    lr = self.base_lr\r\n",
        "    if step>800:\r\n",
        "      step = 800\r\n",
        "\r\n",
        "    power = (step//100)\r\n",
        "    lr = lr*10**(-power)\r\n",
        "    \r\n",
        "\r\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzc1BlTz1e2h"
      },
      "source": [
        "lr_schedule = CustomSchedule(base_lr = 0.03)\r\n",
        "lr_schedule = 1e-5\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "if oh_label:\r\n",
        "  entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.AUTO)#adds a softmax step\r\n",
        "  train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\r\n",
        "else: \r\n",
        "  entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.AUTO)\r\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6Vvb_cHn_py"
      },
      "source": [
        "class_weights = np.ones((512,512,num_classes**2-1))\r\n",
        "class_weights[:,:,0]= 1/3 #class 0 corresponds to no change"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Prq0Baoj7go"
      },
      "source": [
        "def dice_loss (y_true,y_pred,eps = 1e-5,num_classes=6):\r\n",
        "  #y_true = y_true[:,:,:,0]\r\n",
        "  y_pred = tf.nn.softmax(y_pred)\r\n",
        "  \r\n",
        "  #y_pred = tf.argmax(y_pred,axis=-1)\r\n",
        "  #y_true = tf.one_hot(tf.cast(y_true,dtype = tf.uint8),depth = num_classes**2-1)\r\n",
        "  return tf.math.reduce_mean(1 - (2*y_true*y_pred)/(y_true + y_pred + eps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vEs-8owu17E"
      },
      "source": [
        "def DS_loss_fn(y_true, y_pred, loss_function = entropy, layer_weights=[3,1,1,1,1],class_weights = tf.ones((35))):\r\n",
        "  \"\"\"\r\n",
        "  Deep supervision loss\r\n",
        "  Args:\r\n",
        "  y_true-one hot encoded ground truth (n,H,W,n_classes^2-1)\r\n",
        "  y_pred-list of predictions [imsize,imsize/2,imsize/4,imsize/8,imsize/16]\r\n",
        "  loss_function = tf.keras loss function object\r\n",
        "  layer_weights = list of 5 int\r\n",
        "  class_weights = list of int broadcastable to y_true\r\n",
        "  \"\"\"\r\n",
        "  loss = 0\r\n",
        "  if oh_label:\r\n",
        "    y_true = y_true * class_weights\r\n",
        "  for i in range(len(layer_weights)):\r\n",
        "\r\n",
        "    #loss = loss+ tf.math.reduce_mean(layer_weights[i]*loss_function(y_true,y_pred[i]) + layer_weights[i]*dice_loss (y_true, y_pred[i]))\r\n",
        "    #loss = loss+ tf.math.reduce_mean(layer_weights[i]*dice_loss (y_true, y_pred[i]))\r\n",
        "    loss = loss+ layer_weights[i]*loss_function(y_true,y_pred[i])\r\n",
        "    y_true = tf.keras.layers.MaxPool2D()(y_true) \r\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkhs4ADRxhHz"
      },
      "source": [
        "##Test\r\n",
        "\"\"\"\r\n",
        "y_pred = ddn([test_im1,test_im2])\r\n",
        "DS_loss_fn(test_label,y_pred)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oROkWaB5Xkc"
      },
      "source": [
        "save_path = \"/content/Saved_Models/\"\r\n",
        "if not(os.path.isdir(save_path)):\r\n",
        "  os.mkdir(save_path)\r\n",
        "batch_size = 1\r\n",
        "epochs = 1\r\n",
        "model_savename=\"DDN_test\"\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_AGOK7XX_zP"
      },
      "source": [
        "##Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgV2c02ZYBL1"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiNvwCo1ZCGY"
      },
      "source": [
        "# Clear any logs from previous runs\r\n",
        "!rm -rf ./logs/\r\n",
        "\r\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\r\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\r\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\r\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRCCKxl1m6Ce"
      },
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC4h4OtgmOzb"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghw4WCcT2Bj5"
      },
      "source": [
        "steps_per_epoch = 2968//batch_size + 1\r\n",
        "class_weights = np.ones((num_classes**2-1))\r\n",
        "class_weights[0] = 1/6\r\n",
        "if concat_and_mask:\r\n",
        "  train_ds = preprocessing(list_ds, batch_size = batch_size,augmentation=transform2)\r\n",
        "else:\r\n",
        "  train_ds = preprocessing(list_ds, batch_size = batch_size,augmentation=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMbCYpDAevrd"
      },
      "source": [
        "#a = list(train_ds.take(1))[0]\r\n",
        "#plt.imshow(a[2][0,:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f25-qBMU6mo"
      },
      "source": [
        "#for t in a:\r\n",
        "#  print(t.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEi3c6JDYw3i"
      },
      "source": [
        "#plt.imshow(a[3][0,:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxYTCxlVnmQt"
      },
      "source": [
        "#ddn.fit(train_ds,epochs = 3, shuffle=False, use_multiprocessing=True,workers= tf.data.AUTOTUNE,callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnBa8Y1tf7Yv"
      },
      "source": [
        "train_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siMws5f85j3T"
      },
      "source": [
        "for epoch in range(epochs):\r\n",
        "\r\n",
        "  train_loss.reset_states()\r\n",
        "  train_accuracy.reset_states()\r\n",
        "\r\n",
        "  print(\"Start of epoch {}\".format(epoch))\r\n",
        "\r\n",
        "  for step, (im1,im2,label) in enumerate(train_ds):\r\n",
        "\r\n",
        "    step = step + epoch*steps_per_epoch\r\n",
        "\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "\r\n",
        "      y_pred = ddn([im1,im2],training=True)\r\n",
        "      loss_value = DS_loss_fn(label,y_pred,class_weights=class_weights)\r\n",
        "      \r\n",
        "    train_accuracy.update_state(label,y_pred[0]) \r\n",
        "    train_loss.update_state(loss_value) \r\n",
        "    \r\n",
        "    with train_summary_writer.as_default():\r\n",
        "      tf.summary.scalar('loss', train_loss.result(), step=step)\r\n",
        "      tf.summary.scalar('accuracy', train_accuracy.result(), step=step)\r\n",
        "      \r\n",
        "\r\n",
        "    grads = tape.gradient(loss_value,ddn.trainable_weights)\r\n",
        "    optimizer.apply_gradients(zip(grads,ddn.trainable_weights))\r\n",
        "\r\n",
        "    if step % 100== 0:\r\n",
        "      print(\"Training loss: {}\".format(train_loss.result()))\r\n",
        "      \r\n",
        "      print (\"Training accuracy: {}\".format(train_accuracy.result()))\r\n",
        "      print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\r\n",
        "      print(\"Current LR: {}\".format(optimizer.learning_rate(step)))\r\n",
        "            \r\n",
        "  ddn.save('saved_model/{}'.format(model_savename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OUGLTcEqvsa"
      },
      "source": [
        "%tensorboard --logdir logs/gradient_tape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hetEJHtahK9M"
      },
      "source": [
        "#shutil.make_archive(\"/content/DDN_test\",'zip',\"/content/saved_model/DDN_test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POwIyVrPr1H_"
      },
      "source": [
        "#shutil.copy2(\"/content/DDN_test.zip\",\"/content/drive/MyDrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yduFItI2-0L"
      },
      "source": [
        "test = list(train_ds.take(1))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtF6l3AB3DJm"
      },
      "source": [
        "test_im1 = test[0]\r\n",
        "test_im2 = test[1]\r\n",
        "test_label = test[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ5wWeGG3GT7"
      },
      "source": [
        "plt.imshow(test_label[0,:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGEX38St3aIM"
      },
      "source": [
        "test_predict = ddn.predict([test_im1,test_im2])[0]\r\n",
        "test_predict = tf.argmax(test_predict,axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC42USIt3mf-"
      },
      "source": [
        "plt.imshow(test_predict[0,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA5bquNrlDWC"
      },
      "source": [
        "test_predict = tf.expand_dims(test_predict,axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBntvRmPkVFM"
      },
      "source": [
        "test_predict.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "end6AguyktbO"
      },
      "source": [
        "test_label.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b1OQ7ahkMte"
      },
      "source": [
        "acc(test_label,test_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVz6hOSW2SjN"
      },
      "source": [
        "!tensorboard dev upload \\\r\n",
        "  --logdir logs/gradient_tape \\\r\n",
        "  --name \"DDN 2 epochs cat_entropy loss\" \\\r\n",
        "  --description \"Custom LR sqrt schedule\" \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrmPEAf4IqiT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}