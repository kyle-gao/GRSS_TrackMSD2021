{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DDN_Cleaned.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNPFlLhFd1IDXjtf7Z/1ROY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyle-gao/GRSS_TrackMSD2021/blob/main/DDN_Cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcdRBC3lFZvV"
      },
      "source": [
        "#https://github.com/GeoZcx/A-deeply-supervised-image-fusion-network-for-change-detection-in-remote-sensing-images"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4sAKIleU-pl"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import shutil\r\n",
        "import os\r\n",
        "from PIL import Image"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYunA1z8FUVb"
      },
      "source": [
        "def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same',droprate=0.3):\r\n",
        "    x = tf.keras.layers.Conv2D(nb_filter, kernel_size, padding=padding, strides=strides,activation = 'relu')(x)\r\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\r\n",
        "    x = tf.keras.layers.Dropout(rate = droprate)(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "def attach_attention_module(net, attention_module):\r\n",
        "    if attention_module == 'se_block':  # SE_block\r\n",
        "        net = se_block(net)\r\n",
        "    elif attention_module == 'cbam_block':  # CBAM_block\r\n",
        "        net = cbam_block(net)\r\n",
        "    else:\r\n",
        "        raise Exception(\"'{}' is not supported attention module!\".format(attention_module))\r\n",
        "\r\n",
        "    return net\r\n",
        "\r\n",
        "\r\n",
        "def se_block(input_feature, ratio=8):\r\n",
        "    \"\"\"Contains the implementation of Squeeze-and-Excitation(SE) block.\r\n",
        "    As described in https://arxiv.org/abs/1709.01507.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    channel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\r\n",
        "    channel = input_feature.shape[channel_axis]\r\n",
        "\r\n",
        "    se_feature = tf.keras.layers.GlobalAveragePooling2D()(input_feature)\r\n",
        "    se_feature = tf.keras.layers.Reshape((1, 1, channel))(se_feature)\r\n",
        "    assert se_feature.shape[1:] == (1, 1, channel)\r\n",
        "    se_feature = tf.keras.layers.Dense(channel // ratio,\r\n",
        "                       activation='relu',\r\n",
        "                       kernel_initializer='he_normal',\r\n",
        "                       use_bias=True,\r\n",
        "                       bias_initializer='zeros')(se_feature)\r\n",
        "    assert se_feature.shape[1:] == (1, 1, channel // ratio)\r\n",
        "    se_feature = tf.keras.layers.Dense(channel,\r\n",
        "                       activation='sigmoid',\r\n",
        "                       kernel_initializer='he_normal',\r\n",
        "                       use_bias=True,\r\n",
        "                       bias_initializer='zeros')(se_feature)\r\n",
        "    assert se_feature.shape[1:] == (1, 1, channel)\r\n",
        "    if tf.keras.backend.image_data_format() == 'channels_first':\r\n",
        "        se_feature = tf.keras.layers.Permute((3, 1, 2))(se_feature)\r\n",
        "\r\n",
        "    se_feature = input_feature*se_feature\r\n",
        "    return se_feature\r\n",
        "\r\n",
        "\r\n",
        "def cbam_block(cbam_feature, ratio=8):\r\n",
        "    \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block\r\n",
        "    As described in https://arxiv.org/abs/1807.06521.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    cbam_feature = channel_attention(cbam_feature, ratio)\r\n",
        "    cbam_feature = spatial_attention(cbam_feature)\r\n",
        "    return cbam_feature\r\n",
        "\r\n",
        "\r\n",
        "def channel_attention(input_feature, ratio=8):\r\n",
        "    channel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\r\n",
        "    channel = input_feature.shape[channel_axis]\r\n",
        "\r\n",
        "    shared_layer_one = tf.keras.layers.Dense(channel // ratio,\r\n",
        "                             activation='relu',\r\n",
        "                             kernel_initializer='he_normal',\r\n",
        "                             use_bias=True,\r\n",
        "                             bias_initializer='zeros')\r\n",
        "    shared_layer_two = tf.keras.layers.Dense(channel,\r\n",
        "                             kernel_initializer='he_normal',\r\n",
        "                             use_bias=True,\r\n",
        "                             bias_initializer='zeros')\r\n",
        "\r\n",
        "    avg_pool = tf.keras.layers.GlobalAveragePooling2D()(input_feature)\r\n",
        "    avg_pool = tf.keras.layers.Reshape((1, 1, channel))(avg_pool)\r\n",
        "    assert avg_pool.shape[1:] == (1, 1, channel)\r\n",
        "    avg_pool = shared_layer_one(avg_pool)\r\n",
        "    assert avg_pool.shape[1:] == (1, 1, channel // ratio)\r\n",
        "    avg_pool = shared_layer_two(avg_pool)\r\n",
        "    assert avg_pool.shape[1:] == (1, 1, channel)\r\n",
        "\r\n",
        "    max_pool = tf.keras.layers.GlobalMaxPooling2D()(input_feature)\r\n",
        "    max_pool = tf.keras.layers.Reshape((1, 1, channel))(max_pool)\r\n",
        "    assert max_pool.shape[1:] == (1, 1, channel)\r\n",
        "    max_pool = shared_layer_one(max_pool)\r\n",
        "    assert max_pool.shape[1:] == (1, 1, channel // ratio)\r\n",
        "    max_pool = shared_layer_two(max_pool)\r\n",
        "    assert max_pool.shape[1:] == (1, 1, channel)\r\n",
        "\r\n",
        "    cbam_feature = avg_pool + max_pool\r\n",
        "    cbam_feature = tf.keras.layers.Activation('sigmoid')(cbam_feature)\r\n",
        "\r\n",
        "    if tf.keras.backend.image_data_format() == \"channels_first\":\r\n",
        "        cbam_feature = tf.keras.layers.Permute((3, 1, 2))(cbam_feature)\r\n",
        "\r\n",
        "    return input_feature * cbam_feature\r\n",
        "\r\n",
        "\r\n",
        "def spatial_attention(input_feature):\r\n",
        "    kernel_size = 7\r\n",
        "\r\n",
        "    if tf.keras.backend.image_data_format() == \"channels_first\":\r\n",
        "        channel = input_feature.shape[1]\r\n",
        "        cbam_feature = tf.keras.layers.Permute((2, 3, 1))(input_feature)\r\n",
        "    else:\r\n",
        "        channel = input_feature.shape[-1]\r\n",
        "        cbam_feature = input_feature\r\n",
        "\r\n",
        "    avg_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert avg_pool.shape[-1] == 1\r\n",
        "    max_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.max(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert max_pool.shape[-1] == 1\r\n",
        "    concat = tf.keras.layers.Concatenate(axis=3)([avg_pool, max_pool])\r\n",
        "    assert concat.shape[-1] == 2\r\n",
        "    cbam_feature = tf.keras.layers.Conv2D(filters=1,\r\n",
        "                          kernel_size=kernel_size,\r\n",
        "                          strides=1,\r\n",
        "                          padding='same',\r\n",
        "                          activation='sigmoid',\r\n",
        "                          kernel_initializer='he_normal',\r\n",
        "                          use_bias=False)(concat)\r\n",
        "    assert cbam_feature.shape[-1] == 1\r\n",
        "\r\n",
        "    if tf.keras.backend.image_data_format() == \"channels_first\":\r\n",
        "        cbam_feature = tf.keras.layers.Permute((3, 1, 2))(cbam_feature)\r\n",
        "\r\n",
        "    return input_feature * cbam_feature\r\n",
        "\r\n",
        "\r\n",
        "def get_spatial_attention_map(input_feature):\r\n",
        "    kernel_size = 7\r\n",
        "    cbam_feature = input_feature\r\n",
        "\r\n",
        "    avg_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert avg_pool.shape[-1] == 1\r\n",
        "    max_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.max(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert max_pool.shape[-1] == 1\r\n",
        "    concat = tf.keras.layers.Concatenate(axis=3)([avg_pool, max_pool])\r\n",
        "    assert concat.shape[-1] == 2\r\n",
        "    cbam_feature = tf.keras.layers.Conv2D(filters=1,\r\n",
        "                          kernel_size=kernel_size,\r\n",
        "                          strides=1,\r\n",
        "                          padding='same',\r\n",
        "                          activation='sigmoid',\r\n",
        "                          kernel_initializer='he_normal',\r\n",
        "                          use_bias=False)(concat)\r\n",
        "    assert cbam_feature.shape[-1] == 1\r\n",
        "\r\n",
        "    if tf.keras.backend.image_data_format() == \"channels_first\":\r\n",
        "        cbam_feature = tf.keras.layers.Permute((3, 1, 2))(cbam_feature)\r\n",
        "\r\n",
        "    return cbam_feature"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbdAfEOxU5o4"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNSoIhZsWRpq",
        "outputId": "192ecd8d-9c27-4c1a-b20c-3405276a24bf"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAVHeP8jW6yM"
      },
      "source": [
        "if not(os.path.isdir(\"/content/Kaggle_CoverChange\")):\r\n",
        "  shutil.unpack_archive(\"/content/drive/MyDrive/Kaggle_CoverChange.zip\",\"/content/\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtVych-nS5n5"
      },
      "source": [
        "data_dir = \"/content/Kaggle_CoverChange\"\r\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir+\"/im1/*\"),shuffle=False)\r\n",
        "#dataset is made up of strings"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASeQSd7UwjPO"
      },
      "source": [
        "\r\n",
        "#classes = array([ 29.,  38.,  75.,  76., 128., 150., 255.])\r\n",
        "class_dict = {(29):1, (38):2, (75):3,(76):3,128:4,150:5,(255):0} #mapping 75 and 76 to same class, i'm assuming this is an encoding issue.\r\n",
        "\r\n",
        "def to_categorical(tensor,class_dict):\r\n",
        "  #maps pixel values to categories 1,2...num_classes\r\n",
        "  for k,v in class_dict.items():\r\n",
        "    tensor[tensor==k]=v\r\n",
        "  return tensor"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiwDCfO1j-3g"
      },
      "source": [
        "label1_fn = \"/content/Kaggle_CoverChange/label1/00003.png\"\r\n",
        "label1 = tf.keras.preprocessing.image.load_img(label1_fn,color_mode=\"grayscale\")\r\n",
        "label1 = tf.keras.preprocessing.image.img_to_array(label1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMQDMpk9p9FM"
      },
      "source": [
        "##Testing label change conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyb7mGzSxDXK"
      },
      "source": [
        "num_classes = 6"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sd3fkTBxlLh"
      },
      "source": [
        "##Need to convert 2 labels into 1 change label\r\n",
        "\r\n",
        "Trick: Let n be number of classes\r\n",
        "Step 1. Use an outer product between one_hot encoded labels\r\n",
        "(h,w,n),(h,w,n)->(h,w,n,n), this is gives a one hot encoded change matrix M.\r\n",
        "\r\n",
        "Eg. M = 0 except for Mij = 1 -> class i changed to class j.\r\n",
        "\r\n",
        "Step 2. Convert to categorical change -> (h,w,n,n)->(h,w,n^2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnWIcy96GeId",
        "outputId": "ba4c6a13-59d2-482a-9461-17684a6a3b03"
      },
      "source": [
        "\"\"\"#converting (label1,label2)->(label changemap)\r\n",
        "#where change map has num_classes^2 (not all unique) change classes \r\n",
        "def make_label_change_dict(num_classes):\r\n",
        "  label_change_dict = {}\r\n",
        "  i = 0\r\n",
        "  for x in range(num_classes):\r\n",
        "    for y in range(num_classes):\r\n",
        "      label_change_dict[(x,y)] = i *(x!=y)\r\n",
        "      i += 1\r\n",
        "  return label_change_dict\r\n",
        "\r\n",
        "label_change_dict = make_label_change_dict(6)\r\n",
        "print(label_change_dict)\"\"\"\r\n",
        "\r\n",
        "#converting (label1,label2)->(label changemap)\r\n",
        "#where change map has num_classes^2 (not all unique) change classes \r\n",
        "def make_label_change_array(num_classes):\r\n",
        "  \"\"\"Arg:\r\n",
        "  num_classes:int, number of classes\r\n",
        "  returns:\r\n",
        "  num_classes^2 matrix of categorical change labels.\r\n",
        "  \"\"\"\r\n",
        "  label_change_arr = np.zeros((num_classes,num_classes),dtype=np.uint8)\r\n",
        "  i = 0\r\n",
        "  for x in range(num_classes):\r\n",
        "    for y in range(num_classes):\r\n",
        "      label_change_arr[x,y] = i *(x!=y)\r\n",
        "      i += 1\r\n",
        "  return label_change_arr\r\n",
        "\r\n",
        "label_change_arr = make_label_change_array(6)\r\n",
        "\r\n",
        "print(label_change_arr)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  0  8  9 10 11]\n",
            " [12 13  0 15 16 17]\n",
            " [18 19 20  0 22 23]\n",
            " [24 25 26 27  0 29]\n",
            " [30 31 32 33 34  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSTX_fohoYku"
      },
      "source": [
        "def get_class_change_label(before,after,label_change_arr):\r\n",
        "  \"\"\"\r\n",
        "  Input:\r\n",
        "  two np.array or tf.tensor of shape (batch,Width,Height, num_classes) corresponding to class labeled data in one hot encoding\r\n",
        "  the arrays represent the before and after class labels for change detection\r\n",
        "  Output:\r\n",
        "  a np.array of shape (batch,Width,Height) corresponding to change labels (see figure 2)\r\n",
        "  \"\"\"\r\n",
        "  labels_combined = np.einsum(\"abd,abe->abde\",before,after)\r\n",
        "  labels_combined = labels_combined*label_change_arr\r\n",
        "  labels_combined = np.sum(labels_combined, axis=(-1,-2))\r\n",
        "  return labels_combined"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP6H0-H8FkJQ"
      },
      "source": [
        "label1_fn = \"/content/Kaggle_CoverChange/label1/00018.png\"\r\n",
        "label2_fn = \"/content/Kaggle_CoverChange/label2/00018.png\""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaPsT5RHIlCo"
      },
      "source": [
        "##Testing change label generation trick"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "ipkjfudFFiUW",
        "outputId": "c08e89f6-e125-44bb-b284-3919dbd82fd8"
      },
      "source": [
        " \"\"\"   label1 = tf.keras.preprocessing.image.load_img(label1_fn, color_mode=\"grayscale\")\r\n",
        "    label1 = tf.keras.preprocessing.image.img_to_array(label1)\r\n",
        "    label1old = label1\r\n",
        "    label1 = to_categorical(label1,class_dict)\r\n",
        "    label1 = tf.expand_dims(label1,axis=0)\r\n",
        "    label1 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth = num_classes)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    label2 = tf.keras.preprocessing.image.load_img(label2_fn, color_mode =\"grayscale\")\r\n",
        "    label2 = tf.keras.preprocessing.image.img_to_array(label2)\r\n",
        "    label1old = label1\r\n",
        "    label2 = to_categorical(label2,class_dict)\r\n",
        "    label2 = tf.expand_dims(label2,axis=0)\r\n",
        "    label2old = label2\r\n",
        "    label2 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth=num_classes)\r\n",
        "\r\n",
        "    print(label1.shape)\r\n",
        "    print(label2.shape)\r\n",
        "    print(label1[0,300,300,:])\r\n",
        "    print(label2[0,300,300,:])\r\n",
        "    lc = np.einsum(\"abcd,abce->abcde\",label1,label2)\r\n",
        "\r\n",
        "    print(lc[0,300,300,:,:])\r\n",
        "    lc = lc * label_change_arr\r\n",
        "    print(lc[0,300,300,:,:])\"\"\""
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'   label1 = tf.keras.preprocessing.image.load_img(label1_fn, color_mode=\"grayscale\")\\n   label1 = tf.keras.preprocessing.image.img_to_array(label1)\\n   label1old = label1\\n   label1 = to_categorical(label1,class_dict)\\n   label1 = tf.expand_dims(label1,axis=0)\\n   label1 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth = num_classes)\\n\\n\\n\\n\\n   label2 = tf.keras.preprocessing.image.load_img(label2_fn, color_mode =\"grayscale\")\\n   label2 = tf.keras.preprocessing.image.img_to_array(label2)\\n   label1old = label1\\n   label2 = to_categorical(label2,class_dict)\\n   label2 = tf.expand_dims(label2,axis=0)\\n   label2old = label2\\n   label2 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth=num_classes)\\n\\n   print(label1.shape)\\n   print(label2.shape)\\n   print(label1[0,300,300,:])\\n   print(label2[0,300,300,:])\\n   lc = np.einsum(\"abcd,abce->abcde\",label1,label2)\\n\\n   print(lc[0,300,300,:,:])\\n   lc = lc * label_change_arr\\n   print(lc[0,300,300,:,:])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPl1JfAgIo3b"
      },
      "source": [
        "##Testing over"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooE716J8bpnx"
      },
      "source": [
        "def get_item(path):\r\n",
        "\r\n",
        "  #wrap function in tf.numpy_function() or tf.data.dataset.map bugs out\r\n",
        "\r\n",
        "  def _get_item(path):\r\n",
        "    \"\"\"\r\n",
        "    args:\r\n",
        "    path: Dataset.list_file dataset element\r\n",
        "\r\n",
        "    returns: \r\n",
        "    (h,w,3),(h,w,1),(h,w,3),(h,w,1) image-label 4-tuple in tf.float32 tf.Tensor\r\n",
        "    \"\"\"\r\n",
        "    oh_label = False\r\n",
        "    fn = tf.strings.split(path,\"/\")\r\n",
        "    base_dir = tf.strings.join(fn[:-2],separator=\"/\")\r\n",
        "\r\n",
        "    image1_fn = (base_dir+\"/im1/\"+fn[-1]).numpy()\r\n",
        "    image2_fn = (base_dir+\"/im2/\"+fn[-1]).numpy()\r\n",
        "\r\n",
        "    label1_fn = (base_dir+\"/label1/\"+fn[-1]).numpy()\r\n",
        "    label2_fn = (base_dir+\"/label2/\"+fn[-1]).numpy()\r\n",
        "\r\n",
        "    #label1_fn = \"/content/Kaggle_CoverChange/label1/00018.png\"\r\n",
        "    #label2_fn = \"/content/Kaggle_CoverChange/label2/00018.png\"\r\n",
        "\r\n",
        "\r\n",
        "    image1 = tf.keras.preprocessing.image.load_img(image1_fn)\r\n",
        "    image1 = tf.keras.preprocessing.image.img_to_array(image1)\r\n",
        "\r\n",
        "    image2 = tf.keras.preprocessing.image.load_img(image2_fn)\r\n",
        "    image2 = tf.keras.preprocessing.image.img_to_array(image2)\r\n",
        "\r\n",
        "    label1 = tf.keras.preprocessing.image.load_img(label1_fn, color_mode=\"grayscale\")\r\n",
        "    label1 = tf.keras.preprocessing.image.img_to_array(label1)\r\n",
        "    label1 = to_categorical(label1,class_dict)\r\n",
        "    #label1 = tf.expand_dims(label1,axis=0)\r\n",
        "\r\n",
        "    label1 = tf.one_hot(tf.cast(label1[:,:,0],dtype = tf.uint8),depth = num_classes)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    label2 = tf.keras.preprocessing.image.load_img(label2_fn, color_mode =\"grayscale\")\r\n",
        "    label2 = tf.keras.preprocessing.image.img_to_array(label2)\r\n",
        "    label2 = to_categorical(label2,class_dict)\r\n",
        "    #label2 = tf.expand_dims(label2,axis=0)\r\n",
        "\r\n",
        "    label2 = tf.one_hot(tf.cast(label2[:,:,0],dtype = tf.uint8),depth=num_classes)\r\n",
        "\r\n",
        "    change_label = get_class_change_label(label1,label2,label_change_arr=label_change_arr)\r\n",
        "    \r\n",
        "    if oh_label:\r\n",
        "      change_label = tf.one_hot(tf.cast(change_label[:,:],dtype = tf.uint8),depth=num_classes**2-1)\r\n",
        "    else:\r\n",
        "      change_label = tf.expand_dims(change_label, axis=-1)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    #classes = array([ 29.,  38.,  75.,  76., 128., 150., 255.])\r\n",
        "    #(h,w,1) tensor of int from 1-6\r\n",
        "\r\n",
        "    return image1,image2,change_label\r\n",
        "\r\n",
        "  output = tf.numpy_function(_get_item,[path],[tf.float32,tf.float32,tf.float32])\r\n",
        "\r\n",
        "  return output"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT3E2boXh6fa"
      },
      "source": [
        "def transform(x1,x2,y):\r\n",
        "  \"\"\"\r\n",
        "  Write your data transformations here\r\n",
        "  \"\"\"\r\n",
        "  x1=tf.keras.layers.experimental.preprocessing.Rescaling(1./255.0)(x1)\r\n",
        "  x2=tf.keras.layers.experimental.preprocessing.Rescaling(1./255.0)(x2)\r\n",
        "  #y=tf.one_hot(tf.cast(y[:,:,0],dtype = tf.int32),depth = 7)\r\n",
        "\r\n",
        "  return x1,x2,y\r\n",
        "def preprocessing(list_ds,batch_size=8,augmentation=transform):\r\n",
        "  \"\"\"\r\n",
        "  applies some preprocessing\r\n",
        "  args:\r\n",
        "  list_ds-Dataset.list_files dataset object\r\n",
        "  batch_size-int \r\n",
        "  augmentation-a function (x,y)->(x,y)\r\n",
        "  returns-batched dataset\r\n",
        "  \"\"\"\r\n",
        "  #ds = list_ds.cache() \r\n",
        "  ds = list_ds.map(get_item,num_parallel_calls=tf.data.AUTOTUNE) \r\n",
        "  ds = ds.batch(batch_size,drop_remainder=True)\r\n",
        "  ds = ds.shuffle(100)\r\n",
        "\r\n",
        "  if augmentation:\r\n",
        "    ds = ds.map((lambda x,y,z : augmentation(x,y,z)),num_parallel_calls=tf.data.AUTOTUNE)\r\n",
        "\r\n",
        "  \r\n",
        "  ds = ds.prefetch(tf.data.AUTOTUNE)\r\n",
        "  return ds\r\n",
        "\r\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu4qpWMq6guQ"
      },
      "source": [
        "#load pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1jzSEkZ4YZW"
      },
      "source": [
        "if not(os.path.isdir(\"/content/Drive/Saved_Model/\")):\r\n",
        "  shutil.unpack_archive(\"/content/drive/MyDrive/vgg_512_seg_model.zip\",\"/content/Drive/Saved_Model/\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtrhDcrsZM3u"
      },
      "source": [
        "##Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "pm7aDD4m6pIK",
        "outputId": "9d8dfe09-36e6-4e7d-c9b8-9d251d8d8e65"
      },
      "source": [
        "\"\"\"\r\n",
        "vgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\r\n",
        "vgg16_512.summary()\r\n",
        "\r\n",
        "feature_layers = [vgg16_512.get_layer(\"features_c1\"),vgg16_512.get_layer(\"features_c2\"),vgg16_512.get_layer('features_c3'),vgg16_512.get_layer('features_c4'),vgg16_512.get_layer('features_c5')]\r\n",
        "feature_extractor = tf.keras.models.Model(inputs = vgg16_512.input, outputs = [layer.output for layer in feature_layers])\r\n",
        "\r\n",
        "test_tensor = tf.random.normal((1,512,512,3))\r\n",
        "test_out = feature_extractor(test_tensor)\r\n",
        "for t in test_out:\r\n",
        "  print(t.shape)\r\n",
        "\"\"\""
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nvgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\\nvgg16_512.summary()\\n\\nfeature_layers = [vgg16_512.get_layer(\"features_c1\"),vgg16_512.get_layer(\"features_c2\"),vgg16_512.get_layer(\\'features_c3\\'),vgg16_512.get_layer(\\'features_c4\\'),vgg16_512.get_layer(\\'features_c5\\')]\\nfeature_extractor = tf.keras.models.Model(inputs = vgg16_512.input, outputs = [layer.output for layer in feature_layers])\\n\\ntest_tensor = tf.random.normal((1,512,512,3))\\ntest_out = feature_extractor(test_tensor)\\nfor t in test_out:\\n  print(t.shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2mdKpIkXsl4"
      },
      "source": [
        "#DDN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBfmi39zGBYO"
      },
      "source": [
        "#vgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\r\n",
        "#vgg16_512.summary()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eiduk23cFPBz"
      },
      "source": [
        "def DDN (imsize, num_classes = 6):\r\n",
        "    #if input image 512*512\r\n",
        "\r\n",
        "    vgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\r\n",
        "\r\n",
        "    image1 = tf.keras.layers.Input((imsize,imsize,3),name = \"image1\")\r\n",
        "    image2 = tf.keras.layers.Input((imsize,imsize,3),name = \"image2\")\r\n",
        "\r\n",
        "    feature_layers = [vgg16_512.get_layer(\"features_c1\"),vgg16_512.get_layer(\"features_c2\"),vgg16_512.get_layer('features_c3'),vgg16_512.get_layer('features_c4'),vgg16_512.get_layer('features_c5')]\r\n",
        "    feature_extractor = tf.keras.models.Model(inputs = vgg16_512.input, outputs = [layer.output for layer in feature_layers],trainable=True)\r\n",
        "\r\n",
        "    features_1 = feature_extractor(image1)\r\n",
        "    features_2 = feature_extractor(image2)\r\n",
        "\r\n",
        "    t1_b5c3 = features_1[4] #(None, 32, 32, 512)\r\n",
        "    t2_b5c3 = features_2[4] \r\n",
        "\r\n",
        "    t1_b4c3 = features_1[3] #(None, 64, 64, 512)\r\n",
        "    t2_b4c3 = features_2[3] \r\n",
        "    \r\n",
        "    t1_b3c3 = features_1[2] #(None, 128, 128, 256)  \r\n",
        "    t2_b3c3 = features_2[2]\r\n",
        "\r\n",
        "    t1_b2c2 = features_1[1]\r\n",
        "    t2_b2c2 = features_2[1] #(None, 256, 256, 128) \r\n",
        "\r\n",
        "    t1_b1c2 = features_1[0]\r\n",
        "    t2_b1c2 = features_2[0] #(None, 512, 512, 64)\r\n",
        "\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    pair5 = tf.keras.layers.Input((imsize,imsize,64*2), name='pair5') #rbg images concatenated channel-wise\r\n",
        "    pair4 = tf.keras.layers.Input((imsize//2,imsize//2,128*2), name='pair4')\r\n",
        "    pair3 = tf.keras.layers.Input((imsize//4,imsize//4,256*2), name='pair3')\r\n",
        "    pair2 = tf.keras.layers.Input((imsize//8,imsize//8,512*2), name='pair2')\r\n",
        "    pair1 = tf.keras.layers.Input((imsize//16,imsize//16,512*2), name='pair1')\r\n",
        "\r\n",
        "\r\n",
        "    t1_b5c3 = pair1[:,:,:,:3] #(None, 32, 32, 512)\r\n",
        "    t2_b5c3 = pair1[:,:,:,3:] \r\n",
        "\r\n",
        "    t1_b4c3 = pair2[:,:,:,:3] #(None, 64, 64, 512)\r\n",
        "    t2_b4c3 = pair2[:,:,:,3:] \r\n",
        "    \r\n",
        "    t1_b3c3 = pair3[:,:,:,:3] #(None, 128, 128, 256)  \r\n",
        "    t2_b3c3 = pair3[:,:,:,3:]\r\n",
        "\r\n",
        "    t1_b2c2 = pair4[:,:,:,:3]\r\n",
        "    t2_b2c2 = pair4[:,:,:,3:] #(None, 256, 256, 128) \r\n",
        "\r\n",
        "    t1_b1c2 = pair5[:,:,:,:3]\r\n",
        "    t2_b1c2 = pair5[:,:,:,3:] #(None, 512, 512, 64)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    concat_b5c3 = tf.keras.layers.concatenate([t1_b5c3, t2_b5c3], axis=3) #channel 1024\r\n",
        "    x = Conv2d_BN(concat_b5c3,256, 3)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    attention_map_1 = get_spatial_attention_map(x)\r\n",
        "    x = x * attention_map_1\r\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche1\r\n",
        "    branch_1 =tf.keras.layers.Conv2D(num_classes**2-1, kernel_size=1, padding='same',name='output_32')(x)\r\n",
        "\r\n",
        "    x = tf.keras.layers.Conv2DTranspose(imsize, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = tf.keras.layers.concatenate([x,t1_b4c3,t2_b4c3],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,256,3)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x,64,3)\r\n",
        "    attention_map_2 = get_spatial_attention_map(x)\r\n",
        "    x = x *attention_map_2\r\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche2\r\n",
        "    branch_2 =tf.keras.layers.Conv2D(num_classes**2-1, kernel_size=1, padding='same',name='output_64')(x)\r\n",
        "\r\n",
        "    x = tf.keras.layers.Conv2DTranspose(256, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = tf.keras.layers.concatenate([x,t1_b3c3,t2_b3c3],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,256,3)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x, 64, 3)\r\n",
        "    attention_map_3 = get_spatial_attention_map(x)\r\n",
        "    x = x * attention_map_3\r\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche3\r\n",
        "    branch_3 =tf.keras.layers.Conv2D(num_classes**2-1, kernel_size=1, padding='same',name='output_128')(x)\r\n",
        "\r\n",
        "    x = tf.keras.layers.Conv2DTranspose(128, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = tf.keras.layers.concatenate([x,t1_b2c2,t2_b2c2],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x,64,3)\r\n",
        "    x = Conv2d_BN(x, 32, 3)\r\n",
        "    attention_map_4 = get_spatial_attention_map(x)\r\n",
        "    x = x * attention_map_4\r\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche4\r\n",
        "    branch_4 =tf.keras.layers.Conv2D(num_classes**2-1, kernel_size=1, padding='same',name='output_256')(x)\r\n",
        "\r\n",
        "    x = tf.keras.layers.Conv2DTranspose(64, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = tf.keras.layers.concatenate([x,t1_b1c2,t2_b1c2],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,64,3)\r\n",
        "    x = Conv2d_BN(x,32,3)\r\n",
        "    x = Conv2d_BN(x, 16, 3)\r\n",
        "    attention_map_5 = get_spatial_attention_map(x)\r\n",
        "    x = x * attention_map_5\r\n",
        "\r\n",
        "    # branche5\r\n",
        "    branch_5 =tf.keras.layers.Conv2D(num_classes**2-1, kernel_size=1, padding='same',name='output_imsize')(x)\r\n",
        "\r\n",
        "    DDN = tf.keras.models.Model(inputs=[image1,image2], outputs=[branch_5,branch_4,branch_3,branch_2,branch_1])\r\n",
        "\r\n",
        "    return DDN"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "NykWcUcQzdFh",
        "outputId": "20595d01-1a37-47db-9e4c-a3390b00c76c"
      },
      "source": [
        "#TEST\r\n",
        "\"\"\"\r\n",
        "imsize = 512\r\n",
        "image1 = tf.random.normal((1,512,512,3))\r\n",
        "image2 = tf.random.normal((1,512,512,3))\r\n",
        "ddn = DDN(512,6)\r\n",
        "forward = ddn([image1,image2])\r\n",
        "for f in forward:\r\n",
        "  print (f.shape)\"\"\""
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimsize = 512\\nimage1 = tf.random.normal((1,512,512,3))\\nimage2 = tf.random.normal((1,512,512,3))\\nddn = DDN(512,6)\\nforward = ddn([image1,image2])\\nfor f in forward:\\n  print (f.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-ihDr4C1Siz",
        "outputId": "1719d440-a11d-461d-ad81-e4e416de3410"
      },
      "source": [
        "ddn = DDN(512,6)\r\n",
        "ddn.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "image1 (InputLayer)             [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "image2 (InputLayer)             [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_4 (Functional)            [(None, 512, 512, 64 14714688    image1[0][0]                     \n",
            "                                                                 image2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 1024) 0           model_4[0][4]                    \n",
            "                                                                 model_4[1][4]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 256)  2359552     concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 128)  295040      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 32, 32, 1)    0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 32, 32, 1)    0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 2)    0           lambda_8[0][0]                   \n",
            "                                                                 lambda_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 1)    98          concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply (TFOpLambda)   (None, 32, 32, 128)  0           dropout_9[0][0]                  \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 128)  512         tf.math.multiply[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 64, 64, 512)  262656      batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 64, 64, 1536) 0           conv2d_transpose[0][0]           \n",
            "                                                                 model_4[0][3]                    \n",
            "                                                                 model_4[1][3]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1536)         0           concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 1536)         0           concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 1, 1, 1536)   0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 1536)   0           global_max_pooling2d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1, 1, 192)    295104      reshape[0][0]                    \n",
            "                                                                 reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1, 1, 1536)   296448      dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 1, 1, 1536)   0           dense_1[0][0]                    \n",
            "                                                                 dense_1[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 1, 1, 1536)   0           tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_1 (TFOpLambda) (None, 64, 64, 1536) 0           concatenate_10[0][0]             \n",
            "                                                                 activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 64, 64, 256)  3539200     tf.math.multiply_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 64, 64, 256)  1024        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 64, 64, 256)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 128)  295040      dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 64, 64, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 64, 64, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 64, 64, 64)   73792       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 64, 64, 1)    0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, 64, 64, 1)    0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 64, 64, 2)    0           lambda_10[0][0]                  \n",
            "                                                                 lambda_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 64, 64, 1)    98          concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_2 (TFOpLambda) (None, 64, 64, 64)   0           dropout_12[0][0]                 \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         tf.math.multiply_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 256 65792       batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 128, 128, 768 0           conv2d_transpose_1[0][0]         \n",
            "                                                                 model_4[0][2]                    \n",
            "                                                                 model_4[1][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 768)          0           concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_1 (GlobalM (None, 768)          0           concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 1, 1, 768)    0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 1, 1, 768)    0           global_max_pooling2d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1, 1, 96)     73824       reshape_2[0][0]                  \n",
            "                                                                 reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1, 1, 768)    74496       dense_2[0][0]                    \n",
            "                                                                 dense_2[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 1, 1, 768)    0           dense_3[0][0]                    \n",
            "                                                                 dense_3[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 1, 1, 768)    0           tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_3 (TFOpLambda) (None, 128, 128, 768 0           concatenate_12[0][0]             \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 128, 128, 256 1769728     tf.math.multiply_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 128, 128, 256 1024        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 128, 128, 256 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 128, 128, 128 295040      dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 128, 128, 128 512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 128, 128, 128 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 128, 128, 64) 73792       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 128, 128, 64) 256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 128, 128, 64) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_12 (Lambda)              (None, 128, 128, 1)  0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 128, 128, 1)  0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 128, 128, 2)  0           lambda_12[0][0]                  \n",
            "                                                                 lambda_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 128, 128, 1)  98          concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_4 (TFOpLambda) (None, 128, 128, 64) 0           dropout_15[0][0]                 \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 128, 128, 64) 256         tf.math.multiply_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 128 32896       batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 256, 256, 384 0           conv2d_transpose_2[0][0]         \n",
            "                                                                 model_4[0][1]                    \n",
            "                                                                 model_4[1][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 384)          0           concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_2 (GlobalM (None, 384)          0           concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 1, 1, 384)    0           global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 1, 1, 384)    0           global_max_pooling2d_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1, 1, 48)     18480       reshape_4[0][0]                  \n",
            "                                                                 reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1, 1, 384)    18816       dense_4[0][0]                    \n",
            "                                                                 dense_4[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 1, 1, 384)    0           dense_5[0][0]                    \n",
            "                                                                 dense_5[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 1, 1, 384)    0           tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_5 (TFOpLambda) (None, 256, 256, 384 0           concatenate_14[0][0]             \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 256, 256, 128 442496      tf.math.multiply_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 256, 256, 128 512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 256, 256, 128 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 256, 256, 64) 73792       dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 256, 256, 64) 256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 256, 256, 64) 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 256, 256, 32) 18464       dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 256, 256, 32) 128         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 256, 256, 32) 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_14 (Lambda)              (None, 256, 256, 1)  0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_15 (Lambda)              (None, 256, 256, 1)  0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 256, 256, 2)  0           lambda_14[0][0]                  \n",
            "                                                                 lambda_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 256, 256, 1)  98          concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_6 (TFOpLambda) (None, 256, 256, 32) 0           dropout_18[0][0]                 \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 256, 256, 32) 128         tf.math.multiply_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 512, 512, 64) 8256        batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 512, 512, 192 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 model_4[0][0]                    \n",
            "                                                                 model_4[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 192)          0           concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_3 (GlobalM (None, 192)          0           concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 1, 1, 192)    0           global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_7 (Reshape)             (None, 1, 1, 192)    0           global_max_pooling2d_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1, 1, 24)     4632        reshape_6[0][0]                  \n",
            "                                                                 reshape_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1, 1, 192)    4800        dense_6[0][0]                    \n",
            "                                                                 dense_6[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 1, 1, 192)    0           dense_7[0][0]                    \n",
            "                                                                 dense_7[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1, 1, 192)    0           tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_7 (TFOpLambda) (None, 512, 512, 192 0           concatenate_16[0][0]             \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 512, 512, 64) 110656      tf.math.multiply_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 512, 512, 64) 256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 512, 512, 64) 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 512, 512, 32) 18464       dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 512, 512, 32) 128         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 512, 512, 32) 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 512, 512, 16) 4624        dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 512, 512, 16) 64          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 512, 512, 16) 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_16 (Lambda)              (None, 512, 512, 1)  0           dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_17 (Lambda)              (None, 512, 512, 1)  0           dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 512, 512, 2)  0           lambda_16[0][0]                  \n",
            "                                                                 lambda_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 512, 512, 1)  98          concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_8 (TFOpLambda) (None, 512, 512, 16) 0           dropout_21[0][0]                 \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "output_imsize (Conv2D)          (None, 512, 512, 35) 595         tf.math.multiply_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "output_256 (Conv2D)             (None, 256, 256, 35) 1155        batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "output_128 (Conv2D)             (None, 128, 128, 35) 2275        batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "output_64 (Conv2D)              (None, 64, 64, 35)   2275        batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "output_32 (Conv2D)              (None, 32, 32, 35)   4515        batch_normalization_10[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 25,259,489\n",
            "Trainable params: 25,255,681\n",
            "Non-trainable params: 3,808\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq-Zv5CyrHv8"
      },
      "source": [
        "#Defining loss and metrics\r\n",
        "Using Pooling layers to reduce target image size for deep supervision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yyXEEYvvHLP"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n",
        "  def __init__(self, warmup_steps=100, base_lr=0.01):\r\n",
        "    super(CustomSchedule, self).__init__()\r\n",
        "\r\n",
        "    self.base_lr = base_lr\r\n",
        "    self.warmup_steps = tf.cast(warmup_steps,tf.float32)\r\n",
        "\r\n",
        "  def __call__(self, step):\r\n",
        "    step = tf.cast(step,tf.float32)\r\n",
        "    arg1 = tf.math.rsqrt(step)\r\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\r\n",
        "\r\n",
        "    return self.base_lr * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzc1BlTz1e2h"
      },
      "source": [
        "lr_schedule = CustomSchedule(base_lr = 0.1)\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\r\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\r\n",
        "        name='train_accuracy')\r\n",
        "\r\n",
        "entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.SUM)#adds a softmax step"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6Vvb_cHn_py"
      },
      "source": [
        "class_weights = np.ones((512,512,num_classes**2-1))\r\n",
        "class_weights[:,:,0]= 1/5 #class 0 corresponds to no change"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Prq0Baoj7go"
      },
      "source": [
        "def dice_loss (y_true,y_pred,eps = 1e-5,num_classes=6):\r\n",
        "  y_true = y_true[:,:,:,0]\r\n",
        "  y_pred = tf.nn.softmax(y_pred)\r\n",
        "  \r\n",
        "  #y_pred = tf.argmax(y_pred,axis=-1)\r\n",
        "  y_true = tf.one_hot(tf.cast(y_true,dtype = tf.uint8),depth = num_classes**2-1)\r\n",
        "  return tf.math.reduce_mean(1 - (2*y_true*y_pred)/(y_true + y_pred + eps))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vEs-8owu17E"
      },
      "source": [
        "def DS_loss_fn(y_true, y_pred, loss_function = entropy, weights=[3,1,1,1,1]):\r\n",
        "  loss = 0\r\n",
        "  y_true==0\r\n",
        "  for i in range(len(weights)):\r\n",
        "\r\n",
        "    #loss = loss+ tf.math.reduce_mean(weights[i]*loss_function(y_true,y_pred[i]) + weights[i]*dice_loss (y_true, y_pred[i]))\r\n",
        "    loss = loss+ tf.math.reduce_mean(weights[i]*dice_loss (y_true, y_pred[i]))\r\n",
        "    #loss = loss+ weights[i]*loss_function(y_true,y_pred[i])\r\n",
        "    y_true = tf.keras.layers.MaxPool2D()(y_true) \r\n",
        "  return loss"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mkhs4ADRxhHz",
        "outputId": "3f2976af-3fe0-4d57-a80c-792c685d3560"
      },
      "source": [
        "##Test\r\n",
        "\"\"\"\r\n",
        "y_pred = ddn([test_im1,test_im2])\r\n",
        "DS_loss_fn(test_label,y_pred)\"\"\""
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ny_pred = ddn([test_im1,test_im2])\\nDS_loss_fn(test_label,y_pred)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oROkWaB5Xkc"
      },
      "source": [
        "save_path = \"/content/Saved_Models/\"\r\n",
        "if not(os.path.isdir(save_path)):\r\n",
        "  os.mkdir(save_path)\r\n",
        "batch_size = 1\r\n",
        "epochs = 2\r\n",
        "model_savename=\"DDN_test\"\r\n",
        "train_ds = preprocessing(list_ds, batch_size = batch_size)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_AGOK7XX_zP"
      },
      "source": [
        "##Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgV2c02ZYBL1"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "import datetime"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiNvwCo1ZCGY"
      },
      "source": [
        "# Clear any logs from previous runs\r\n",
        "!rm -rf ./logs/\r\n",
        "\r\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\r\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\r\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\r\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRCCKxl1m6Ce"
      },
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC4h4OtgmOzb"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghw4WCcT2Bj5"
      },
      "source": [
        "steps_per_epoch = 2968//batch_size"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxYTCxlVnmQt"
      },
      "source": [
        "#ddn.fit(train_ds,epochs = 3, shuffle=False, use_multiprocessing=True,workers= tf.data.AUTOTUNE,callbacks=[tensorboard_callback])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "siMws5f85j3T",
        "outputId": "f1570d2c-6af7-4ab1-b3ef-5ed85d9b2c15"
      },
      "source": [
        "for epoch in range(epochs):\r\n",
        "\r\n",
        "  train_loss.reset_states()\r\n",
        "  train_accuracy.reset_states()\r\n",
        "\r\n",
        "  print(\"Start of epoch {}\".format(epoch))\r\n",
        "\r\n",
        "  for step, (im1,im2,label) in enumerate(train_ds):\r\n",
        "\r\n",
        "    step = step + epoch*steps_per_epoch\r\n",
        "\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "\r\n",
        "      y_pred = ddn([im1,im2],training=True)\r\n",
        "\r\n",
        "      loss_value = DS_loss_fn(label,y_pred)\r\n",
        "      \r\n",
        "    acc = train_accuracy(label,y_pred[0]) #makes a metrics.CategoricalAccuracy object\r\n",
        "    train_loss(loss_value) #puts the loss value into a metrics.Means object\r\n",
        "    \r\n",
        "    with train_summary_writer.as_default():\r\n",
        "      tf.summary.scalar('loss', train_loss.result(), step=step)\r\n",
        "      tf.summary.scalar('accuracy', train_accuracy.result(), step=step)\r\n",
        "      \r\n",
        "\r\n",
        "    grads = tape.gradient(loss_value,ddn.trainable_weights)\r\n",
        "    optimizer.apply_gradients(zip(grads,ddn.trainable_weights))\r\n",
        "\r\n",
        "    if step % 100== 0:\r\n",
        "      print(\r\n",
        "                \"Training loss at step %d: %.4f\"\r\n",
        "                % (step, float(loss_value.numpy()))\r\n",
        "            )\r\n",
        "      \r\n",
        "      print (\"Training accuracy at step {} is {}\".format(step, acc.numpy()))\r\n",
        "      print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\r\n",
        "      print(\"Current LR: {}\".format(optimizer.learning_rate(step)))\r\n",
        "            \r\n",
        "  ddn.save('saved_model/{}'.format(model_savename))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 0\n",
            "Training loss at step 0: 6.9891\n",
            "Training accuracy at step 0 is 0.03164863586425781\n",
            "Seen so far: 2 samples\n",
            "Current LR: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-75d5615a82c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDS_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1018\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1148\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2602\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2604\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2605\u001b[0m   return squeeze_batch_dims(\n\u001b[1;32m   2606\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OUGLTcEqvsa"
      },
      "source": [
        "%tensorboard --logdir logs/gradient_tape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hetEJHtahK9M"
      },
      "source": [
        "shutil.make_archive(\"/content/DDN_test\",'zip',\"/content/saved_model/DDN_test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POwIyVrPr1H_"
      },
      "source": [
        "shutil.copy2(\"/content/DDN_test.zip\",\"/content/drive/MyDrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yduFItI2-0L"
      },
      "source": [
        "test = list(train_ds.take(1))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtF6l3AB3DJm"
      },
      "source": [
        "test_im1 = test[0]\r\n",
        "test_im2 = test[1]\r\n",
        "test_label = test[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ5wWeGG3GT7"
      },
      "source": [
        "plt.imshow(test_label[0,:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGEX38St3aIM"
      },
      "source": [
        "test_predict = ddn.predict([test_im1,test_im2])[0]\r\n",
        "#test_predict = tf.nn.softmax(test_predict)\r\n",
        "test_predict = tf.argmax(test_predict,axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC42USIt3mf-"
      },
      "source": [
        "plt.imshow(test_predict[0,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVz6hOSW2SjN"
      },
      "source": [
        "!tensorboard dev upload \\\r\n",
        "  --logdir logs/gradient_tape \\\r\n",
        "  --name \"DDN 2 epochs cat_entropy loss\" \\\r\n",
        "  --description \"Custom LR sqrt schedule\" \\"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}