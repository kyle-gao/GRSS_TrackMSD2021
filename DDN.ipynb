{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMQo2BeGfR6rfcrqVQyGNmL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyle-gao/GRSS_TrackMSD2021/blob/main/DDN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcdRBC3lFZvV"
      },
      "source": [
        "#https://github.com/GeoZcx/A-deeply-supervised-image-fusion-network-for-change-detection-in-remote-sensing-images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4sAKIleU-pl"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import keras.backend as K\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import shutil\r\n",
        "import os\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, \\\r\n",
        "    Conv2D, Add, Activation, Lambda\r\n",
        "from keras import backend as K\r\n",
        "from keras.activations import sigmoid\r\n",
        "\r\n",
        "from keras import applications\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, concatenate, \\\r\n",
        "    Activation, ZeroPadding2D,Conv2DTranspose,Subtract,multiply,add,UpSampling2D,PReLU\r\n",
        "from keras import  layers\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYunA1z8FUVb"
      },
      "source": [
        "def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same',with_activation = False):\r\n",
        "    x = Conv2D(nb_filter, kernel_size, padding=padding, strides=strides)(x)\r\n",
        "    x=PReLU()(x)\r\n",
        "    x=BatchNormalization(axis=3)(x)\r\n",
        "    x=Dropout(rate = 0.6)(x)\r\n",
        "    if with_activation == True:\r\n",
        "        x = Activation('relu')(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "def attach_attention_module(net, attention_module):\r\n",
        "    if attention_module == 'se_block':  # SE_block\r\n",
        "        net = se_block(net)\r\n",
        "    elif attention_module == 'cbam_block':  # CBAM_block\r\n",
        "        net = cbam_block(net)\r\n",
        "    else:\r\n",
        "        raise Exception(\"'{}' is not supported attention module!\".format(attention_module))\r\n",
        "\r\n",
        "    return net\r\n",
        "\r\n",
        "\r\n",
        "def se_block(input_feature, ratio=8):\r\n",
        "    \"\"\"Contains the implementation of Squeeze-and-Excitation(SE) block.\r\n",
        "    As described in https://arxiv.org/abs/1709.01507.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\r\n",
        "    channel = input_feature.shape[channel_axis]\r\n",
        "\r\n",
        "    se_feature = GlobalAveragePooling2D()(input_feature)\r\n",
        "    se_feature = Reshape((1, 1, channel))(se_feature)\r\n",
        "    assert se_feature.shape[1:] == (1, 1, channel)\r\n",
        "    se_feature = Dense(channel // ratio,\r\n",
        "                       activation='relu',\r\n",
        "                       kernel_initializer='he_normal',\r\n",
        "                       use_bias=True,\r\n",
        "                       bias_initializer='zeros')(se_feature)\r\n",
        "    assert se_feature.shape[1:] == (1, 1, channel // ratio)\r\n",
        "    se_feature = Dense(channel,\r\n",
        "                       activation='sigmoid',\r\n",
        "                       kernel_initializer='he_normal',\r\n",
        "                       use_bias=True,\r\n",
        "                       bias_initializer='zeros')(se_feature)\r\n",
        "    assert se_feature.shape[1:] == (1, 1, channel)\r\n",
        "    if K.image_data_format() == 'channels_first':\r\n",
        "        se_feature = Permute((3, 1, 2))(se_feature)\r\n",
        "\r\n",
        "    se_feature = multiply([input_feature, se_feature])\r\n",
        "    return se_feature\r\n",
        "\r\n",
        "\r\n",
        "def cbam_block(cbam_feature, ratio=8):\r\n",
        "    \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\r\n",
        "    As described in https://arxiv.org/abs/1807.06521.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    cbam_feature = channel_attention(cbam_feature, ratio)\r\n",
        "    cbam_feature = spatial_attention(cbam_feature)\r\n",
        "    return cbam_feature\r\n",
        "\r\n",
        "\r\n",
        "def channel_attention(input_feature, ratio=8):\r\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\r\n",
        "    channel = input_feature.shape[channel_axis]\r\n",
        "\r\n",
        "    shared_layer_one = Dense(channel // ratio,\r\n",
        "                             activation='relu',\r\n",
        "                             kernel_initializer='he_normal',\r\n",
        "                             use_bias=True,\r\n",
        "                             bias_initializer='zeros')\r\n",
        "    shared_layer_two = Dense(channel,\r\n",
        "                             kernel_initializer='he_normal',\r\n",
        "                             use_bias=True,\r\n",
        "                             bias_initializer='zeros')\r\n",
        "\r\n",
        "    avg_pool = GlobalAveragePooling2D()(input_feature)\r\n",
        "    avg_pool = Reshape((1, 1, channel))(avg_pool)\r\n",
        "    assert avg_pool.shape[1:] == (1, 1, channel)\r\n",
        "    avg_pool = shared_layer_one(avg_pool)\r\n",
        "    assert avg_pool.shape[1:] == (1, 1, channel // ratio)\r\n",
        "    avg_pool = shared_layer_two(avg_pool)\r\n",
        "    assert avg_pool.shape[1:] == (1, 1, channel)\r\n",
        "\r\n",
        "    max_pool = GlobalMaxPooling2D()(input_feature)\r\n",
        "    max_pool = Reshape((1, 1, channel))(max_pool)\r\n",
        "    assert max_pool.shape[1:] == (1, 1, channel)\r\n",
        "    max_pool = shared_layer_one(max_pool)\r\n",
        "    assert max_pool.shape[1:] == (1, 1, channel // ratio)\r\n",
        "    max_pool = shared_layer_two(max_pool)\r\n",
        "    assert max_pool.shape[1:] == (1, 1, channel)\r\n",
        "\r\n",
        "    cbam_feature = Add()([avg_pool, max_pool])\r\n",
        "    cbam_feature = Activation('sigmoid')(cbam_feature)\r\n",
        "\r\n",
        "    if K.image_data_format() == \"channels_first\":\r\n",
        "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\r\n",
        "\r\n",
        "    return multiply([input_feature, cbam_feature])\r\n",
        "\r\n",
        "\r\n",
        "def spatial_attention(input_feature):\r\n",
        "    kernel_size = 7\r\n",
        "\r\n",
        "    if K.image_data_format() == \"channels_first\":\r\n",
        "        channel = input_feature.shape[1]\r\n",
        "        cbam_feature = Permute((2, 3, 1))(input_feature)\r\n",
        "    else:\r\n",
        "        channel = input_feature.shape[-1]\r\n",
        "        cbam_feature = input_feature\r\n",
        "\r\n",
        "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert avg_pool.shape[-1] == 1\r\n",
        "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert max_pool.shape[-1] == 1\r\n",
        "    concat = Concatenate(axis=3)([avg_pool, max_pool])\r\n",
        "    assert concat.shape[-1] == 2\r\n",
        "    cbam_feature = Conv2D(filters=1,\r\n",
        "                          kernel_size=kernel_size,\r\n",
        "                          strides=1,\r\n",
        "                          padding='same',\r\n",
        "                          activation='sigmoid',\r\n",
        "                          kernel_initializer='he_normal',\r\n",
        "                          use_bias=False)(concat)\r\n",
        "    assert cbam_feature.shape[-1] == 1\r\n",
        "\r\n",
        "    if K.image_data_format() == \"channels_first\":\r\n",
        "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\r\n",
        "\r\n",
        "    return multiply([input_feature, cbam_feature])\r\n",
        "\r\n",
        "\r\n",
        "def get_spatial_attention_map(input_feature):\r\n",
        "    kernel_size = 7\r\n",
        "    cbam_feature = input_feature\r\n",
        "\r\n",
        "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert avg_pool.shape[-1] == 1\r\n",
        "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert max_pool.shape[-1] == 1\r\n",
        "    concat = Concatenate(axis=3)([avg_pool, max_pool])\r\n",
        "    assert concat.shape[-1] == 2\r\n",
        "    cbam_feature = Conv2D(filters=1,\r\n",
        "                          kernel_size=kernel_size,\r\n",
        "                          strides=1,\r\n",
        "                          padding='same',\r\n",
        "                          activation='sigmoid',\r\n",
        "                          kernel_initializer='he_normal',\r\n",
        "                          use_bias=False)(concat)\r\n",
        "    assert cbam_feature.shape[-1] == 1\r\n",
        "\r\n",
        "    if K.image_data_format() == \"channels_first\":\r\n",
        "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\r\n",
        "\r\n",
        "    return cbam_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwG5CvxkOeMK",
        "cellView": "form"
      },
      "source": [
        "#@title DSIFN code\n",
        "\n",
        "def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same',with_activation = False):\n",
        "    x = Conv2D(nb_filter, kernel_size, padding=padding, strides=strides)(x)\n",
        "    x=PReLU()(x)\n",
        "    x=BatchNormalization(axis=3)(x)\n",
        "    x=Dropout(rate = 0.6)(x)\n",
        "    if with_activation == True:\n",
        "        x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def vgg16():\n",
        "    vgg_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(512,512,3))\n",
        "    model = Model(inputs=vgg_model.input, outputs = vgg_model.get_layer('block5_conv3').output)\n",
        "    model.trainable=False\n",
        "    return model\n",
        "\n",
        "def DSIFN(imsize):\n",
        "    #DFEN accepts inputs in size of imsize*imsize*3\n",
        "    vgg_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(imsize,imsize,3))\n",
        "\n",
        "    b5c3_model = Model(inputs=vgg_model.input, outputs = vgg_model.get_layer('block5_conv3').output)\n",
        "    b5c3_model.trainable=False\n",
        "\n",
        "    b4c3_model = Model(inputs=vgg_model.input, outputs = vgg_model.get_layer('block4_conv3').output)\n",
        "    b4c3_model.trainable=False\n",
        "\n",
        "    b3c3_model = Model(inputs=vgg_model.input, outputs = vgg_model.get_layer('block3_conv3').output)\n",
        "    b3c3_model.trainable=False\n",
        "\n",
        "    b2c2_model = Model(inputs=vgg_model.input, outputs = vgg_model.get_layer('block2_conv2').output)\n",
        "    b2c2_model.trainable=False\n",
        "\n",
        "    b1c2_model = Model(inputs=vgg_model.input, outputs = vgg_model.get_layer('block1_conv2').output)\n",
        "    b1c2_model.trainable=False\n",
        "\n",
        "    input_t1 = layers.Input((imsize,imsize,3), name='Input_t1')\n",
        "    input_t2 = layers.Input((imsize,imsize,3), name='Input_t2')\n",
        "\n",
        "    t1_b5c3 = b5c3_model(input_t1)\n",
        "    t2_b5c3 = b5c3_model(input_t2)\n",
        "\n",
        "    t1_b4c3 = b4c3_model(input_t1)\n",
        "    t2_b4c3 = b4c3_model(input_t2)\n",
        "\n",
        "    t1_b3c3 = b3c3_model(input_t1)\n",
        "    t2_b3c3 = b3c3_model(input_t2)\n",
        "\n",
        "    t1_b2c2 = b2c2_model(input_t1)\n",
        "    t2_b2c2 = b2c2_model(input_t2)\n",
        "\n",
        "    t1_b1c2 = b1c2_model(input_t1)\n",
        "    t2_b1c2 = b1c2_model(input_t2)\n",
        "\n",
        "    concat_b5c3 = concatenate([t1_b5c3, t2_b5c3], axis=3) #channel 1024\n",
        "    x = Conv2d_BN(concat_b5c3,imsize, 3)\n",
        "    x = Conv2d_BN(x,imsize,3)\n",
        "    attention_map_1 = get_spatial_attention_map(x)\n",
        "    x = multiply([x, attention_map_1])\n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "\n",
        "    #branche1\n",
        "    branch_1 =Conv2D(1, kernel_size=1, activation='sigmoid', padding='same',name='output_32')(x)\n",
        "\n",
        "    x = Conv2DTranspose(imsize, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\n",
        "    x = concatenate([x,t1_b4c3,t2_b4c3],axis=3)\n",
        "    x = channel_attention(x)\n",
        "    x = Conv2d_BN(x,imsize,3)\n",
        "    x = Conv2d_BN(x,256,3)\n",
        "    x = Conv2d_BN(x,256,3)\n",
        "    attention_map_2 = get_spatial_attention_map(x)\n",
        "    x = multiply([x, attention_map_2])\n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "\n",
        "    #branche2\n",
        "    branch_2 =Conv2D(1, kernel_size=1, activation='sigmoid', padding='same',name='output_64')(x)\n",
        "\n",
        "    x = Conv2DTranspose(256, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\n",
        "    x = concatenate([x,t1_b3c3,t2_b3c3],axis=3)\n",
        "    x = channel_attention(x)\n",
        "    x = Conv2d_BN(x,256,3)\n",
        "    x = Conv2d_BN(x,128,3)\n",
        "    x = Conv2d_BN(x, 128, 3)\n",
        "    attention_map_3 = get_spatial_attention_map(x)\n",
        "    x = multiply([x, attention_map_3])\n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "\n",
        "    #branche3\n",
        "    branch_3 =Conv2D(1, kernel_size=1, activation='sigmoid', padding='same',name='output_128')(x)\n",
        "\n",
        "    x = Conv2DTranspose(128, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\n",
        "    x = concatenate([x,t1_b2c2,t2_b2c2],axis=3)\n",
        "    x = channel_attention(x)\n",
        "    x = Conv2d_BN(x,128,3)\n",
        "    x = Conv2d_BN(x,64,3)\n",
        "    x = Conv2d_BN(x, 64, 3)\n",
        "    attention_map_4 = get_spatial_attention_map(x)\n",
        "    x = multiply([x, attention_map_4])\n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "\n",
        "    #branche4\n",
        "    branch_4 =Conv2D(1, kernel_size=1, activation='sigmoid', padding='same',name='output_256')(x)\n",
        "\n",
        "    x = Conv2DTranspose(64, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\n",
        "    x = concatenate([x,t1_b1c2,t2_b1c2],axis=3)\n",
        "    x = channel_attention(x)\n",
        "    x = Conv2d_BN(x,64,3)\n",
        "    x = Conv2d_BN(x,32,3)\n",
        "    x = Conv2d_BN(x, 16, 3)\n",
        "    attention_map_5 = get_spatial_attention_map(x)\n",
        "    x = multiply([x, attention_map_5])\n",
        "\n",
        "    # branche5\n",
        "    branch_5 =Conv2D(1, kernel_size=1, activation='sigmoid', padding='same',name='output_imsize')(x)\n",
        "\n",
        "    DSIFN = Model(inputs=[input_t1,input_t2], outputs=[branch_1,branch_2,branch_3,branch_4,branch_5])\n",
        "\n",
        "    return DSIFN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbdAfEOxU5o4"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNSoIhZsWRpq",
        "outputId": "3ba01986-a57c-426f-e513-94c198df75dc"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAVHeP8jW6yM"
      },
      "source": [
        "shutil.unpack_archive(\"/content/drive/MyDrive/Kaggle_CoverChange.zip\",\"/content/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtVych-nS5n5"
      },
      "source": [
        "data_dir = \"/content/Kaggle_CoverChange\"\r\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir+\"/im1/*\"),shuffle=False)\r\n",
        "#dataset is made up of strings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASeQSd7UwjPO"
      },
      "source": [
        "\r\n",
        "#classes = array([ 29.,  38.,  75.,  76., 128., 150., 255.])\r\n",
        "class_dict = {(29):1, (38):2, (75):3,(76):3,128:4,150:5,(255):0} #mapping 75 and 76 to same class, i'm assuming this is an encoding issue.\r\n",
        "\r\n",
        "def to_categorical(tensor,class_dict):\r\n",
        "  #maps pixel values to categories 1,2...num_classes\r\n",
        "  for k,v in class_dict.items():\r\n",
        "    tensor[tensor==k]=v\r\n",
        "  return tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiwDCfO1j-3g"
      },
      "source": [
        "label1_fn = \"/content/Kaggle_CoverChange/label1/00003.png\"\r\n",
        "label1 = tf.keras.preprocessing.image.load_img(label1_fn,color_mode=\"grayscale\")\r\n",
        "label1 = tf.keras.preprocessing.image.img_to_array(label1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMQDMpk9p9FM"
      },
      "source": [
        "##Testing label change conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyb7mGzSxDXK"
      },
      "source": [
        "num_classes = 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sd3fkTBxlLh"
      },
      "source": [
        "##Need to convert 2 labels into 1 change label\r\n",
        "\r\n",
        "Trick: Let n be number of classes\r\n",
        "Step 1. Use an outer product between one_hot encoded labels\r\n",
        "(h,w,n),(h,w,n)->(h,w,n,n), this is gives a one hot encoded change matrix M.\r\n",
        "\r\n",
        "Eg. M = 0 except for Mij = 1 -> class i changed to class j.\r\n",
        "\r\n",
        "Step 2. Convert to categorical change -> (h,w,n,n)->(h,w,n^2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnWIcy96GeId",
        "outputId": "8d5d8bf0-f565-47dd-d1c6-8cec8a5fc02a"
      },
      "source": [
        "\"\"\"#converting (label1,label2)->(label changemap)\r\n",
        "#where change map has num_classes^2 (not all unique) change classes \r\n",
        "def make_label_change_dict(num_classes):\r\n",
        "  label_change_dict = {}\r\n",
        "  i = 0\r\n",
        "  for x in range(num_classes):\r\n",
        "    for y in range(num_classes):\r\n",
        "      label_change_dict[(x,y)] = i *(x!=y)\r\n",
        "      i += 1\r\n",
        "  return label_change_dict\r\n",
        "\r\n",
        "label_change_dict = make_label_change_dict(6)\r\n",
        "print(label_change_dict)\"\"\"\r\n",
        "\r\n",
        "#converting (label1,label2)->(label changemap)\r\n",
        "#where change map has num_classes^2 (not all unique) change classes \r\n",
        "def make_label_change_array(num_classes):\r\n",
        "  \"\"\"Arg:\r\n",
        "  num_classes:int, number of classes\r\n",
        "  returns:\r\n",
        "  num_classes^2 matrix of categorical change labels.\r\n",
        "  \"\"\"\r\n",
        "  label_change_arr = np.zeros((num_classes,num_classes),dtype=np.uint8)\r\n",
        "  i = 0\r\n",
        "  for x in range(num_classes):\r\n",
        "    for y in range(num_classes):\r\n",
        "      label_change_arr[x,y] = i *(x!=y)\r\n",
        "      i += 1\r\n",
        "  return label_change_arr\r\n",
        "\r\n",
        "label_change_arr = make_label_change_array(6)\r\n",
        "\r\n",
        "print(label_change_arr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  0  8  9 10 11]\n",
            " [12 13  0 15 16 17]\n",
            " [18 19 20  0 22 23]\n",
            " [24 25 26 27  0 29]\n",
            " [30 31 32 33 34  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSTX_fohoYku"
      },
      "source": [
        "def get_class_change_label(before,after,label_change_arr):\r\n",
        "  \"\"\"\r\n",
        "  Input:\r\n",
        "  two np.array or tf.tensor of shape (batch,Width,Height, num_classes) corresponding to class labeled data in one hot encoding\r\n",
        "  the arrays represent the before and after class labels for change detection\r\n",
        "  Output:\r\n",
        "  a np.array of shape (batch,Width,Height) corresponding to change labels (see figure 2)\r\n",
        "  \"\"\"\r\n",
        "  labels_combined = np.einsum(\"abd,abe->abde\",before,after)\r\n",
        "  labels_combined = labels_combined*label_change_arr\r\n",
        "  labels_combined = np.sum(labels_combined, axis=(-1,-2))\r\n",
        "  return labels_combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP6H0-H8FkJQ"
      },
      "source": [
        "label1_fn = \"/content/Kaggle_CoverChange/label1/00018.png\"\r\n",
        "label2_fn = \"/content/Kaggle_CoverChange/label2/00018.png\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaPsT5RHIlCo"
      },
      "source": [
        "##Testing change label generation trick"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "ipkjfudFFiUW",
        "outputId": "f314226f-d702-4504-e927-335a54191a2e"
      },
      "source": [
        " \"\"\"   label1 = tf.keras.preprocessing.image.load_img(label1_fn, color_mode=\"grayscale\")\r\n",
        "    label1 = tf.keras.preprocessing.image.img_to_array(label1)\r\n",
        "    label1old = label1\r\n",
        "    label1 = to_categorical(label1,class_dict)\r\n",
        "    label1 = tf.expand_dims(label1,axis=0)\r\n",
        "    label1 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth = num_classes)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    label2 = tf.keras.preprocessing.image.load_img(label2_fn, color_mode =\"grayscale\")\r\n",
        "    label2 = tf.keras.preprocessing.image.img_to_array(label2)\r\n",
        "    label1old = label1\r\n",
        "    label2 = to_categorical(label2,class_dict)\r\n",
        "    label2 = tf.expand_dims(label2,axis=0)\r\n",
        "    label2old = label2\r\n",
        "    label2 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth=num_classes)\r\n",
        "\r\n",
        "    print(label1.shape)\r\n",
        "    print(label2.shape)\r\n",
        "    print(label1[0,300,300,:])\r\n",
        "    print(label2[0,300,300,:])\r\n",
        "    lc = np.einsum(\"abcd,abce->abcde\",label1,label2)\r\n",
        "\r\n",
        "    print(lc[0,300,300,:,:])\r\n",
        "    lc = lc * label_change_arr\r\n",
        "    print(lc[0,300,300,:,:])\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'   label1 = tf.keras.preprocessing.image.load_img(label1_fn, color_mode=\"grayscale\")\\n   label1 = tf.keras.preprocessing.image.img_to_array(label1)\\n   label1old = label1\\n   label1 = to_categorical(label1,class_dict)\\n   label1 = tf.expand_dims(label1,axis=0)\\n   label1 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth = num_classes)\\n\\n\\n\\n\\n   label2 = tf.keras.preprocessing.image.load_img(label2_fn, color_mode =\"grayscale\")\\n   label2 = tf.keras.preprocessing.image.img_to_array(label2)\\n   label1old = label1\\n   label2 = to_categorical(label2,class_dict)\\n   label2 = tf.expand_dims(label2,axis=0)\\n   label2old = label2\\n   label2 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth=num_classes)\\n\\n   print(label1.shape)\\n   print(label2.shape)\\n   print(label1[0,300,300,:])\\n   print(label2[0,300,300,:])\\n   lc = np.einsum(\"abcd,abce->abcde\",label1,label2)\\n\\n   print(lc[0,300,300,:,:])\\n   lc = lc * label_change_arr\\n   print(lc[0,300,300,:,:])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPl1JfAgIo3b"
      },
      "source": [
        "##Testing over"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooE716J8bpnx"
      },
      "source": [
        "def get_item(path):\r\n",
        "\r\n",
        "  #wrap function in tf.numpy_function() or tf.data.dataset.map bugs out\r\n",
        "\r\n",
        "  def _get_item(path):\r\n",
        "    \"\"\"\r\n",
        "    args:\r\n",
        "    path: Dataset.list_file dataset element\r\n",
        "\r\n",
        "    returns: \r\n",
        "    (h,w,3),(h,w,1),(h,w,3),(h,w,1) image-label 4-tuple in tf.float32 tf.Tensor\r\n",
        "    \"\"\"\r\n",
        "    fn = tf.strings.split(path,\"/\")\r\n",
        "    base_dir = tf.strings.join(fn[:-2],separator=\"/\")\r\n",
        "\r\n",
        "    image1_fn = (base_dir+\"/im1/\"+fn[-1]).numpy()\r\n",
        "    image2_fn = (base_dir+\"/im2/\"+fn[-1]).numpy()\r\n",
        "\r\n",
        "    label1_fn = (base_dir+\"/label1/\"+fn[-1]).numpy()\r\n",
        "    label2_fn = (base_dir+\"/label2/\"+fn[-1]).numpy()\r\n",
        "\r\n",
        "    #label1_fn = \"/content/Kaggle_CoverChange/label1/00018.png\"\r\n",
        "    #label2_fn = \"/content/Kaggle_CoverChange/label2/00018.png\"\r\n",
        "\r\n",
        "\r\n",
        "    image1 = tf.keras.preprocessing.image.load_img(image1_fn)\r\n",
        "    image1 = tf.keras.preprocessing.image.img_to_array(image1)\r\n",
        "\r\n",
        "    image2 = tf.keras.preprocessing.image.load_img(image2_fn)\r\n",
        "    image2 = tf.keras.preprocessing.image.img_to_array(image2)\r\n",
        "\r\n",
        "    label1 = tf.keras.preprocessing.image.load_img(label1_fn, color_mode=\"grayscale\")\r\n",
        "    label1 = tf.keras.preprocessing.image.img_to_array(label1)\r\n",
        "    label1 = to_categorical(label1,class_dict)\r\n",
        "    #label1 = tf.expand_dims(label1,axis=0)\r\n",
        "\r\n",
        "    label1 = tf.one_hot(tf.cast(label1[:,:,0],dtype = tf.uint8),depth = num_classes)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    label2 = tf.keras.preprocessing.image.load_img(label2_fn, color_mode =\"grayscale\")\r\n",
        "    label2 = tf.keras.preprocessing.image.img_to_array(label2)\r\n",
        "    label2 = to_categorical(label2,class_dict)\r\n",
        "    #label2 = tf.expand_dims(label2,axis=0)\r\n",
        "\r\n",
        "    label2 = tf.one_hot(tf.cast(label2[:,:,0],dtype = tf.uint8),depth=num_classes)\r\n",
        "\r\n",
        "    change_label = get_class_change_label(label1,label2,label_change_arr=label_change_arr)\r\n",
        "    change_label = tf.expand_dims(change_label, axis=-1)\r\n",
        "\r\n",
        "    #classes = array([ 29.,  38.,  75.,  76., 128., 150., 255.])\r\n",
        "    #(h,w,1) tensor of int from 1-6\r\n",
        "\r\n",
        "    return image1,image2,change_label\r\n",
        "\r\n",
        "  output = tf.numpy_function(_get_item,[path],[tf.float32,tf.float32,tf.float32])\r\n",
        "\r\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT3E2boXh6fa"
      },
      "source": [
        "def preprocessing(list_ds,batch_size=8,augmentation=None):\r\n",
        "  \"\"\"\r\n",
        "  applies some preprocessing\r\n",
        "  args:\r\n",
        "  list_ds-Dataset.list_files dataset object\r\n",
        "  batch_size-int \r\n",
        "  augmentation-a function (x,y)->(x,y)\r\n",
        "  returns-batched dataset\r\n",
        "  \"\"\"\r\n",
        "  #ds = list_ds.cache() \r\n",
        "  ds = list_ds.map(get_item,num_parallel_calls=tf.data.AUTOTUNE) #(h,w,3),(h,w,1)\r\n",
        "  ds = ds.batch(batch_size)\r\n",
        "  ds = ds.shuffle(100)\r\n",
        "\r\n",
        "  if augmentation:\r\n",
        "    ds = ds.map((lambda x,y : augmentation(x,y)),num_parallel_calls=tf.data.AUTOTUNE)\r\n",
        "\r\n",
        "  \r\n",
        "  ds = ds.prefetch(8)\r\n",
        "  return ds\r\n",
        "\r\n",
        "def transform(x,y):\r\n",
        "  \"\"\"\r\n",
        "  Write your data transformations here\r\n",
        "  \"\"\"\r\n",
        "  x=tf.keras.layers.experimental.preprocessing.Rescaling(1./255.0)(x)\r\n",
        "  y=tf.one_hot(tf.cast(y[:,:,0],dtype = tf.int32),depth = 7)\r\n",
        "\r\n",
        "  return x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu4qpWMq6guQ"
      },
      "source": [
        "#load pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1jzSEkZ4YZW"
      },
      "source": [
        "shutil.unpack_archive(\"/content/drive/MyDrive/vgg_512_seg_model.zip\",\"/content/Drive/Saved_Model/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtrhDcrsZM3u"
      },
      "source": [
        "##Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm7aDD4m6pIK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "47493b21-79fb-4e40-e139-c89dc0d32f59"
      },
      "source": [
        "\"\"\"\r\n",
        "vgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\r\n",
        "vgg16_512.summary()\r\n",
        "\r\n",
        "feature_layers = [vgg16_512.get_layer(\"features_c1\"),vgg16_512.get_layer(\"features_c2\"),vgg16_512.get_layer('features_c3'),vgg16_512.get_layer('features_c4'),vgg16_512.get_layer('features_c5')]\r\n",
        "feature_extractor = tf.keras.models.Model(inputs = vgg16_512.input, outputs = [layer.output for layer in feature_layers])\r\n",
        "\r\n",
        "test_tensor = tf.random.normal((1,512,512,3))\r\n",
        "test_out = feature_extractor(test_tensor)\r\n",
        "for t in test_out:\r\n",
        "  print(t.shape)\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nvgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\\nvgg16_512.summary()\\n\\nfeature_layers = [vgg16_512.get_layer(\"features_c1\"),vgg16_512.get_layer(\"features_c2\"),vgg16_512.get_layer(\\'features_c3\\'),vgg16_512.get_layer(\\'features_c4\\'),vgg16_512.get_layer(\\'features_c5\\')]\\nfeature_extractor = tf.keras.models.Model(inputs = vgg16_512.input, outputs = [layer.output for layer in feature_layers])\\n\\ntest_tensor = tf.random.normal((1,512,512,3))\\ntest_out = feature_extractor(test_tensor)\\nfor t in test_out:\\n  print(t.shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2mdKpIkXsl4"
      },
      "source": [
        "#DDN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eiduk23cFPBz"
      },
      "source": [
        "def DDN (imsize, num_classes = 6):\r\n",
        "    #if input image 512*512\r\n",
        "\r\n",
        "    vgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\r\n",
        "\r\n",
        "    image1 = layers.Input((imsize,imsize,3),name = \"image1\")\r\n",
        "    image2 = layers.Input((imsize,imsize,3),name = \"image2\")\r\n",
        "\r\n",
        "    feature_layers = [vgg16_512.get_layer(\"features_c1\"),vgg16_512.get_layer(\"features_c2\"),vgg16_512.get_layer('features_c3'),vgg16_512.get_layer('features_c4'),vgg16_512.get_layer('features_c5')]\r\n",
        "    feature_extractor = tf.keras.models.Model(inputs = vgg16_512.input, outputs = [layer.output for layer in feature_layers],trainable=False)\r\n",
        "\r\n",
        "    features_1 = feature_extractor(image1)\r\n",
        "    features_2 = feature_extractor(image1)\r\n",
        "\r\n",
        "    t1_b5c3 = features_1[4] #(None, 32, 32, 512)\r\n",
        "    t2_b5c3 = features_2[4] \r\n",
        "\r\n",
        "    t1_b4c3 = features_1[3] #(None, 64, 64, 512)\r\n",
        "    t2_b4c3 = features_2[3] \r\n",
        "    \r\n",
        "    t1_b3c3 = features_1[2] #(None, 128, 128, 256)  \r\n",
        "    t2_b3c3 = features_2[2]\r\n",
        "\r\n",
        "    t1_b2c2 = features_1[1]\r\n",
        "    t2_b2c2 = features_2[1] #(None, 256, 256, 128) \r\n",
        "\r\n",
        "    t1_b1c2 = features_1[0]\r\n",
        "    t2_b1c2 = features_2[0] #(None, 512, 512, 64)\r\n",
        "\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    pair5 = layers.Input((imsize,imsize,64*2), name='pair5') #rbg images concatenated channel-wise\r\n",
        "    pair4 = layers.Input((imsize//2,imsize//2,128*2), name='pair4')\r\n",
        "    pair3 = layers.Input((imsize//4,imsize//4,256*2), name='pair3')\r\n",
        "    pair2 = layers.Input((imsize//8,imsize//8,512*2), name='pair2')\r\n",
        "    pair1 = layers.Input((imsize//16,imsize//16,512*2), name='pair1')\r\n",
        "\r\n",
        "\r\n",
        "    t1_b5c3 = pair1[:,:,:,:3] #(None, 32, 32, 512)\r\n",
        "    t2_b5c3 = pair1[:,:,:,3:] \r\n",
        "\r\n",
        "    t1_b4c3 = pair2[:,:,:,:3] #(None, 64, 64, 512)\r\n",
        "    t2_b4c3 = pair2[:,:,:,3:] \r\n",
        "    \r\n",
        "    t1_b3c3 = pair3[:,:,:,:3] #(None, 128, 128, 256)  \r\n",
        "    t2_b3c3 = pair3[:,:,:,3:]\r\n",
        "\r\n",
        "    t1_b2c2 = pair4[:,:,:,:3]\r\n",
        "    t2_b2c2 = pair4[:,:,:,3:] #(None, 256, 256, 128) \r\n",
        "\r\n",
        "    t1_b1c2 = pair5[:,:,:,:3]\r\n",
        "    t2_b1c2 = pair5[:,:,:,3:] #(None, 512, 512, 64)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    concat_b5c3 = concatenate([t1_b5c3, t2_b5c3], axis=3) #channel 1024\r\n",
        "    x = Conv2d_BN(concat_b5c3,imsize, 3)\r\n",
        "    x = Conv2d_BN(x,imsize,3)\r\n",
        "    attention_map_1 = get_spatial_attention_map(x)\r\n",
        "    x = multiply([x, attention_map_1])\r\n",
        "    x = BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche1\r\n",
        "    branch_1 =Conv2D(num_classes**2, kernel_size=1, padding='same',name='output_32')(x)\r\n",
        "\r\n",
        "    x = Conv2DTranspose(imsize, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = concatenate([x,t1_b4c3,t2_b4c3],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,imsize,3)\r\n",
        "    x = Conv2d_BN(x,256,3)\r\n",
        "    x = Conv2d_BN(x,256,3)\r\n",
        "    attention_map_2 = get_spatial_attention_map(x)\r\n",
        "    x = multiply([x, attention_map_2])\r\n",
        "    x = BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche2\r\n",
        "    branch_2 =Conv2D(num_classes**2, kernel_size=1, padding='same',name='output_64')(x)\r\n",
        "\r\n",
        "    x = Conv2DTranspose(256, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = concatenate([x,t1_b3c3,t2_b3c3],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,256,3)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x, 128, 3)\r\n",
        "    attention_map_3 = get_spatial_attention_map(x)\r\n",
        "    x = multiply([x, attention_map_3])\r\n",
        "    x = BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche3\r\n",
        "    branch_3 =Conv2D(num_classes**2, kernel_size=1, padding='same',name='output_128')(x)\r\n",
        "\r\n",
        "    x = Conv2DTranspose(128, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = concatenate([x,t1_b2c2,t2_b2c2],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x, 128, 3)\r\n",
        "    attention_map_4 = get_spatial_attention_map(x)\r\n",
        "    x = multiply([x, attention_map_4])\r\n",
        "    x = BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche4\r\n",
        "    branch_4 =Conv2D(num_classes**2, kernel_size=1, padding='same',name='output_256')(x)\r\n",
        "\r\n",
        "    x = Conv2DTranspose(64, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = concatenate([x,t1_b1c2,t2_b1c2],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x,64,3)\r\n",
        "    x = Conv2d_BN(x, 64, 3)\r\n",
        "    attention_map_5 = get_spatial_attention_map(x)\r\n",
        "    x = multiply([x, attention_map_5])\r\n",
        "\r\n",
        "    # branche5\r\n",
        "    branch_5 =Conv2D(num_classes**2, kernel_size=1, padding='same',name='output_imsize')(x)\r\n",
        "\r\n",
        "    DDN = Model(inputs=[image1,image2], outputs=[branch_5,branch_4,branch_3,branch_2,branch_1])\r\n",
        "\r\n",
        "    return DDN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NykWcUcQzdFh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c4850e0b-48e0-45cd-e307-eb979f15b17f"
      },
      "source": [
        "#TEST\r\n",
        "\"\"\"\r\n",
        "imsize = 512\r\n",
        "image1 = tf.random.normal((1,512,512,3))\r\n",
        "image2 = tf.random.normal((1,512,512,3))\r\n",
        "ddn = DDN(512,6)\r\n",
        "forward = ddn([image1,image2])\r\n",
        "for f in forward:\r\n",
        "  print (f.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimsize = 512\\nimage1 = tf.random.normal((1,512,512,3))\\nimage2 = tf.random.normal((1,512,512,3))\\nddn = DDN(512,6)\\nforward = ddn([image1,image2])\\nfor f in forward:\\n  print (f.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-ihDr4C1Siz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c58637b-7804-4548-9d4e-a9e7a7ce1571"
      },
      "source": [
        "ddn = DDN(512,6)\r\n",
        "ddn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "image1 (InputLayer)             [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Functional)            [(None, 512, 512, 64 14714688    image1[0][0]                     \n",
            "                                                                 image1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 1024) 0           model_2[0][4]                    \n",
            "                                                                 model_2[1][4]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_14 (PReLU)              (None, 32, 32, 512)  524288      conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 512)  2048        p_re_lu_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 32, 32, 512)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 512)  2359808     dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_15 (PReLU)              (None, 32, 32, 512)  524288      conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 512)  2048        p_re_lu_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 32, 32, 512)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 32, 32, 1)    0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, 32, 32, 1)    0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 2)    0           lambda_10[0][0]                  \n",
            "                                                                 lambda_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 1)    98          concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_9 (Multiply)           (None, 32, 32, 512)  0           dropout_15[0][0]                 \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 512)  2048        multiply_9[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 64, 64, 512)  1049088     batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 64, 64, 1536) 0           conv2d_transpose_4[0][0]         \n",
            "                                                                 model_2[0][3]                    \n",
            "                                                                 model_2[1][3]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 1536)         0           concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_4 (GlobalM (None, 1536)         0           concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_8 (Reshape)             (None, 1, 1, 1536)   0           global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_9 (Reshape)             (None, 1, 1, 1536)   0           global_max_pooling2d_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1, 1, 192)    295104      reshape_8[0][0]                  \n",
            "                                                                 reshape_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 1, 1, 1536)   296448      dense_8[0][0]                    \n",
            "                                                                 dense_8[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 1, 1, 1536)   0           dense_9[0][0]                    \n",
            "                                                                 dense_9[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 1, 1, 1536)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_10 (Multiply)          (None, 64, 64, 1536) 0           concatenate_12[0][0]             \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 64, 64, 512)  7078400     multiply_10[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_16 (PReLU)              (None, 64, 64, 512)  2097152     conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 64, 64, 512)  2048        p_re_lu_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 64, 64, 512)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 64, 64, 256)  1179904     dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_17 (PReLU)              (None, 64, 64, 256)  1048576     conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 64, 64, 256)  1024        p_re_lu_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 64, 64, 256)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 64, 64, 256)  590080      dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_18 (PReLU)              (None, 64, 64, 256)  1048576     conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 64, 64, 256)  1024        p_re_lu_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 64, 64, 256)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_12 (Lambda)              (None, 64, 64, 1)    0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 64, 64, 1)    0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 64, 64, 2)    0           lambda_12[0][0]                  \n",
            "                                                                 lambda_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 64, 64, 1)    98          concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_11 (Multiply)          (None, 64, 64, 256)  0           dropout_18[0][0]                 \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 64, 64, 256)  1024        multiply_11[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 128, 128, 256 262400      batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 128, 128, 768 0           conv2d_transpose_5[0][0]         \n",
            "                                                                 model_2[0][2]                    \n",
            "                                                                 model_2[1][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_5 (Glo (None, 768)          0           concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_5 (GlobalM (None, 768)          0           concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_10 (Reshape)            (None, 1, 1, 768)    0           global_average_pooling2d_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_11 (Reshape)            (None, 1, 1, 768)    0           global_max_pooling2d_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1, 1, 96)     73824       reshape_10[0][0]                 \n",
            "                                                                 reshape_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 1, 1, 768)    74496       dense_10[0][0]                   \n",
            "                                                                 dense_10[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 1, 1, 768)    0           dense_11[0][0]                   \n",
            "                                                                 dense_11[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 1, 1, 768)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_12 (Multiply)          (None, 128, 128, 768 0           concatenate_14[0][0]             \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 128, 128, 256 1769728     multiply_12[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_19 (PReLU)              (None, 128, 128, 256 4194304     conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 128, 128, 256 1024        p_re_lu_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 128, 128, 256 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 128, 128, 128 295040      dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_20 (PReLU)              (None, 128, 128, 128 2097152     conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 128, 128, 128 512         p_re_lu_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 128, 128, 128 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 128, 128, 128 147584      dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_21 (PReLU)              (None, 128, 128, 128 2097152     conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 128, 128, 128 512         p_re_lu_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 128, 128, 128 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_14 (Lambda)              (None, 128, 128, 1)  0           dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_15 (Lambda)              (None, 128, 128, 1)  0           dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 128, 128, 2)  0           lambda_14[0][0]                  \n",
            "                                                                 lambda_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 128, 128, 1)  98          concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_13 (Multiply)          (None, 128, 128, 128 0           dropout_21[0][0]                 \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 128, 128, 128 512         multiply_13[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 256, 256, 128 65664       batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 256, 256, 384 0           conv2d_transpose_6[0][0]         \n",
            "                                                                 model_2[0][1]                    \n",
            "                                                                 model_2[1][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_6 (Glo (None, 384)          0           concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_6 (GlobalM (None, 384)          0           concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_12 (Reshape)            (None, 1, 1, 384)    0           global_average_pooling2d_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_13 (Reshape)            (None, 1, 1, 384)    0           global_max_pooling2d_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 1, 1, 48)     18480       reshape_12[0][0]                 \n",
            "                                                                 reshape_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 1, 1, 384)    18816       dense_12[0][0]                   \n",
            "                                                                 dense_12[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 1, 1, 384)    0           dense_13[0][0]                   \n",
            "                                                                 dense_13[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 1, 1, 384)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_14 (Multiply)          (None, 256, 256, 384 0           concatenate_16[0][0]             \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 256, 256, 128 442496      multiply_14[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_22 (PReLU)              (None, 256, 256, 128 8388608     conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 256, 256, 128 512         p_re_lu_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 256, 256, 128 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 256, 256, 128 147584      dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_23 (PReLU)              (None, 256, 256, 128 8388608     conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 256, 256, 128 512         p_re_lu_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 256, 256, 128 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 256, 256, 128 147584      dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_24 (PReLU)              (None, 256, 256, 128 8388608     conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 256, 256, 128 512         p_re_lu_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 256, 256, 128 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_16 (Lambda)              (None, 256, 256, 1)  0           dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_17 (Lambda)              (None, 256, 256, 1)  0           dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 256, 256, 2)  0           lambda_16[0][0]                  \n",
            "                                                                 lambda_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 256, 256, 1)  98          concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_15 (Multiply)          (None, 256, 256, 128 0           dropout_24[0][0]                 \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 256, 256, 128 512         multiply_15[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 512, 512, 64) 32832       batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 512, 512, 192 0           conv2d_transpose_7[0][0]         \n",
            "                                                                 model_2[0][0]                    \n",
            "                                                                 model_2[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_7 (Glo (None, 192)          0           concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_7 (GlobalM (None, 192)          0           concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_14 (Reshape)            (None, 1, 1, 192)    0           global_average_pooling2d_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_15 (Reshape)            (None, 1, 1, 192)    0           global_max_pooling2d_7[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 1, 1, 24)     4632        reshape_14[0][0]                 \n",
            "                                                                 reshape_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 1, 1, 192)    4800        dense_14[0][0]                   \n",
            "                                                                 dense_14[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 1, 1, 192)    0           dense_15[0][0]                   \n",
            "                                                                 dense_15[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 1, 1, 192)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_16 (Multiply)          (None, 512, 512, 192 0           concatenate_18[0][0]             \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 512, 512, 128 221312      multiply_16[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_25 (PReLU)              (None, 512, 512, 128 33554432    conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 512, 512, 128 512         p_re_lu_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 512, 512, 128 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 512, 512, 64) 73792       dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_26 (PReLU)              (None, 512, 512, 64) 16777216    conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 512, 512, 64) 256         p_re_lu_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 512, 512, 64) 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 512, 512, 64) 36928       dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_27 (PReLU)              (None, 512, 512, 64) 16777216    conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 512, 512, 64) 256         p_re_lu_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 512, 512, 64) 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_18 (Lambda)              (None, 512, 512, 1)  0           dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_19 (Lambda)              (None, 512, 512, 1)  0           dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 512, 512, 2)  0           lambda_18[0][0]                  \n",
            "                                                                 lambda_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 512, 512, 1)  98          concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_17 (Multiply)          (None, 512, 512, 64) 0           dropout_27[0][0]                 \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "image2 (InputLayer)             [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "output_imsize (Conv2D)          (None, 512, 512, 36) 2340        multiply_17[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output_256 (Conv2D)             (None, 256, 256, 36) 4644        batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "output_128 (Conv2D)             (None, 128, 128, 36) 4644        batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "output_64 (Conv2D)              (None, 64, 64, 36)   9252        batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "output_32 (Conv2D)              (None, 32, 32, 36)   18468       batch_normalization_20[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 142,083,526\n",
            "Trainable params: 127,360,390\n",
            "Non-trainable params: 14,723,136\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzc1BlTz1e2h"
      },
      "source": [
        "lr = 0.003\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n",
        "\r\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(\r\n",
        "        name='train_accuracy')\r\n",
        "\r\n",
        "entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)#adds a softmax step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq-Zv5CyrHv8"
      },
      "source": [
        "#Using Pooling layers to reduce target image size for deep supervision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vEs-8owu17E"
      },
      "source": [
        "def DS_loss_fn(y_true, y_pred, loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), weights=[3,1,1,1,1]):\r\n",
        "  loss = 0\r\n",
        "  for i in range(len(weights)):\r\n",
        "    print(y_true.shape)\r\n",
        "    loss = loss+ weights[i]*loss_function(y_true,y_pred[i])\r\n",
        "    y_true = tf.keras.layers.MaxPool2D()(y_true) \r\n",
        "  return loss\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mkhs4ADRxhHz",
        "outputId": "b7aef446-ecdc-400c-c99b-f78b0c80334c"
      },
      "source": [
        "##Test\r\n",
        "\"\"\"\r\n",
        "y_pred = ddn([test_im1,test_im2])\r\n",
        "DS_loss_fn(test_label,y_pred)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ny_pred = ddn([test_im1,test_im2])\\nDS_loss_fn(test_label,y_pred)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oROkWaB5Xkc"
      },
      "source": [
        "save_path = \"/content/Saved_Models/\"\r\n",
        "if not(os.path.isdir(save_path)):\r\n",
        "  os.mkdir(save_path)\r\n",
        "batch_size=2\r\n",
        "epochs = 1\r\n",
        "model_savename=\"DDN_test\"\r\n",
        "train_ds = preprocessing(list_ds, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "siMws5f85j3T",
        "outputId": "9ba41882-6a77-489f-eedc-fddef4a6eadf"
      },
      "source": [
        "for epoch in range(epochs):\r\n",
        "  print(\"Start of epoch {}\".format(epoch))\r\n",
        "\r\n",
        "  for step, (im1,im2,label) in enumerate(train_ds):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "\r\n",
        "      y_pred = ddn([im1,im2],training=True)\r\n",
        "\r\n",
        "      loss_value = DS_loss_fn(label,y_pred)\r\n",
        "      \r\n",
        "\r\n",
        "    grads = tape.gradient(loss_value,ddn.trainable_weights)\r\n",
        "    optimizer.apply_gradients(zip(grads,ddn.trainable_weights))\r\n",
        "\r\n",
        "  if step % 100 == 0:\r\n",
        "      print(\r\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\r\n",
        "                % (step, float(loss_value))\r\n",
        "            )\r\n",
        "      acc = train_accuracy(y_pred,y_batch)\r\n",
        "      print (\"Training accuracy at step {} is {}\".format(step, acc))\r\n",
        "      print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\r\n",
        "            \r\n",
        "  test.save('saved_model/{}'.format(model_savename))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-8cc37426e6c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDS_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m           outputs = nn.bias_add(\n\u001b[0;32m--> 267\u001b[0;31m               outputs, self.bias, data_format=self._tf_data_format)\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   3377\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3378\u001b[0m       return gen_nn_ops.bias_add(\n\u001b[0;32m-> 3379\u001b[0;31m           value, bias, data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m    676\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2,64,64,36] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:BiasAdd]"
          ]
        }
      ]
    }
  ]
}