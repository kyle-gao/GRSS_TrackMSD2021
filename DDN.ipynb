{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP3QX1kulmCC00N7OT3frXj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyle-gao/GRSS_TrackMSD2021/blob/main/DDN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcdRBC3lFZvV"
      },
      "source": [
        "#https://github.com/GeoZcx/A-deeply-supervised-image-fusion-network-for-change-detection-in-remote-sensing-images"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4sAKIleU-pl"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import keras.backend as K\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import shutil\r\n",
        "import os\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, \\\r\n",
        "    Conv2D, Add, Activation, Lambda\r\n",
        "from keras import backend as K\r\n",
        "from keras.activations import sigmoid\r\n",
        "\r\n",
        "from keras import applications\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, concatenate, \\\r\n",
        "    Activation, ZeroPadding2D,Conv2DTranspose,Subtract,multiply,add,UpSampling2D\r\n",
        "from keras import  layers\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYunA1z8FUVb"
      },
      "source": [
        "def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same',droprate=0.3):\r\n",
        "    x = Conv2D(nb_filter, kernel_size, padding=padding, strides=strides,activation = 'relu')(x)\r\n",
        "    x=BatchNormalization(axis=3)(x)\r\n",
        "    x=Dropout(rate = droprate)(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "def attach_attention_module(net, attention_module):\r\n",
        "    if attention_module == 'se_block':  # SE_block\r\n",
        "        net = se_block(net)\r\n",
        "    elif attention_module == 'cbam_block':  # CBAM_block\r\n",
        "        net = cbam_block(net)\r\n",
        "    else:\r\n",
        "        raise Exception(\"'{}' is not supported attention module!\".format(attention_module))\r\n",
        "\r\n",
        "    return net\r\n",
        "\r\n",
        "\r\n",
        "def se_block(input_feature, ratio=8):\r\n",
        "    \"\"\"Contains the implementation of Squeeze-and-Excitation(SE) block.\r\n",
        "    As described in https://arxiv.org/abs/1709.01507.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\r\n",
        "    channel = input_feature.shape[channel_axis]\r\n",
        "\r\n",
        "    se_feature = GlobalAveragePooling2D()(input_feature)\r\n",
        "    se_feature = Reshape((1, 1, channel))(se_feature)\r\n",
        "    assert se_feature.shape[1:] == (1, 1, channel)\r\n",
        "    se_feature = Dense(channel // ratio,\r\n",
        "                       activation='relu',\r\n",
        "                       kernel_initializer='he_normal',\r\n",
        "                       use_bias=True,\r\n",
        "                       bias_initializer='zeros')(se_feature)\r\n",
        "    assert se_feature.shape[1:] == (1, 1, channel // ratio)\r\n",
        "    se_feature = Dense(channel,\r\n",
        "                       activation='sigmoid',\r\n",
        "                       kernel_initializer='he_normal',\r\n",
        "                       use_bias=True,\r\n",
        "                       bias_initializer='zeros')(se_feature)\r\n",
        "    assert se_feature.shape[1:] == (1, 1, channel)\r\n",
        "    if K.image_data_format() == 'channels_first':\r\n",
        "        se_feature = Permute((3, 1, 2))(se_feature)\r\n",
        "\r\n",
        "    se_feature = multiply([input_feature, se_feature])\r\n",
        "    return se_feature\r\n",
        "\r\n",
        "\r\n",
        "def cbam_block(cbam_feature, ratio=8):\r\n",
        "    \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\r\n",
        "    As described in https://arxiv.org/abs/1807.06521.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    cbam_feature = channel_attention(cbam_feature, ratio)\r\n",
        "    cbam_feature = spatial_attention(cbam_feature)\r\n",
        "    return cbam_feature\r\n",
        "\r\n",
        "\r\n",
        "def channel_attention(input_feature, ratio=8):\r\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\r\n",
        "    channel = input_feature.shape[channel_axis]\r\n",
        "\r\n",
        "    shared_layer_one = Dense(channel // ratio,\r\n",
        "                             activation='relu',\r\n",
        "                             kernel_initializer='he_normal',\r\n",
        "                             use_bias=True,\r\n",
        "                             bias_initializer='zeros')\r\n",
        "    shared_layer_two = Dense(channel,\r\n",
        "                             kernel_initializer='he_normal',\r\n",
        "                             use_bias=True,\r\n",
        "                             bias_initializer='zeros')\r\n",
        "\r\n",
        "    avg_pool = GlobalAveragePooling2D()(input_feature)\r\n",
        "    avg_pool = Reshape((1, 1, channel))(avg_pool)\r\n",
        "    assert avg_pool.shape[1:] == (1, 1, channel)\r\n",
        "    avg_pool = shared_layer_one(avg_pool)\r\n",
        "    assert avg_pool.shape[1:] == (1, 1, channel // ratio)\r\n",
        "    avg_pool = shared_layer_two(avg_pool)\r\n",
        "    assert avg_pool.shape[1:] == (1, 1, channel)\r\n",
        "\r\n",
        "    max_pool = GlobalMaxPooling2D()(input_feature)\r\n",
        "    max_pool = Reshape((1, 1, channel))(max_pool)\r\n",
        "    assert max_pool.shape[1:] == (1, 1, channel)\r\n",
        "    max_pool = shared_layer_one(max_pool)\r\n",
        "    assert max_pool.shape[1:] == (1, 1, channel // ratio)\r\n",
        "    max_pool = shared_layer_two(max_pool)\r\n",
        "    assert max_pool.shape[1:] == (1, 1, channel)\r\n",
        "\r\n",
        "    cbam_feature = Add()([avg_pool, max_pool])\r\n",
        "    cbam_feature = Activation('sigmoid')(cbam_feature)\r\n",
        "\r\n",
        "    if K.image_data_format() == \"channels_first\":\r\n",
        "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\r\n",
        "\r\n",
        "    return multiply([input_feature, cbam_feature])\r\n",
        "\r\n",
        "\r\n",
        "def spatial_attention(input_feature):\r\n",
        "    kernel_size = 7\r\n",
        "\r\n",
        "    if K.image_data_format() == \"channels_first\":\r\n",
        "        channel = input_feature.shape[1]\r\n",
        "        cbam_feature = Permute((2, 3, 1))(input_feature)\r\n",
        "    else:\r\n",
        "        channel = input_feature.shape[-1]\r\n",
        "        cbam_feature = input_feature\r\n",
        "\r\n",
        "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert avg_pool.shape[-1] == 1\r\n",
        "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert max_pool.shape[-1] == 1\r\n",
        "    concat = Concatenate(axis=3)([avg_pool, max_pool])\r\n",
        "    assert concat.shape[-1] == 2\r\n",
        "    cbam_feature = Conv2D(filters=1,\r\n",
        "                          kernel_size=kernel_size,\r\n",
        "                          strides=1,\r\n",
        "                          padding='same',\r\n",
        "                          activation='sigmoid',\r\n",
        "                          kernel_initializer='he_normal',\r\n",
        "                          use_bias=False)(concat)\r\n",
        "    assert cbam_feature.shape[-1] == 1\r\n",
        "\r\n",
        "    if K.image_data_format() == \"channels_first\":\r\n",
        "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\r\n",
        "\r\n",
        "    return multiply([input_feature, cbam_feature])\r\n",
        "\r\n",
        "\r\n",
        "def get_spatial_attention_map(input_feature):\r\n",
        "    kernel_size = 7\r\n",
        "    cbam_feature = input_feature\r\n",
        "\r\n",
        "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert avg_pool.shape[-1] == 1\r\n",
        "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\r\n",
        "    assert max_pool.shape[-1] == 1\r\n",
        "    concat = Concatenate(axis=3)([avg_pool, max_pool])\r\n",
        "    assert concat.shape[-1] == 2\r\n",
        "    cbam_feature = Conv2D(filters=1,\r\n",
        "                          kernel_size=kernel_size,\r\n",
        "                          strides=1,\r\n",
        "                          padding='same',\r\n",
        "                          activation='sigmoid',\r\n",
        "                          kernel_initializer='he_normal',\r\n",
        "                          use_bias=False)(concat)\r\n",
        "    assert cbam_feature.shape[-1] == 1\r\n",
        "\r\n",
        "    if K.image_data_format() == \"channels_first\":\r\n",
        "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\r\n",
        "\r\n",
        "    return cbam_feature"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbdAfEOxU5o4"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNSoIhZsWRpq",
        "outputId": "9ef062e1-5498-4935-cea4-7b1affa61a28"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAVHeP8jW6yM"
      },
      "source": [
        "shutil.unpack_archive(\"/content/drive/MyDrive/Kaggle_CoverChange.zip\",\"/content/\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtVych-nS5n5"
      },
      "source": [
        "data_dir = \"/content/Kaggle_CoverChange\"\r\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir+\"/im1/*\"),shuffle=False)\r\n",
        "#dataset is made up of strings"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASeQSd7UwjPO"
      },
      "source": [
        "\r\n",
        "#classes = array([ 29.,  38.,  75.,  76., 128., 150., 255.])\r\n",
        "class_dict = {(29):1, (38):2, (75):3,(76):3,128:4,150:5,(255):0} #mapping 75 and 76 to same class, i'm assuming this is an encoding issue.\r\n",
        "\r\n",
        "def to_categorical(tensor,class_dict):\r\n",
        "  #maps pixel values to categories 1,2...num_classes\r\n",
        "  for k,v in class_dict.items():\r\n",
        "    tensor[tensor==k]=v\r\n",
        "  return tensor"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiwDCfO1j-3g"
      },
      "source": [
        "label1_fn = \"/content/Kaggle_CoverChange/label1/00003.png\"\r\n",
        "label1 = tf.keras.preprocessing.image.load_img(label1_fn,color_mode=\"grayscale\")\r\n",
        "label1 = tf.keras.preprocessing.image.img_to_array(label1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMQDMpk9p9FM"
      },
      "source": [
        "##Testing label change conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyb7mGzSxDXK"
      },
      "source": [
        "num_classes = 6"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sd3fkTBxlLh"
      },
      "source": [
        "##Need to convert 2 labels into 1 change label\r\n",
        "\r\n",
        "Trick: Let n be number of classes\r\n",
        "Step 1. Use an outer product between one_hot encoded labels\r\n",
        "(h,w,n),(h,w,n)->(h,w,n,n), this is gives a one hot encoded change matrix M.\r\n",
        "\r\n",
        "Eg. M = 0 except for Mij = 1 -> class i changed to class j.\r\n",
        "\r\n",
        "Step 2. Convert to categorical change -> (h,w,n,n)->(h,w,n^2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnWIcy96GeId",
        "outputId": "8b58e9fa-fc66-44fb-ead6-2aefb356ebcf"
      },
      "source": [
        "\"\"\"#converting (label1,label2)->(label changemap)\r\n",
        "#where change map has num_classes^2 (not all unique) change classes \r\n",
        "def make_label_change_dict(num_classes):\r\n",
        "  label_change_dict = {}\r\n",
        "  i = 0\r\n",
        "  for x in range(num_classes):\r\n",
        "    for y in range(num_classes):\r\n",
        "      label_change_dict[(x,y)] = i *(x!=y)\r\n",
        "      i += 1\r\n",
        "  return label_change_dict\r\n",
        "\r\n",
        "label_change_dict = make_label_change_dict(6)\r\n",
        "print(label_change_dict)\"\"\"\r\n",
        "\r\n",
        "#converting (label1,label2)->(label changemap)\r\n",
        "#where change map has num_classes^2 (not all unique) change classes \r\n",
        "def make_label_change_array(num_classes):\r\n",
        "  \"\"\"Arg:\r\n",
        "  num_classes:int, number of classes\r\n",
        "  returns:\r\n",
        "  num_classes^2 matrix of categorical change labels.\r\n",
        "  \"\"\"\r\n",
        "  label_change_arr = np.zeros((num_classes,num_classes),dtype=np.uint8)\r\n",
        "  i = 0\r\n",
        "  for x in range(num_classes):\r\n",
        "    for y in range(num_classes):\r\n",
        "      label_change_arr[x,y] = i *(x!=y)\r\n",
        "      i += 1\r\n",
        "  return label_change_arr\r\n",
        "\r\n",
        "label_change_arr = make_label_change_array(6)\r\n",
        "\r\n",
        "print(label_change_arr)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  0  8  9 10 11]\n",
            " [12 13  0 15 16 17]\n",
            " [18 19 20  0 22 23]\n",
            " [24 25 26 27  0 29]\n",
            " [30 31 32 33 34  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSTX_fohoYku"
      },
      "source": [
        "def get_class_change_label(before,after,label_change_arr):\r\n",
        "  \"\"\"\r\n",
        "  Input:\r\n",
        "  two np.array or tf.tensor of shape (batch,Width,Height, num_classes) corresponding to class labeled data in one hot encoding\r\n",
        "  the arrays represent the before and after class labels for change detection\r\n",
        "  Output:\r\n",
        "  a np.array of shape (batch,Width,Height) corresponding to change labels (see figure 2)\r\n",
        "  \"\"\"\r\n",
        "  labels_combined = np.einsum(\"abd,abe->abde\",before,after)\r\n",
        "  labels_combined = labels_combined*label_change_arr\r\n",
        "  labels_combined = np.sum(labels_combined, axis=(-1,-2))\r\n",
        "  return labels_combined"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP6H0-H8FkJQ"
      },
      "source": [
        "label1_fn = \"/content/Kaggle_CoverChange/label1/00018.png\"\r\n",
        "label2_fn = \"/content/Kaggle_CoverChange/label2/00018.png\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaPsT5RHIlCo"
      },
      "source": [
        "##Testing change label generation trick"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "ipkjfudFFiUW",
        "outputId": "212a52ed-466b-4e34-f583-c9f7cf7e4428"
      },
      "source": [
        " \"\"\"   label1 = tf.keras.preprocessing.image.load_img(label1_fn, color_mode=\"grayscale\")\r\n",
        "    label1 = tf.keras.preprocessing.image.img_to_array(label1)\r\n",
        "    label1old = label1\r\n",
        "    label1 = to_categorical(label1,class_dict)\r\n",
        "    label1 = tf.expand_dims(label1,axis=0)\r\n",
        "    label1 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth = num_classes)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    label2 = tf.keras.preprocessing.image.load_img(label2_fn, color_mode =\"grayscale\")\r\n",
        "    label2 = tf.keras.preprocessing.image.img_to_array(label2)\r\n",
        "    label1old = label1\r\n",
        "    label2 = to_categorical(label2,class_dict)\r\n",
        "    label2 = tf.expand_dims(label2,axis=0)\r\n",
        "    label2old = label2\r\n",
        "    label2 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth=num_classes)\r\n",
        "\r\n",
        "    print(label1.shape)\r\n",
        "    print(label2.shape)\r\n",
        "    print(label1[0,300,300,:])\r\n",
        "    print(label2[0,300,300,:])\r\n",
        "    lc = np.einsum(\"abcd,abce->abcde\",label1,label2)\r\n",
        "\r\n",
        "    print(lc[0,300,300,:,:])\r\n",
        "    lc = lc * label_change_arr\r\n",
        "    print(lc[0,300,300,:,:])\"\"\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'   label1 = tf.keras.preprocessing.image.load_img(label1_fn, color_mode=\"grayscale\")\\n   label1 = tf.keras.preprocessing.image.img_to_array(label1)\\n   label1old = label1\\n   label1 = to_categorical(label1,class_dict)\\n   label1 = tf.expand_dims(label1,axis=0)\\n   label1 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth = num_classes)\\n\\n\\n\\n\\n   label2 = tf.keras.preprocessing.image.load_img(label2_fn, color_mode =\"grayscale\")\\n   label2 = tf.keras.preprocessing.image.img_to_array(label2)\\n   label1old = label1\\n   label2 = to_categorical(label2,class_dict)\\n   label2 = tf.expand_dims(label2,axis=0)\\n   label2old = label2\\n   label2 = tf.one_hot(tf.cast(label1[:,:,:,0],dtype = tf.uint8),depth=num_classes)\\n\\n   print(label1.shape)\\n   print(label2.shape)\\n   print(label1[0,300,300,:])\\n   print(label2[0,300,300,:])\\n   lc = np.einsum(\"abcd,abce->abcde\",label1,label2)\\n\\n   print(lc[0,300,300,:,:])\\n   lc = lc * label_change_arr\\n   print(lc[0,300,300,:,:])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPl1JfAgIo3b"
      },
      "source": [
        "##Testing over"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooE716J8bpnx"
      },
      "source": [
        "def get_item(path):\r\n",
        "\r\n",
        "  #wrap function in tf.numpy_function() or tf.data.dataset.map bugs out\r\n",
        "\r\n",
        "  def _get_item(path):\r\n",
        "    \"\"\"\r\n",
        "    args:\r\n",
        "    path: Dataset.list_file dataset element\r\n",
        "\r\n",
        "    returns: \r\n",
        "    (h,w,3),(h,w,1),(h,w,3),(h,w,1) image-label 4-tuple in tf.float32 tf.Tensor\r\n",
        "    \"\"\"\r\n",
        "    fn = tf.strings.split(path,\"/\")\r\n",
        "    base_dir = tf.strings.join(fn[:-2],separator=\"/\")\r\n",
        "\r\n",
        "    image1_fn = (base_dir+\"/im1/\"+fn[-1]).numpy()\r\n",
        "    image2_fn = (base_dir+\"/im2/\"+fn[-1]).numpy()\r\n",
        "\r\n",
        "    label1_fn = (base_dir+\"/label1/\"+fn[-1]).numpy()\r\n",
        "    label2_fn = (base_dir+\"/label2/\"+fn[-1]).numpy()\r\n",
        "\r\n",
        "    #label1_fn = \"/content/Kaggle_CoverChange/label1/00018.png\"\r\n",
        "    #label2_fn = \"/content/Kaggle_CoverChange/label2/00018.png\"\r\n",
        "\r\n",
        "\r\n",
        "    image1 = tf.keras.preprocessing.image.load_img(image1_fn)\r\n",
        "    image1 = tf.keras.preprocessing.image.img_to_array(image1)\r\n",
        "\r\n",
        "    image2 = tf.keras.preprocessing.image.load_img(image2_fn)\r\n",
        "    image2 = tf.keras.preprocessing.image.img_to_array(image2)\r\n",
        "\r\n",
        "    label1 = tf.keras.preprocessing.image.load_img(label1_fn, color_mode=\"grayscale\")\r\n",
        "    label1 = tf.keras.preprocessing.image.img_to_array(label1)\r\n",
        "    label1 = to_categorical(label1,class_dict)\r\n",
        "    #label1 = tf.expand_dims(label1,axis=0)\r\n",
        "\r\n",
        "    label1 = tf.one_hot(tf.cast(label1[:,:,0],dtype = tf.uint8),depth = num_classes)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    label2 = tf.keras.preprocessing.image.load_img(label2_fn, color_mode =\"grayscale\")\r\n",
        "    label2 = tf.keras.preprocessing.image.img_to_array(label2)\r\n",
        "    label2 = to_categorical(label2,class_dict)\r\n",
        "    #label2 = tf.expand_dims(label2,axis=0)\r\n",
        "\r\n",
        "    label2 = tf.one_hot(tf.cast(label2[:,:,0],dtype = tf.uint8),depth=num_classes)\r\n",
        "\r\n",
        "    change_label = get_class_change_label(label1,label2,label_change_arr=label_change_arr)\r\n",
        "    change_label = tf.expand_dims(change_label, axis=-1)\r\n",
        "\r\n",
        "    #classes = array([ 29.,  38.,  75.,  76., 128., 150., 255.])\r\n",
        "    #(h,w,1) tensor of int from 1-6\r\n",
        "\r\n",
        "    return image1,image2,change_label\r\n",
        "\r\n",
        "  output = tf.numpy_function(_get_item,[path],[tf.float32,tf.float32,tf.float32])\r\n",
        "\r\n",
        "  return output"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT3E2boXh6fa"
      },
      "source": [
        "def preprocessing(list_ds,batch_size=8,augmentation=None):\r\n",
        "  \"\"\"\r\n",
        "  applies some preprocessing\r\n",
        "  args:\r\n",
        "  list_ds-Dataset.list_files dataset object\r\n",
        "  batch_size-int \r\n",
        "  augmentation-a function (x,y)->(x,y)\r\n",
        "  returns-batched dataset\r\n",
        "  \"\"\"\r\n",
        "  #ds = list_ds.cache() \r\n",
        "  ds = list_ds.map(get_item,num_parallel_calls=tf.data.AUTOTUNE) #(h,w,3),(h,w,1)\r\n",
        "  ds = ds.batch(batch_size)\r\n",
        "  ds = ds.shuffle(100)\r\n",
        "\r\n",
        "  if augmentation:\r\n",
        "    ds = ds.map((lambda x,y : augmentation(x,y)),num_parallel_calls=tf.data.AUTOTUNE)\r\n",
        "\r\n",
        "  \r\n",
        "  ds = ds.prefetch(8)\r\n",
        "  return ds\r\n",
        "\r\n",
        "def transform(x,y):\r\n",
        "  \"\"\"\r\n",
        "  Write your data transformations here\r\n",
        "  \"\"\"\r\n",
        "  x=tf.keras.layers.experimental.preprocessing.Rescaling(1./255.0)(x)\r\n",
        "  y=tf.one_hot(tf.cast(y[:,:,0],dtype = tf.int32),depth = 7)\r\n",
        "\r\n",
        "  return x,y"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu4qpWMq6guQ"
      },
      "source": [
        "#load pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1jzSEkZ4YZW"
      },
      "source": [
        "shutil.unpack_archive(\"/content/drive/MyDrive/vgg_512_seg_model.zip\",\"/content/Drive/Saved_Model/\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtrhDcrsZM3u"
      },
      "source": [
        "##Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm7aDD4m6pIK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "beb0fb58-818a-46f6-987e-8b4adb459bb7"
      },
      "source": [
        "\"\"\"\r\n",
        "vgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\r\n",
        "vgg16_512.summary()\r\n",
        "\r\n",
        "feature_layers = [vgg16_512.get_layer(\"features_c1\"),vgg16_512.get_layer(\"features_c2\"),vgg16_512.get_layer('features_c3'),vgg16_512.get_layer('features_c4'),vgg16_512.get_layer('features_c5')]\r\n",
        "feature_extractor = tf.keras.models.Model(inputs = vgg16_512.input, outputs = [layer.output for layer in feature_layers])\r\n",
        "\r\n",
        "test_tensor = tf.random.normal((1,512,512,3))\r\n",
        "test_out = feature_extractor(test_tensor)\r\n",
        "for t in test_out:\r\n",
        "  print(t.shape)\r\n",
        "\"\"\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nvgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\\nvgg16_512.summary()\\n\\nfeature_layers = [vgg16_512.get_layer(\"features_c1\"),vgg16_512.get_layer(\"features_c2\"),vgg16_512.get_layer(\\'features_c3\\'),vgg16_512.get_layer(\\'features_c4\\'),vgg16_512.get_layer(\\'features_c5\\')]\\nfeature_extractor = tf.keras.models.Model(inputs = vgg16_512.input, outputs = [layer.output for layer in feature_layers])\\n\\ntest_tensor = tf.random.normal((1,512,512,3))\\ntest_out = feature_extractor(test_tensor)\\nfor t in test_out:\\n  print(t.shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2mdKpIkXsl4"
      },
      "source": [
        "#DDN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBfmi39zGBYO"
      },
      "source": [
        "vgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQJ4Ho2XGDKh",
        "outputId": "ed25e0de-9714-452c-e316-7cf35a319c02"
      },
      "source": [
        "vgg16_512.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_24 (InputLayer)           [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "base_vgg (Functional)           [(None, 128, 128, 25 14714688    input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "features_c5 (Dropout)           (None, 32, 32, 512)  0           base_vgg[0][2]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling2D) (None, 16, 16, 512)  0           features_c5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 4096) 102764544   max_pooling2d_57[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_98 (Dropout)            (None, 16, 16, 4096) 0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 16, 16, 4096) 16781312    dropout_98[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "features_c2 (Dropout)           (None, 256, 256, 128 0           base_vgg[0][3]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_99 (Dropout)            (None, 16, 16, 4096) 0           conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "features_c4 (Dropout)           (None, 64, 64, 512)  0           base_vgg[0][1]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling2D) (None, 128, 128, 128 0           features_c2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 16, 16, 7)    28679       dropout_99[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling2D) (None, 32, 32, 512)  0           features_c4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "junk2 (Conv2D)                  (None, 128, 128, 256 33024       max_pooling2d_54[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_100 (Dropout)           (None, 16, 16, 7)    0           conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 32, 32, 7)    3591        max_pooling2d_56[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "features_c3 (Dropout)           (None, 128, 128, 256 0           base_vgg[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_20 (TFOpLambda (None, 128, 128, 256 0           junk2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_36 (Conv2DTran (None, 32, 32, 7)    791         dropout_100[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_97 (Dropout)            (None, 32, 32, 7)    0           conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_44 (TFOpLa (None, 128, 128, 256 0           features_c3[0][0]                \n",
            "                                                                 tf.math.multiply_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_45 (TFOpLa (None, 32, 32, 7)    0           conv2d_transpose_36[0][0]        \n",
            "                                                                 dropout_97[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling2D) (None, 64, 64, 256)  0           tf.__operators__.add_44[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_101 (Dropout)           (None, 32, 32, 7)    0           tf.__operators__.add_45[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 64, 64, 7)    1799        max_pooling2d_55[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_37 (Conv2DTran (None, 64, 64, 7)    791         dropout_101[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_96 (Dropout)            (None, 64, 64, 7)    0           conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_46 (TFOpLa (None, 64, 64, 7)    0           conv2d_transpose_37[0][0]        \n",
            "                                                                 dropout_96[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_102 (Dropout)           (None, 64, 64, 7)    0           tf.__operators__.add_46[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "features_c1 (Dropout)           (None, 512, 512, 64) 0           base_vgg[0][4]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_38 (Conv2DTran (None, 512, 512, 7)  12551       dropout_102[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "junk (Conv2D)                   (None, 512, 512, 7)  455         features_c1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 512, 512, 7)  0           conv2d_transpose_38[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_21 (TFOpLambda (None, 512, 512, 7)  0           junk[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_47 (TFOpLa (None, 512, 512, 7)  0           dropout_103[0][0]                \n",
            "                                                                 tf.math.multiply_21[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 134,342,225\n",
            "Trainable params: 134,342,225\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eiduk23cFPBz"
      },
      "source": [
        "def DDN (imsize, num_classes = 6):\r\n",
        "    #if input image 512*512\r\n",
        "\r\n",
        "    vgg16_512 = tf.keras.models.load_model(\"/content/Drive/Saved_Model\")\r\n",
        "\r\n",
        "    image1 = layers.Input((imsize,imsize,3),name = \"image1\")\r\n",
        "    image2 = layers.Input((imsize,imsize,3),name = \"image2\")\r\n",
        "\r\n",
        "    feature_layers = [vgg16_512.get_layer(\"features_c1\"),vgg16_512.get_layer(\"features_c2\"),vgg16_512.get_layer('features_c3'),vgg16_512.get_layer('features_c4'),vgg16_512.get_layer('features_c5')]\r\n",
        "    feature_extractor = tf.keras.models.Model(inputs = vgg16_512.input, outputs = [layer.output for layer in feature_layers],trainable=False)\r\n",
        "\r\n",
        "    features_1 = feature_extractor(image1)\r\n",
        "    features_2 = feature_extractor(image1)\r\n",
        "\r\n",
        "    t1_b5c3 = features_1[4] #(None, 32, 32, 512)\r\n",
        "    t2_b5c3 = features_2[4] \r\n",
        "\r\n",
        "    t1_b4c3 = features_1[3] #(None, 64, 64, 512)\r\n",
        "    t2_b4c3 = features_2[3] \r\n",
        "    \r\n",
        "    t1_b3c3 = features_1[2] #(None, 128, 128, 256)  \r\n",
        "    t2_b3c3 = features_2[2]\r\n",
        "\r\n",
        "    t1_b2c2 = features_1[1]\r\n",
        "    t2_b2c2 = features_2[1] #(None, 256, 256, 128) \r\n",
        "\r\n",
        "    t1_b1c2 = features_1[0]\r\n",
        "    t2_b1c2 = features_2[0] #(None, 512, 512, 64)\r\n",
        "\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    pair5 = layers.Input((imsize,imsize,64*2), name='pair5') #rbg images concatenated channel-wise\r\n",
        "    pair4 = layers.Input((imsize//2,imsize//2,128*2), name='pair4')\r\n",
        "    pair3 = layers.Input((imsize//4,imsize//4,256*2), name='pair3')\r\n",
        "    pair2 = layers.Input((imsize//8,imsize//8,512*2), name='pair2')\r\n",
        "    pair1 = layers.Input((imsize//16,imsize//16,512*2), name='pair1')\r\n",
        "\r\n",
        "\r\n",
        "    t1_b5c3 = pair1[:,:,:,:3] #(None, 32, 32, 512)\r\n",
        "    t2_b5c3 = pair1[:,:,:,3:] \r\n",
        "\r\n",
        "    t1_b4c3 = pair2[:,:,:,:3] #(None, 64, 64, 512)\r\n",
        "    t2_b4c3 = pair2[:,:,:,3:] \r\n",
        "    \r\n",
        "    t1_b3c3 = pair3[:,:,:,:3] #(None, 128, 128, 256)  \r\n",
        "    t2_b3c3 = pair3[:,:,:,3:]\r\n",
        "\r\n",
        "    t1_b2c2 = pair4[:,:,:,:3]\r\n",
        "    t2_b2c2 = pair4[:,:,:,3:] #(None, 256, 256, 128) \r\n",
        "\r\n",
        "    t1_b1c2 = pair5[:,:,:,:3]\r\n",
        "    t2_b1c2 = pair5[:,:,:,3:] #(None, 512, 512, 64)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    concat_b5c3 = concatenate([t1_b5c3, t2_b5c3], axis=3) #channel 1024\r\n",
        "    x = Conv2d_BN(concat_b5c3,imsize, 3)\r\n",
        "    x = Conv2d_BN(x,imsize,3)\r\n",
        "    attention_map_1 = get_spatial_attention_map(x)\r\n",
        "    x = multiply([x, attention_map_1])\r\n",
        "    x = BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche1\r\n",
        "    branch_1 =Conv2D(num_classes**2, kernel_size=1, padding='same',name='output_32')(x)\r\n",
        "\r\n",
        "    x = Conv2DTranspose(imsize, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = concatenate([x,t1_b4c3,t2_b4c3],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,imsize,3)\r\n",
        "    x = Conv2d_BN(x,256,3)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    attention_map_2 = get_spatial_attention_map(x)\r\n",
        "    x = multiply([x, attention_map_2])\r\n",
        "    x = BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche2\r\n",
        "    branch_2 =Conv2D(num_classes**2, kernel_size=1, padding='same',name='output_64')(x)\r\n",
        "\r\n",
        "    x = Conv2DTranspose(256, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = concatenate([x,t1_b3c3,t2_b3c3],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,256,3)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x, 64, 3)\r\n",
        "    attention_map_3 = get_spatial_attention_map(x)\r\n",
        "    x = multiply([x, attention_map_3])\r\n",
        "    x = BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche3\r\n",
        "    branch_3 =Conv2D(num_classes**2, kernel_size=1, padding='same',name='output_128')(x)\r\n",
        "\r\n",
        "    x = Conv2DTranspose(128, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = concatenate([x,t1_b2c2,t2_b2c2],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x, 128, 3)\r\n",
        "    attention_map_4 = get_spatial_attention_map(x)\r\n",
        "    x = multiply([x, attention_map_4])\r\n",
        "    x = BatchNormalization(axis=3)(x)\r\n",
        "\r\n",
        "    #branche4\r\n",
        "    branch_4 =Conv2D(num_classes**2, kernel_size=1, padding='same',name='output_256')(x)\r\n",
        "\r\n",
        "    x = Conv2DTranspose(64, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(x)\r\n",
        "    x = concatenate([x,t1_b1c2,t2_b1c2],axis=3)\r\n",
        "    x = channel_attention(x)\r\n",
        "    x = Conv2d_BN(x,128,3)\r\n",
        "    x = Conv2d_BN(x,64,3)\r\n",
        "    x = Conv2d_BN(x, 64, 3)\r\n",
        "    attention_map_5 = get_spatial_attention_map(x)\r\n",
        "    x = multiply([x, attention_map_5])\r\n",
        "\r\n",
        "    # branche5\r\n",
        "    branch_5 =Conv2D(num_classes**2, kernel_size=1, padding='same',name='output_imsize')(x)\r\n",
        "\r\n",
        "    DDN = Model(inputs=[image1,image2], outputs=[branch_5,branch_4,branch_3,branch_2,branch_1])\r\n",
        "\r\n",
        "    return DDN"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NykWcUcQzdFh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0fb42a74-3a7f-4cd5-f73a-085c192ee33c"
      },
      "source": [
        "#TEST\r\n",
        "\"\"\"\r\n",
        "imsize = 512\r\n",
        "image1 = tf.random.normal((1,512,512,3))\r\n",
        "image2 = tf.random.normal((1,512,512,3))\r\n",
        "ddn = DDN(512,6)\r\n",
        "forward = ddn([image1,image2])\r\n",
        "for f in forward:\r\n",
        "  print (f.shape)\"\"\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimsize = 512\\nimage1 = tf.random.normal((1,512,512,3))\\nimage2 = tf.random.normal((1,512,512,3))\\nddn = DDN(512,6)\\nforward = ddn([image1,image2])\\nfor f in forward:\\n  print (f.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-ihDr4C1Siz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ace0aa1-e354-47cd-983d-20333ef2d082"
      },
      "source": [
        "ddn = DDN(512,6)\r\n",
        "ddn.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "image1 (InputLayer)             [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model (Functional)              [(None, 512, 512, 64 14714688    image1[0][0]                     \n",
            "                                                                 image1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 1024) 0           model[0][4]                      \n",
            "                                                                 model[1][4]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 512)  4719104     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 512)  2048        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 512)  0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 512)  2359808     dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 512)  2048        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 512)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 32, 32, 1)    0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 32, 32, 1)    0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 2)    0           lambda[0][0]                     \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 1)    98          concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 32, 32, 512)  0           dropout_1[0][0]                  \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 512)  2048        multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 64, 64, 512)  1049088     batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 1536) 0           conv2d_transpose[0][0]           \n",
            "                                                                 model[0][3]                      \n",
            "                                                                 model[1][3]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1536)         0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 1536)         0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 1, 1, 1536)   0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 1536)   0           global_max_pooling2d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1, 1, 192)    295104      reshape[0][0]                    \n",
            "                                                                 reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1, 1, 1536)   296448      dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 1, 1, 1536)   0           dense_1[0][0]                    \n",
            "                                                                 dense_1[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 1, 1, 1536)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 64, 64, 1536) 0           concatenate_2[0][0]              \n",
            "                                                                 activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 64, 64, 512)  7078400     multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 512)  2048        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64, 64, 512)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 64, 64, 256)  1179904     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64, 64, 256)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 256)  1024        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 64, 64, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 64, 64, 1)    0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 64, 64, 1)    0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 64, 64, 2)    0           lambda_2[0][0]                   \n",
            "                                                                 lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 1)    98          concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 64, 64, 256)  0           dropout_4[0][0]                  \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 256)  1024        multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 256 262400      batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 128, 128, 768 0           conv2d_transpose_1[0][0]         \n",
            "                                                                 model[0][2]                      \n",
            "                                                                 model[1][2]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 768)          0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_1 (GlobalM (None, 768)          0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 1, 1, 768)    0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 1, 1, 768)    0           global_max_pooling2d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1, 1, 96)     73824       reshape_2[0][0]                  \n",
            "                                                                 reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1, 1, 768)    74496       dense_2[0][0]                    \n",
            "                                                                 dense_2[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 1, 1, 768)    0           dense_3[0][0]                    \n",
            "                                                                 dense_3[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 1, 1, 768)    0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_3 (Multiply)           (None, 128, 128, 768 0           concatenate_4[0][0]              \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 128, 128, 256 1769728     multiply_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 128, 128, 256 1024        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 128, 128, 256 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 128, 128, 128 295040      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 128, 128, 128 512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 128, 128, 128 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 128, 128, 128 147584      dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 128, 128, 128 512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 128, 128, 128 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 128, 128, 1)  0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 128, 128, 1)  0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 128, 128, 2)  0           lambda_4[0][0]                   \n",
            "                                                                 lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 128, 128, 1)  98          concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, 128, 128, 128 0           dropout_7[0][0]                  \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 128, 128, 128 512         multiply_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 128 65664       batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 256, 256, 384 0           conv2d_transpose_2[0][0]         \n",
            "                                                                 model[0][1]                      \n",
            "                                                                 model[1][1]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 384)          0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_2 (GlobalM (None, 384)          0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 1, 1, 384)    0           global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 1, 1, 384)    0           global_max_pooling2d_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1, 1, 48)     18480       reshape_4[0][0]                  \n",
            "                                                                 reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1, 1, 384)    18816       dense_4[0][0]                    \n",
            "                                                                 dense_4[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 1, 1, 384)    0           dense_5[0][0]                    \n",
            "                                                                 dense_5[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 1, 1, 384)    0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_5 (Multiply)           (None, 256, 256, 384 0           concatenate_6[0][0]              \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 256, 256, 128 442496      multiply_5[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 256, 256, 128 512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 256, 256, 128 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 256, 256, 128 147584      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 256, 256, 128 512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 256, 256, 128 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 256, 256, 128 147584      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 256, 256, 128 512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 256, 256, 128 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 256, 256, 1)  0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 256, 256, 1)  0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 256, 256, 2)  0           lambda_6[0][0]                   \n",
            "                                                                 lambda_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 256, 256, 1)  98          concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_6 (Multiply)           (None, 256, 256, 128 0           dropout_10[0][0]                 \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 256, 256, 128 512         multiply_6[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 512, 512, 64) 32832       batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 512, 512, 192 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 model[0][0]                      \n",
            "                                                                 model[1][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 192)          0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_3 (GlobalM (None, 192)          0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 1, 1, 192)    0           global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_7 (Reshape)             (None, 1, 1, 192)    0           global_max_pooling2d_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1, 1, 24)     4632        reshape_6[0][0]                  \n",
            "                                                                 reshape_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1, 1, 192)    4800        dense_6[0][0]                    \n",
            "                                                                 dense_6[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 1, 1, 192)    0           dense_7[0][0]                    \n",
            "                                                                 dense_7[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1, 1, 192)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_7 (Multiply)           (None, 512, 512, 192 0           concatenate_8[0][0]              \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 512, 512, 128 221312      multiply_7[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 512, 512, 128 512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 512, 512, 128 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 512, 512, 64) 73792       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 512, 512, 64) 256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 512, 512, 64) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 512, 512, 64) 36928       dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 512, 512, 64) 256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 512, 512, 64) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 512, 512, 1)  0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 512, 512, 1)  0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 512, 512, 2)  0           lambda_8[0][0]                   \n",
            "                                                                 lambda_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 512, 512, 1)  98          concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_8 (Multiply)           (None, 512, 512, 64) 0           dropout_13[0][0]                 \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "image2 (InputLayer)             [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "output_imsize (Conv2D)          (None, 512, 512, 36) 2340        multiply_8[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "output_256 (Conv2D)             (None, 256, 256, 36) 4644        batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "output_128 (Conv2D)             (None, 128, 128, 36) 4644        batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "output_64 (Conv2D)              (None, 64, 64, 36)   9252        batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "output_32 (Conv2D)              (None, 32, 32, 36)   18468       batch_normalization_2[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 36,177,350\n",
            "Trainable params: 21,454,214\n",
            "Non-trainable params: 14,723,136\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzc1BlTz1e2h"
      },
      "source": [
        "lr = 0.003\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n",
        "\r\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(\r\n",
        "        name='train_accuracy')\r\n",
        "\r\n",
        "entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)#adds a softmax step"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq-Zv5CyrHv8"
      },
      "source": [
        "#Using Pooling layers to reduce target image size for deep supervision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vEs-8owu17E"
      },
      "source": [
        "def DS_loss_fn(y_true, y_pred, loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), weights=[3,1,1,1,1]):\r\n",
        "  loss = 0\r\n",
        "  for i in range(len(weights)):\r\n",
        "    print(y_true.shape)\r\n",
        "    loss = loss+ weights[i]*loss_function(y_true,y_pred[i])\r\n",
        "    y_true = tf.keras.layers.MaxPool2D()(y_true) \r\n",
        "  return loss\r\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mkhs4ADRxhHz",
        "outputId": "5494efe6-583c-4373-ee84-a2544f3dfad6"
      },
      "source": [
        "##Test\r\n",
        "\"\"\"\r\n",
        "y_pred = ddn([test_im1,test_im2])\r\n",
        "DS_loss_fn(test_label,y_pred)\"\"\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ny_pred = ddn([test_im1,test_im2])\\nDS_loss_fn(test_label,y_pred)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oROkWaB5Xkc"
      },
      "source": [
        "save_path = \"/content/Saved_Models/\"\r\n",
        "if not(os.path.isdir(save_path)):\r\n",
        "  os.mkdir(save_path)\r\n",
        "batch_size=2\r\n",
        "epochs = 1\r\n",
        "model_savename=\"DDN_test\"\r\n",
        "train_ds = preprocessing(list_ds, batch_size = batch_size)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "siMws5f85j3T",
        "outputId": "780f1b82-8fd4-42da-8c3d-61adf3c88f47"
      },
      "source": [
        "for epoch in range(epochs):\r\n",
        "  print(\"Start of epoch {}\".format(epoch))\r\n",
        "\r\n",
        "  for step, (im1,im2,label) in enumerate(train_ds):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "\r\n",
        "      y_pred = ddn([im1,im2],training=True)\r\n",
        "\r\n",
        "      loss_value = DS_loss_fn(label,y_pred)\r\n",
        "      \r\n",
        "\r\n",
        "    grads = tape.gradient(loss_value,ddn.trainable_weights)\r\n",
        "    optimizer.apply_gradients(zip(grads,ddn.trainable_weights))\r\n",
        "\r\n",
        "  if step % 100 == 0:\r\n",
        "      print(\r\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\r\n",
        "                % (step, float(loss_value))\r\n",
        "            )\r\n",
        "      acc = train_accuracy(y_pred,y_batch)\r\n",
        "      print (\"Training accuracy at step {} is {}\".format(step, acc))\r\n",
        "      print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\r\n",
        "            \r\n",
        "  test.save('saved_model/{}'.format(model_savename))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-8cc37426e6c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDS_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36m_merge_function\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(tensors, axis)\u001b[0m\n\u001b[1;32m   2987\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mragged_concat_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2989\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1675\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1676\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1677\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2,512,512,192] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ConcatV2] name: concat"
          ]
        }
      ]
    }
  ]
}